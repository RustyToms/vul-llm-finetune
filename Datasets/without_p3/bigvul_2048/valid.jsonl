{"code":"static bool blk_kick_flush(struct request_queue *q, struct blk_flush_queue *fq)\n{\n\tstruct list_head *pending = &fq->flush_queue[fq->flush_pending_idx];\n\tstruct request *first_rq =\n\t\tlist_first_entry(pending, struct request, flush.list);\n\tstruct request *flush_rq = fq->flush_rq;\n\n\t\/* C1 described at the top of this file *\/\n\tif (fq->flush_pending_idx != fq->flush_running_idx || list_empty(pending))\n\t\treturn false;\n\n\t\/* C2 and C3 *\/\n\tif (!list_empty(&fq->flush_data_in_flight) &&\n\t    time_before(jiffies,\n\t\t\tfq->flush_pending_since + FLUSH_PENDING_TIMEOUT))\n\t\treturn false;\n\n\t\/*\n\t * Issue flush and toggle pending_idx.  This makes pending_idx\n\t * different from running_idx, which means flush is in flight.\n\t *\/\n\tfq->flush_pending_idx ^= 1;\n\n\tblk_rq_init(q, flush_rq);\n \n \t\/*\n \t * Borrow tag from the first request since they can't\n\t * be in flight at the same time.\n \t *\/\n \tif (q->mq_ops) {\n \t\tflush_rq->mq_ctx = first_rq->mq_ctx;\n \t\tflush_rq->tag = first_rq->tag;\n \t}\n \n \tflush_rq->cmd_type = REQ_TYPE_FS;\n\tflush_rq->cmd_flags = WRITE_FLUSH | REQ_FLUSH_SEQ;\n\tflush_rq->rq_disk = first_rq->rq_disk;\n\tflush_rq->end_io = flush_end_io;\n\n\treturn blk_flush_queue_rq(flush_rq, false);\n}\n","idx":182625,"target":1}
{"code":"static void flush_end_io(struct request *flush_rq, int error)\n{\n\tstruct request_queue *q = flush_rq->q;\n\tstruct list_head *running;\n\tbool queued = false;\n\tstruct request *rq, *n;\n\tunsigned long flags = 0;\n \tstruct blk_flush_queue *fq = blk_get_flush_queue(q, flush_rq->mq_ctx);\n \n \tif (q->mq_ops) {\n \t\tspin_lock_irqsave(&fq->mq_flush_lock, flags);\n \t\tflush_rq->tag = -1;\n \t}\n \n\trunning = &fq->flush_queue[fq->flush_running_idx];\n\tBUG_ON(fq->flush_pending_idx == fq->flush_running_idx);\n\n\t\/* account completion of the flush request *\/\n\tfq->flush_running_idx ^= 1;\n\n\tif (!q->mq_ops)\n\t\telv_completed_request(q, flush_rq);\n\n\t\/* and push the waiting requests to the next stage *\/\n\tlist_for_each_entry_safe(rq, n, running, flush.list) {\n\t\tunsigned int seq = blk_flush_cur_seq(rq);\n\n\t\tBUG_ON(seq != REQ_FSEQ_PREFLUSH && seq != REQ_FSEQ_POSTFLUSH);\n\t\tqueued |= blk_flush_complete_seq(rq, fq, seq, error);\n\t}\n\n\t\/*\n\t * Kick the queue to avoid stall for two cases:\n\t * 1. Moving a request silently to empty queue_head may stall the\n\t * queue.\n\t * 2. When flush request is running in non-queueable queue, the\n\t * queue is hold. Restart the queue after flush request is finished\n\t * to avoid stall.\n\t * This function is called from request completion path and calling\n\t * directly into request_fn may confuse the driver.  Always use\n\t * kblockd.\n\t *\/\n\tif (queued || fq->flush_queue_delayed) {\n\t\tWARN_ON(q->mq_ops);\n\t\tblk_run_queue_async(q);\n\t}\n\tfq->flush_queue_delayed = 0;\n\tif (q->mq_ops)\n\t\tspin_unlock_irqrestore(&fq->mq_flush_lock, flags);\n}\n","idx":182626,"target":1}
{"code":"static void bt_for_each(struct blk_mq_hw_ctx *hctx,\n\t\tstruct blk_mq_bitmap_tags *bt, unsigned int off,\n\t\tbusy_iter_fn *fn, void *data, bool reserved)\n{\n\tstruct request *rq;\n\tint bit, i;\n\n\tfor (i = 0; i < bt->map_nr; i++) {\n\t\tstruct blk_align_bitmap *bm = &bt->map[i];\n\n \t\tfor (bit = find_first_bit(&bm->word, bm->depth);\n \t\t     bit < bm->depth;\n \t\t     bit = find_next_bit(&bm->word, bm->depth, bit + 1)) {\n\t\t     \trq = blk_mq_tag_to_rq(hctx->tags, off + bit);\n \t\t\tif (rq->q == hctx->queue)\n \t\t\t\tfn(hctx, rq, data, reserved);\n \t\t}\n\n\t\toff += (1 << bt->bits_per_word);\n\t}\n}\n","idx":182627,"target":1}
{"code":"static void bt_tags_for_each(struct blk_mq_tags *tags,\n\t\tstruct blk_mq_bitmap_tags *bt, unsigned int off,\n\t\tbusy_tag_iter_fn *fn, void *data, bool reserved)\n{\n\tstruct request *rq;\n\tint bit, i;\n\n\tif (!tags->rqs)\n\t\treturn;\n\tfor (i = 0; i < bt->map_nr; i++) {\n\t\tstruct blk_align_bitmap *bm = &bt->map[i];\n\n \t\tfor (bit = find_first_bit(&bm->word, bm->depth);\n \t\t     bit < bm->depth;\n \t\t     bit = find_next_bit(&bm->word, bm->depth, bit + 1)) {\n\t\t\trq = blk_mq_tag_to_rq(tags, off + bit);\n \t\t\tfn(rq, data, reserved);\n \t\t}\n \n\t\toff += (1 << bt->bits_per_word);\n\t}\n}\n","idx":182628,"target":1}
{"code":" struct request *blk_mq_tag_to_rq(struct blk_mq_tags *tags, unsigned int tag)\n {\n\tstruct request *rq = tags->rqs[tag];\n\t\/* mq_ctx of flush rq is always cloned from the corresponding req *\/\n\tstruct blk_flush_queue *fq = blk_get_flush_queue(rq->q, rq->mq_ctx);\n\tif (!is_flush_request(rq, fq, tag))\n\t\treturn rq;\n\treturn fq->flush_rq;\n }\n","idx":182629,"target":1}
{"code":"static inline bool is_flush_request(struct request *rq,\n\t\tstruct blk_flush_queue *fq, unsigned int tag)\n{\n\treturn ((rq->cmd_flags & REQ_FLUSH_SEQ) &&\n\t\t\tfq->flush_rq->tag == tag);\n}\n","idx":182630,"target":1}
{"code":"Parser::Parser(XRef *xrefA, Lexer *lexerA, GBool allowStreamsA) {\n  xref = xrefA;\n  lexer = lexerA;\n  inlineImg = 0;\n  allowStreams = allowStreamsA;\n  buf1 = lexer->getObj();\n  buf2 = lexer->getObj();\n}\n","idx":4783,"target":0}
{"code":" void dvb_usbv2_disconnect(struct usb_interface *intf)\n {\n \tstruct dvb_usb_device *d = usb_get_intfdata(intf);\n\tconst char *name = d->name;\n\tstruct device dev = d->udev->dev;\n \n \tdev_dbg(&d->udev->dev, \"%s: bInterfaceNumber=%d\\n\", __func__,\n \t\t\tintf->cur_altsetting->desc.bInterfaceNumber);\n\n\tif (d->props->exit)\n\t\td->props->exit(d);\n \n \tdvb_usbv2_exit(d);\n \n\tdev_info(&dev, \"%s: '%s' successfully deinitialized and disconnected\\n\",\n\t\t\tKBUILD_MODNAME, name);\n }\n","idx":181394,"target":1}
{"code":"vips_malloc( VipsObject *object, size_t size )\n {\n \tvoid *buf;\n \n\tbuf = g_malloc( size );\n \n         if( object ) {\n \t\tg_signal_connect( object, \"postclose\", \n\t\t\tG_CALLBACK( vips_malloc_cb ), buf );\n\t\tobject->local_memory += size;\n\t}\n\n\treturn( buf );\n}\n","idx":182911,"target":1}
{"code":"vips_tracked_malloc( size_t size )\n{\n        void *buf;\n\n\tvips_tracked_init(); \n\n\t\/* Need an extra sizeof(size_t) bytes to track \n\t * size of this block. Ask for an extra 16 to make sure we don't break\n\t * alignment rules.\n \t *\/\n \tsize += 16;\n \n        if( !(buf = g_try_malloc( size )) ) {\n #ifdef DEBUG\n \t\tg_assert_not_reached();\n #endif \/*DEBUG*\/\n\n\t\tvips_error( \"vips_tracked\", \n\t\t\t_( \"out of memory --- size == %dMB\" ), \n\t\t\t(int) (size \/ (1024.0 * 1024.0))  );\n\t\tg_warning( _( \"out of memory --- size == %dMB\" ), \n\t\t\t(int) (size \/ (1024.0 * 1024.0))  );\n\n                return( NULL );\n\t}\n\n\tg_mutex_lock( vips_tracked_mutex );\n\n\t*((size_t *)buf) = size;\n\tbuf = (void *) ((char *)buf + 16);\n\n\tvips_tracked_mem += size;\n\tif( vips_tracked_mem > vips_tracked_mem_highwater ) \n\t\tvips_tracked_mem_highwater = vips_tracked_mem;\n\tvips_tracked_allocs += 1;\n\n#ifdef DEBUG_VERBOSE\n\tprintf( \"vips_tracked_malloc: %p, %zd bytes\\n\", buf, size ); \n#endif \/*DEBUG_VERBOSE*\/\n\n\tg_mutex_unlock( vips_tracked_mutex );\n\n\tVIPS_GATE_MALLOC( size ); \n\n        return( buf );\n}\n","idx":182912,"target":1}
{"code":"static void Rp_test(js_State *J)\n {\n \tjs_Regexp *re;\n \tconst char *text;\n \tint opts;\n \tResub m;\n \n\tre = js_toregexp(J, 0);\n\ttext = js_tostring(J, 1);\n\n\topts = 0;\n\tif (re->flags & JS_REGEXP_G) {\n\t\tif (re->last > strlen(text)) {\n\t\t\tre->last = 0;\n\t\t\tjs_pushboolean(J, 0);\n\t\t\treturn;\n\t\t}\n\t\tif (re->last > 0) {\n\t\t\ttext += re->last;\n\t\t\topts |= REG_NOTBOL;\n \t\t}\n \t}\n \n\tif (!js_regexec(re->prog, text, &m, opts)) {\n \t\tif (re->flags & JS_REGEXP_G)\n \t\t\tre->last = re->last + (m.sub[0].ep - text);\n \t\tjs_pushboolean(J, 1);\n\t\treturn;\n\t}\n\n\tif (re->flags & JS_REGEXP_G)\n\t\tre->last = 0;\n\n\tjs_pushboolean(J, 0);\n}\n","idx":182868,"target":1}
{"code":" void js_RegExp_prototype_exec(js_State *J, js_Regexp *re, const char *text)\n {\n \tint i;\n \tint opts;\n \tResub m;\n\n\topts = 0;\n\tif (re->flags & JS_REGEXP_G) {\n\t\tif (re->last > strlen(text)) {\n\t\t\tre->last = 0;\n\t\t\tjs_pushnull(J);\n\t\t\treturn;\n\t\t}\n\t\tif (re->last > 0) {\n\t\t\ttext += re->last;\n\t\t\topts |= REG_NOTBOL;\n \t\t}\n \t}\n \n\tif (!js_regexec(re->prog, text, &m, opts)) {\n \t\tjs_newarray(J);\n \t\tjs_pushstring(J, text);\n \t\tjs_setproperty(J, -2, \"input\");\n\t\tjs_pushnumber(J, js_utfptrtoidx(text, m.sub[0].sp));\n\t\tjs_setproperty(J, -2, \"index\");\n\t\tfor (i = 0; i < m.nsub; ++i) {\n\t\t\tjs_pushlstring(J, m.sub[i].sp, m.sub[i].ep - m.sub[i].sp);\n\t\t\tjs_setindex(J, -2, i);\n\t\t}\n\t\tif (re->flags & JS_REGEXP_G)\n\t\t\tre->last = re->last + (m.sub[0].ep - text);\n\t\treturn;\n\t}\n\n\tif (re->flags & JS_REGEXP_G)\n\t\tre->last = 0;\n\n\tjs_pushnull(J);\n}\n","idx":182869,"target":1}
{"code":"static void Sp_match(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tint len;\n\tconst char *a, *b, *c, *e;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\n\tif (js_isregexp(J, 1))\n\t\tjs_copy(J, 1);\n\telse if (js_isundefined(J, 1))\n\t\tjs_newregexp(J, \"\", 0);\n\telse\n\t\tjs_newregexp(J, js_tostring(J, 1), 0);\n\n\tre = js_toregexp(J, -1);\n\tif (!(re->flags & JS_REGEXP_G)) {\n\t\tjs_RegExp_prototype_exec(J, re, text);\n\t\treturn;\n\t}\n\n\tre->last = 0;\n\n\tjs_newarray(J);\n\n\tlen = 0;\n \ta = text;\n \te = text + strlen(text);\n \twhile (a <= e) {\n\t\tif (js_regexec(re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n \t\t\tbreak;\n \n \t\tb = m.sub[0].sp;\n\t\tc = m.sub[0].ep;\n\n\t\tjs_pushlstring(J, b, c - b);\n\t\tjs_setindex(J, -2, len++);\n\n\t\ta = c;\n\t\tif (c - b == 0)\n\t\t\t++a;\n\t}\n\n\tif (len == 0) {\n\t\tjs_pop(J, 1);\n\t\tjs_pushnull(J);\n\t}\n}\n","idx":182870,"target":1}
{"code":"static void Sp_search(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\n\tif (js_isregexp(J, 1))\n\t\tjs_copy(J, 1);\n\telse if (js_isundefined(J, 1))\n\t\tjs_newregexp(J, \"\", 0);\n\telse\n\t\tjs_newregexp(J, js_tostring(J, 1), 0);\n \n \tre = js_toregexp(J, -1);\n \n\tif (!js_regexec(re->prog, text, &m, 0))\n \t\tjs_pushnumber(J, js_utfptrtoidx(text, m.sub[0].sp));\n \telse\n \t\tjs_pushnumber(J, -1);\n}\n","idx":182872,"target":1}
{"code":"static void Sp_split_regexp(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tint limit, len, k;\n\tconst char *p, *a, *b, *c, *e;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\tre = js_toregexp(J, 1);\n\tlimit = js_isdefined(J, 2) ? js_tointeger(J, 2) : 1 << 30;\n\n\tjs_newarray(J);\n\tlen = 0;\n\n\te = text + strlen(text);\n \n \t\/* splitting the empty string *\/\n \tif (e == text) {\n\t\tif (js_regexec(re->prog, text, &m, 0)) {\n \t\t\tif (len == limit) return;\n \t\t\tjs_pushliteral(J, \"\");\n \t\t\tjs_setindex(J, -2, 0);\n\t\t}\n\t\treturn;\n\t}\n \n \tp = a = text;\n \twhile (a < e) {\n\t\tif (js_regexec(re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n \t\t\tbreak; \/* no match *\/\n \n \t\tb = m.sub[0].sp;\n\t\tc = m.sub[0].ep;\n\n\t\t\/* empty string at end of last match *\/\n\t\tif (b == p) {\n\t\t\t++a;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (len == limit) return;\n\t\tjs_pushlstring(J, p, b - p);\n\t\tjs_setindex(J, -2, len++);\n\n\t\tfor (k = 1; k < m.nsub; ++k) {\n\t\t\tif (len == limit) return;\n\t\t\tjs_pushlstring(J, m.sub[k].sp, m.sub[k].ep - m.sub[k].sp);\n\t\t\tjs_setindex(J, -2, len++);\n\t\t}\n\n\t\ta = p = c;\n\t}\n\n\tif (len == limit) return;\n\tjs_pushstring(J, p);\n\tjs_setindex(J, -2, len);\n}\n","idx":182873,"target":1}
{"code":"int avpriv_ac3_parse_header(AC3HeaderInfo **phdr, const uint8_t *buf,\n                            size_t size)\n{\n    GetBitContext gb;\n    AC3HeaderInfo *hdr;\n    int err;\n\n    if (!*phdr)\n        *phdr = av_mallocz(sizeof(AC3HeaderInfo));\n    if (!*phdr)\n         return AVERROR(ENOMEM);\n     hdr = *phdr;\n \n    init_get_bits8(&gb, buf, size);\n     err = ff_ac3_parse_header(&gb, hdr);\n     if (err < 0)\n         return AVERROR_INVALIDDATA;\n\n    return get_bits_count(&gb);\n}\n","idx":182330,"target":1}
{"code":"void DesktopNativeWidgetHelperAura::PreInitialize(\n    aura::Window* window,\n    const Widget::InitParams& params) {\n#if !defined(OS_WIN)\n  if (params.type == Widget::InitParams::TYPE_POPUP) {\n    is_embedded_window_ = true;\n    position_client_.reset(new EmbeddedWindowScreenPositionClient(widget_));\n    aura::client::SetScreenPositionClient(window, position_client_.get());\n    return;\n  } else if (params.type == Widget::InitParams::TYPE_CONTROL) {\n    return;\n  }\n#endif\n\n  gfx::Rect bounds = params.bounds;\n  if (bounds.IsEmpty()) {\n    bounds.set_size(gfx::Size(100, 100));\n  }\n  root_window_.reset(new aura::RootWindow(bounds));\n  root_window_->Init();\n  root_window_->set_focus_manager(new aura::FocusManager);\n\n  root_window_event_filter_ =\n      new aura::shared::RootWindowEventFilter(root_window_.get());\n   root_window_->SetEventFilter(root_window_event_filter_);\n \n   input_method_filter_.reset(new aura::shared::InputMethodEventFilter());\n   root_window_event_filter_->AddFilter(input_method_filter_.get());\n \n   aura::DesktopActivationClient* activation_client =\n      new aura::DesktopActivationClient(root_window_.get());\n\n#if defined(USE_X11)\n  x11_window_event_filter_.reset(\n      new X11WindowEventFilter(root_window_.get(), activation_client, widget_));\n  x11_window_event_filter_->SetUseHostWindowBorders(false);\n  root_window_event_filter_->AddFilter(x11_window_event_filter_.get());\n#endif\n\n  root_window_->AddRootWindowObserver(this);\n\n  aura::client::SetActivationClient(root_window_.get(), activation_client);\n  aura::client::SetDispatcherClient(root_window_.get(),\n                                    new aura::DesktopDispatcherClient);\n\n  position_client_.reset(\n      new RootWindowScreenPositionClient(root_window_.get()));\n  aura::client::SetScreenPositionClient(window, position_client_.get());\n}\n","idx":184493,"target":1}
{"code":"static int udf_encode_fh(struct inode *inode, __u32 *fh, int *lenp,\n\t\t\t struct inode *parent)\n{\n\tint len = *lenp;\n\tstruct kernel_lb_addr location = UDF_I(inode)->i_location;\n\tstruct fid *fid = (struct fid *)fh;\n\tint type = FILEID_UDF_WITHOUT_PARENT;\n\n\tif (parent && (len < 5)) {\n\t\t*lenp = 5;\n\t\treturn 255;\n\t} else if (len < 3) {\n\t\t*lenp = 3;\n\t\treturn 255;\n\t}\n\n \t*lenp = 3;\n \tfid->udf.block = location.logicalBlockNum;\n \tfid->udf.partref = location.partitionReferenceNum;\n \tfid->udf.generation = inode->i_generation;\n \n \tif (parent) {\n\t\tlocation = UDF_I(parent)->i_location;\n\t\tfid->udf.parent_block = location.logicalBlockNum;\n\t\tfid->udf.parent_partref = location.partitionReferenceNum;\n\t\tfid->udf.parent_generation = inode->i_generation;\n\t\t*lenp = 5;\n\t\ttype = FILEID_UDF_WITH_PARENT;\n\t}\n\n\treturn type;\n}\n","idx":179350,"target":1}
{"code":"void close_all_sockets(atransport* t) {\n    asocket* s;\n\n \/* this is a little gross, but since s->close() *will* modify\n    ** the list out from under you, your options are limited.\n    *\/\n    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);\n\n restart:\n     for (s = local_socket_list.next; s != &local_socket_list; s = s->next) {\n         if (s->transport == t || (s->peer && s->peer->transport == t)) {\n            local_socket_close(s);\n             goto restart;\n         }\n     }\n}\n","idx":187427,"target":1}
{"code":"do_uncompress( compress_filter_context_t *zfx, z_stream *zs,\n               IOBUF a, size_t *ret_len )\n {\n     int zrc;\n    int rc=0;\n     size_t n;\n     int nread, count;\n     int refill = !zs->avail_in;\n    if( DBG_FILTER )\n\tlog_debug(\"begin inflate: avail_in=%u, avail_out=%u, inbuf=%u\\n\",\n\t\t(unsigned)zs->avail_in, (unsigned)zs->avail_out,\n\t\t(unsigned)zfx->inbufsize );\n    do {\n\tif( zs->avail_in < zfx->inbufsize && refill ) {\n\t    n = zs->avail_in;\n\t    if( !n )\n            zs->next_in = BYTEF_CAST (zfx->inbuf);\n\t    count = zfx->inbufsize - n;\n\t    nread = iobuf_read( a, zfx->inbuf + n, count );\n            nread = iobuf_read( a, zfx->inbuf + n, count );\n            if( nread == -1 ) nread = 0;\n            n += nread;\n           \/* If we use the undocumented feature to suppress\n            * the zlib header, we have to give inflate an\n            * extra dummy byte to read *\/\n           if( nread < count && zfx->algo == 1 ) {\n               *(zfx->inbuf + n) = 0xFF; \/* is it really needed ? *\/\n               zfx->algo1hack = 1;\n                n++;\n            }\n            zs->avail_in = n;\n        }\n\t    log_debug(\"enter inflate: avail_in=%u, avail_out=%u\\n\",\n\t\t    (unsigned)zs->avail_in, (unsigned)zs->avail_out);\n\tzrc = inflate ( zs, Z_SYNC_FLUSH );\n\tif( DBG_FILTER )\n\t    log_debug(\"leave inflate: avail_in=%u, avail_out=%u, zrc=%d\\n\",\n\t\t   (unsigned)zs->avail_in, (unsigned)zs->avail_out, zrc);\n\tif( zrc == Z_STREAM_END )\n\t    rc = -1; \/* eof *\/\n\telse if( zrc != Z_OK && zrc != Z_BUF_ERROR ) {\n\t    if( zs->msg )\n\t\tlog_fatal(\"zlib inflate problem: %s\\n\", zs->msg );\n\t    else\n\t\tlog_fatal(\"zlib inflate problem: rc=%d\\n\", zrc );\n            else\n                log_fatal(\"zlib inflate problem: rc=%d\\n\", zrc );\n        }\n    } while( zs->avail_out && zrc != Z_STREAM_END && zrc != Z_BUF_ERROR );\n \n     *ret_len = zfx->outbufsize - zs->avail_out;\n     if( DBG_FILTER )\n}\n","idx":178225,"target":1}
{"code":"bool TabsCaptureVisibleTabFunction::RunImpl() {\n  PrefService* service = profile()->GetPrefs();\n  if (service->GetBoolean(prefs::kDisableScreenshots)) {\n    error_ = keys::kScreenshotsDisabled;\n    return false;\n  }\n\n  WebContents* web_contents = NULL;\n  if (!GetTabToCapture(&web_contents))\n    return false;\n\n  image_format_ = FORMAT_JPEG;  \/\/ Default format is JPEG.\n  image_quality_ = kDefaultQuality;  \/\/ Default quality setting.\n\n  if (HasOptionalArgument(1)) {\n    DictionaryValue* options = NULL;\n    EXTENSION_FUNCTION_VALIDATE(args_->GetDictionary(1, &options));\n\n    if (options->HasKey(keys::kFormatKey)) {\n      std::string format;\n      EXTENSION_FUNCTION_VALIDATE(\n          options->GetString(keys::kFormatKey, &format));\n\n      if (format == keys::kFormatValueJpeg) {\n        image_format_ = FORMAT_JPEG;\n      } else if (format == keys::kFormatValuePng) {\n        image_format_ = FORMAT_PNG;\n      } else {\n        EXTENSION_FUNCTION_VALIDATE(0);\n      }\n    }\n\n    if (options->HasKey(keys::kQualityKey)) {\n      EXTENSION_FUNCTION_VALIDATE(\n          options->GetInteger(keys::kQualityKey, &image_quality_));\n     }\n   }\n \n  if (!GetExtension()->CanCaptureVisiblePage(\n        web_contents->GetURL(),\n        SessionID::IdForTab(web_contents),\n        &error_)) {\n     return false;\n   }\n \n  RenderViewHost* render_view_host = web_contents->GetRenderViewHost();\n  content::RenderWidgetHostView* view = render_view_host->GetView();\n  if (!view) {\n    error_ = keys::kInternalVisibleTabCaptureError;\n    return false;\n  }\n  render_view_host->CopyFromBackingStore(\n      gfx::Rect(),\n      view->GetViewBounds().size(),\n      base::Bind(&TabsCaptureVisibleTabFunction::CopyFromBackingStoreComplete,\n                 this));\n  return true;\n}\n","idx":184960,"target":1}
{"code":" static int kvm_vm_ioctl_set_pit(struct kvm *kvm, struct kvm_pit_state *ps)\n {\n \tmutex_lock(&kvm->arch.vpit->pit_state.lock);\n \tmemcpy(&kvm->arch.vpit->pit_state, ps, sizeof(struct kvm_pit_state));\n\tkvm_pit_load_count(kvm, 0, ps->channels[0].count, 0);\n \tmutex_unlock(&kvm->arch.vpit->pit_state.lock);\n \treturn 0;\n }\n","idx":180732,"target":1}
{"code":" static int kvm_vm_ioctl_set_pit2(struct kvm *kvm, struct kvm_pit_state2 *ps)\n {\n \tint start = 0;\n \tu32 prev_legacy, cur_legacy;\n \tmutex_lock(&kvm->arch.vpit->pit_state.lock);\n \tprev_legacy = kvm->arch.vpit->pit_state.flags & KVM_PIT_FLAGS_HPET_LEGACY;\n\tcur_legacy = ps->flags & KVM_PIT_FLAGS_HPET_LEGACY;\n\tif (!prev_legacy && cur_legacy)\n\t\tstart = 1;\n \tmemcpy(&kvm->arch.vpit->pit_state.channels, &ps->channels,\n \t       sizeof(kvm->arch.vpit->pit_state.channels));\n \tkvm->arch.vpit->pit_state.flags = ps->flags;\n\tkvm_pit_load_count(kvm, 0, kvm->arch.vpit->pit_state.channels[0].count, start);\n \tmutex_unlock(&kvm->arch.vpit->pit_state.lock);\n \treturn 0;\n }\n","idx":180733,"target":1}
{"code":"  void Reset() {\n    events_.clear();\n    tap_ = false;\n    tap_down_ = false;\n    tap_cancel_ = false;\n    begin_ = false;\n    end_ = false;\n    scroll_begin_ = false;\n    scroll_update_ = false;\n    scroll_end_ = false;\n    pinch_begin_ = false;\n    pinch_update_ = false;\n    pinch_end_ = false;\n    long_press_ = false;\n    fling_ = false;\n    two_finger_tap_ = false;\n    show_press_ = false;\n    swipe_left_ = false;\n    swipe_right_ = false;\n    swipe_up_ = false;\n    swipe_down_ = false;\n\n    scroll_begin_position_.SetPoint(0, 0);\n    tap_location_.SetPoint(0, 0);\n    gesture_end_location_.SetPoint(0, 0);\n\n    scroll_x_ = 0;\n    scroll_y_ = 0;\n    scroll_velocity_x_ = 0;\n    scroll_velocity_y_ = 0;\n    velocity_x_ = 0;\n    velocity_y_ = 0;\n    scroll_x_hint_ = 0;\n    scroll_y_hint_ = 0;\n     tap_count_ = 0;\n     scale_ = 0;\n     flags_ = 0;\n   }\n","idx":184895,"target":1}
{"code":" void GestureProviderAura::OnGestureEvent(\n    const GestureEventData& gesture) {\n  GestureEventDetails details = gesture.details;\n\n  if (gesture.type == ET_GESTURE_TAP) {\n    int tap_count = 1;\n    if (previous_tap_ && IsConsideredDoubleTap(*previous_tap_, gesture))\n      tap_count = 1 + (previous_tap_->details.tap_count() % 3);\n    details.set_tap_count(tap_count);\n    if (!previous_tap_)\n      previous_tap_.reset(new GestureEventData(gesture));\n    else\n      *previous_tap_ = gesture;\n    previous_tap_->details = details;\n  } else if (gesture.type == ET_GESTURE_TAP_CANCEL) {\n    previous_tap_.reset();\n  }\n\n  scoped_ptr<ui::GestureEvent> event(\n      new ui::GestureEvent(gesture.type,\n                           gesture.x,\n                           gesture.y,\n                           last_touch_event_flags_,\n                           gesture.time - base::TimeTicks(),\n                           details,\n                            1 << gesture.motion_event_id));\n \n   if (!handling_event_) {\n     client_->OnGestureEvent(event.get());\n  } else {\n    pending_gestures_.push_back(event.release());\n  }\n}\n","idx":184896,"target":1}
{"code":" bool GestureProviderAura::OnTouchEvent(const TouchEvent& event) {\n  last_touch_event_flags_ = event.flags();\n   bool pointer_id_is_active = false;\n   for (size_t i = 0; i < pointer_state_.GetPointerCount(); ++i) {\n     if (event.touch_id() != pointer_state_.GetPointerId(i))\n      continue;\n    pointer_id_is_active = true;\n    break;\n  }\n\n  if (event.type() == ET_TOUCH_PRESSED && pointer_id_is_active) {\n    return false;\n  } else if (event.type() != ET_TOUCH_PRESSED && !pointer_id_is_active) {\n     return false;\n   }\n \n   pointer_state_.OnTouch(event);\n \n   bool result = filtered_gesture_provider_.OnTouchEvent(pointer_state_);\n  pointer_state_.CleanupRemovedTouchPoints(event);\n  return result;\n}\n","idx":184897,"target":1}
{"code":"void GestureProviderAura::OnTouchEventAck(bool event_consumed) {\n  DCHECK(pending_gestures_.empty());\n   DCHECK(!handling_event_);\n   base::AutoReset<bool> handling_event(&handling_event_, true);\n   filtered_gesture_provider_.OnTouchEventAck(event_consumed);\n }\n","idx":184898,"target":1}
{"code":"void NotificationService::RemoveObserver(NotificationObserver* observer,\n                                          NotificationType type,\n                                          const NotificationSource& source) {\n   DCHECK(type.value < NotificationType::NOTIFICATION_TYPE_COUNT);\n  DCHECK(HasKey(observers_[type.value], source));\n \n   NotificationObserverList* observer_list =\n       observers_[type.value][source.map_key()];\n  if (observer_list) {\n    observer_list->RemoveObserver(observer);\n#ifndef NDEBUG\n    --observer_counts_[type.value];\n#endif\n  }\n\n}\n","idx":183605,"target":1}
{"code":"void DownloadRequestLimiter::TabDownloadState::DidFinishNavigation(\n    content::NavigationHandle* navigation_handle) {\n  if (!navigation_handle->IsInMainFrame())\n    return;\n\n   if (status_ == ALLOW_ONE_DOWNLOAD ||\n       (status_ == PROMPT_BEFORE_DOWNLOAD &&\n       !navigation_handle->IsRendererInitiated())) {\n    NotifyCallbacks(false);\n    host_->Remove(this, web_contents());\n  }\n}\n","idx":187179,"target":1}
{"code":"void DownloadRequestLimiter::TabDownloadState::DidStartNavigation(\n    content::NavigationHandle* navigation_handle) {\n  if (!navigation_handle->IsInMainFrame())\n    return;\n\n   download_seen_ = false;\n   ui_status_ = DOWNLOAD_UI_DEFAULT;\n \n  if (navigation_handle->IsRendererInitiated() &&\n      (status_ == PROMPT_BEFORE_DOWNLOAD || status_ == DOWNLOADS_NOT_ALLOWED)) {\n    return;\n   }\n \n   if (status_ == DownloadRequestLimiter::ALLOW_ALL_DOWNLOADS ||\n      status_ == DownloadRequestLimiter::DOWNLOADS_NOT_ALLOWED) {\n    if (!initial_page_host_.empty() &&\n        navigation_handle->GetURL().host_piece() == initial_page_host_) {\n      return;\n    }\n  }\n\n  NotifyCallbacks(false);\n  host_->Remove(this, web_contents());\n}\n","idx":187180,"target":1}
{"code":"void DownloadRequestLimiter::TabDownloadState::SetDownloadStatusAndNotifyImpl(\n    DownloadStatus status,\n    ContentSetting setting) {\n  DCHECK((GetSettingFromDownloadStatus(status) == setting) ||\n         (GetDownloadStatusFromSetting(setting) == status))\n      << \"status \" << status << \" and setting \" << setting\n      << \" do not correspond to each other\";\n\n  ContentSetting last_setting = GetSettingFromDownloadStatus(status_);\n  DownloadUiStatus last_ui_status = ui_status_;\n\n  status_ = status;\n  ui_status_ = GetUiStatusFromDownloadStatus(status_, download_seen_);\n\n   if (!web_contents())\n     return;\n \n  if (last_setting == setting && last_ui_status == ui_status_)\n    return;\n\n  content::NotificationService::current()->Notify(\n      chrome::NOTIFICATION_WEB_CONTENT_SETTINGS_CHANGED,\n      content::Source<content::WebContents>(web_contents()),\n       content::NotificationService::NoDetails());\n }\n","idx":187181,"target":1}
{"code":"bool Performance::PassesTimingAllowCheck(\n    const ResourceResponse& response,\n     const SecurityOrigin& initiator_security_origin,\n     const AtomicString& original_timing_allow_origin,\n     ExecutionContext* context) {\n   scoped_refptr<const SecurityOrigin> resource_origin =\n      SecurityOrigin::Create(response.Url());\n   if (resource_origin->IsSameSchemeHostPort(&initiator_security_origin))\n     return true;\n \n  const AtomicString& timing_allow_origin_string =\n      original_timing_allow_origin.IsEmpty()\n          ? response.HttpHeaderField(HTTPNames::Timing_Allow_Origin)\n          : original_timing_allow_origin;\n  if (timing_allow_origin_string.IsEmpty() ||\n      EqualIgnoringASCIICase(timing_allow_origin_string, \"null\"))\n    return false;\n\n  if (timing_allow_origin_string == \"*\") {\n    UseCounter::Count(context, WebFeature::kStarInTimingAllowOrigin);\n    return true;\n  }\n\n  const String& security_origin = initiator_security_origin.ToString();\n  Vector<String> timing_allow_origins;\n  timing_allow_origin_string.GetString().Split(',', timing_allow_origins);\n  if (timing_allow_origins.size() > 1) {\n    UseCounter::Count(context, WebFeature::kMultipleOriginsInTimingAllowOrigin);\n  } else if (timing_allow_origins.size() == 1 &&\n             timing_allow_origin_string != \"*\") {\n    UseCounter::Count(context, WebFeature::kSingleOriginInTimingAllowOrigin);\n  }\n  for (const String& allow_origin : timing_allow_origins) {\n    const String allow_origin_stripped = allow_origin.StripWhiteSpace();\n    if (allow_origin_stripped == security_origin ||\n        allow_origin_stripped == \"*\") {\n      return true;\n    }\n  }\n\n  return false;\n}\n","idx":187127,"target":1}
{"code":"bool PDFiumEngine::HandleEvent(const pp::InputEvent& event) {\n  DCHECK(!defer_page_unload_);\n  defer_page_unload_ = true;\n  bool rv = false;\n  switch (event.GetType()) {\n    case PP_INPUTEVENT_TYPE_MOUSEDOWN:\n      rv = OnMouseDown(pp::MouseInputEvent(event));\n      break;\n    case PP_INPUTEVENT_TYPE_MOUSEUP:\n      rv = OnMouseUp(pp::MouseInputEvent(event));\n      break;\n    case PP_INPUTEVENT_TYPE_MOUSEMOVE:\n      rv = OnMouseMove(pp::MouseInputEvent(event));\n      break;\n    case PP_INPUTEVENT_TYPE_KEYDOWN:\n      rv = OnKeyDown(pp::KeyboardInputEvent(event));\n      break;\n    case PP_INPUTEVENT_TYPE_KEYUP:\n      rv = OnKeyUp(pp::KeyboardInputEvent(event));\n      break;\n    case PP_INPUTEVENT_TYPE_CHAR:\n      rv = OnChar(pp::KeyboardInputEvent(event));\n      break;\n    case PP_INPUTEVENT_TYPE_TOUCHSTART: {\n      KillTouchTimer(next_touch_timer_id_);\n\n      pp::TouchInputEvent touch_event(event);\n      if (touch_event.GetTouchCount(PP_TOUCHLIST_TYPE_TARGETTOUCHES) == 1)\n        ScheduleTouchTimer(touch_event);\n      break;\n    }\n    case PP_INPUTEVENT_TYPE_TOUCHEND:\n      KillTouchTimer(next_touch_timer_id_);\n      break;\n    case PP_INPUTEVENT_TYPE_TOUCHMOVE:\n      KillTouchTimer(next_touch_timer_id_);\n    default:\n      break;\n  }\n \n   DCHECK(defer_page_unload_);\n   defer_page_unload_ = false;\n  for (int page_index : deferred_page_unloads_)\n     pages_[page_index]->Unload();\n  deferred_page_unloads_.clear();\n   return rv;\n }\n","idx":186642,"target":1}
{"code":"static int __init fm10k_init_module(void)\n{\n\tpr_info(\"%s - version %s\\n\", fm10k_driver_string, fm10k_driver_version);\n\tpr_info(\"%s\\n\", fm10k_copyright);\n\n \t\/* create driver workqueue *\/\n \tfm10k_workqueue = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0,\n \t\t\t\t\t  fm10k_driver_name);\n \n \tfm10k_dbg_init();\n \n\treturn fm10k_register_pci_driver();\n}\n","idx":182688,"target":1}
{"code":"UWORD32 ihevcd_cabac_decode_bypass_bins_egk(cab_ctxt_t *ps_cabac,\n bitstrm_t *ps_bitstrm,\n                                            WORD32 k)\n{\n\n    UWORD32 u4_sym;\n    WORD32 numones;\n    WORD32 bin;\n\n \/* Sanity checks *\/\n    ASSERT((k >= 0));\n\n\n     numones = k;\n     bin = 1;\n     u4_sym = 0;\n    while(bin)\n     {\n         IHEVCD_CABAC_DECODE_BYPASS_BIN(bin, ps_cabac, ps_bitstrm);\n         u4_sym += bin << numones++;\n     }\n \n     numones -= 1;\n    numones = CLIP3(numones, 0, 16);\n \n     if(numones)\n     {\n        UWORD32 u4_suffix;\n\n        IHEVCD_CABAC_DECODE_BYPASS_BINS(u4_suffix, ps_cabac, ps_bitstrm, numones);\n        u4_sym += u4_suffix;\n }\n return (u4_sym);\n}\n","idx":188073,"target":1}
{"code":"static PassRefPtr<CSSValue> getPositionOffsetValue(RenderStyle* style, CSSPropertyID propertyID, RenderView* renderView)\n{\n    if (!style)\n        return 0;\n\n    Length l;\n    switch (propertyID) {\n        case CSSPropertyLeft:\n            l = style->left();\n            break;\n        case CSSPropertyRight:\n            l = style->right();\n            break;\n        case CSSPropertyTop:\n            l = style->top();\n            break;\n        case CSSPropertyBottom:\n            l = style->bottom();\n            break;\n        default:\n            return 0;\n    }\n\n    if (style->position() == AbsolutePosition || style->position() == FixedPosition) {\n        if (l.type() == WebCore::Fixed)\n            return zoomAdjustedPixelValue(l.value(), style);\n        else if (l.isViewportPercentage())\n            return zoomAdjustedPixelValue(valueForLength(l, 0, renderView), style);\n         return cssValuePool().createValue(l);\n     }\n \n    if (style->position() == RelativePosition)\n         return cssValuePool().createValue(l);\n \n     return cssValuePool().createIdentifierValue(CSSValueAuto);\n }\n","idx":183823,"target":1}
{"code":"CWD_API void realpath_cache_del(const char *path, int path_len TSRMLS_DC) \/* {{{ *\/\n{\n#ifdef PHP_WIN32\n\tunsigned long key = realpath_cache_key(path, path_len TSRMLS_CC);\n#else\n\tunsigned long key = realpath_cache_key(path, path_len);\n#endif\n\tunsigned long n = key % (sizeof(CWDG(realpath_cache)) \/ sizeof(CWDG(realpath_cache)[0]));\n\trealpath_cache_bucket **bucket = &CWDG(realpath_cache)[n];\n\n\twhile (*bucket != NULL) {\n\t\tif (key == (*bucket)->key && path_len == (*bucket)->path_len &&\n                                        memcmp(path, (*bucket)->path, path_len) == 0) {\n                        realpath_cache_bucket *r = *bucket;\n                        *bucket = (*bucket)->next;\n                        \/* if the pointers match then only subtract the length of the path *\/\n                        if(r->path == r->realpath) {\n                                CWDG(realpath_cache_size) -= sizeof(realpath_cache_bucket) + r->path_len + 1;\n                        } else {\n                                CWDG(realpath_cache_size) -= sizeof(realpath_cache_bucket) + r->path_len + 1 + r->realpath_len + 1;\n                        }\n                        free(r);\n                        return;\n                } else {\n\t\t\tbucket = &(*bucket)->next;\n\t\t}\n\t}\n}\n\/* }}} *\/\n","idx":178154,"target":1}
{"code":"XSLStyleSheet::XSLStyleSheet(XSLImportRule* parentRule, const String& originalURL, const KURL& finalURL)\n    : m_ownerNode(0)\n    , m_originalURL(originalURL)\n    , m_finalURL(finalURL)\n    , m_isDisabled(false)\n    , m_embedded(false)\n     , m_processed(false) \/\/ Child sheets get marked as processed when the libxslt engine has finally seen them.\n     , m_stylesheetDoc(0)\n     , m_stylesheetDocTaken(false)\n     , m_parentStyleSheet(parentRule ? parentRule->parentStyleSheet() : 0)\n {\n }\n","idx":184875,"target":1}
{"code":"XSLStyleSheet::XSLStyleSheet(Node* parentNode, const String& originalURL, const KURL& finalURL,  bool embedded)\n    : m_ownerNode(parentNode)\n    , m_originalURL(originalURL)\n    , m_finalURL(finalURL)\n    , m_isDisabled(false)\n    , m_embedded(embedded)\n     , m_processed(true) \/\/ The root sheet starts off processed.\n     , m_stylesheetDoc(0)\n     , m_stylesheetDocTaken(false)\n     , m_parentStyleSheet(0)\n {\n }\n","idx":184876,"target":1}
{"code":"xsltStylesheetPtr XSLStyleSheet::compileStyleSheet()\n{\n     if (m_embedded)\n         return xsltLoadStylesheetPI(document());\n \n     ASSERT(!m_stylesheetDocTaken);\n     xsltStylesheetPtr result = xsltParseStylesheetDoc(m_stylesheetDoc);\n     if (result)\n         m_stylesheetDocTaken = true;\n     return result;\n }\n","idx":184877,"target":1}
{"code":"static PixelChannels **AcquirePixelThreadSet(const Image *images)\n{\n  const Image\n    *next;\n\n  PixelChannels\n    **pixels;\n\n  register ssize_t\n    i;\n \n   size_t\n     columns,\n    number_threads;\n \n  number_threads=(size_t) GetMagickResourceLimit(ThreadResource);\n  pixels=(PixelChannels **) AcquireQuantumMemory(number_threads,\n    sizeof(*pixels));\n   if (pixels == (PixelChannels **) NULL)\n     return((PixelChannels **) NULL);\n  (void) memset(pixels,0,number_threads*sizeof(*pixels));\n  columns=images->columns;\n   for (next=images; next != (Image *) NULL; next=next->next)\n     columns=MagickMax(next->columns,columns);\n  for (i=0; i < (ssize_t) number_threads; i++)\n   {\n     register ssize_t\n       j;\n\n    pixels[i]=(PixelChannels *) AcquireQuantumMemory(columns,sizeof(**pixels));\n    if (pixels[i] == (PixelChannels *) NULL)\n      return(DestroyPixelThreadSet(pixels));\n    for (j=0; j < (ssize_t) columns; j++)\n    {\n      register ssize_t\n        k;\n\n      for (k=0; k < MaxPixelChannels; k++)\n        pixels[i][j].channel[k]=0.0;\n    }\n  }\n  return(pixels);\n}\n","idx":183373,"target":1}
{"code":"bool BaseSessionService::RestoreUpdateTabNavigationCommand(\n    const SessionCommand& command,\n    TabNavigation* navigation,\n    SessionID::id_type* tab_id) {\n  scoped_ptr<Pickle> pickle(command.PayloadAsPickle());\n  if (!pickle.get())\n    return false;\n  void* iterator = NULL;\n  std::string url_spec;\n  if (!pickle->ReadInt(&iterator, tab_id) ||\n      !pickle->ReadInt(&iterator, &(navigation->index_)) ||\n      !pickle->ReadString(&iterator, &url_spec) ||\n      !pickle->ReadString16(&iterator, &(navigation->title_)) ||\n      !pickle->ReadString(&iterator, &(navigation->state_)) ||\n      !pickle->ReadInt(&iterator,\n                       reinterpret_cast<int*>(&(navigation->transition_))))\n    return false;\n  bool has_type_mask = pickle->ReadInt(&iterator, &(navigation->type_mask_));\n\n  if (has_type_mask) {\n    std::string referrer_spec;\n    pickle->ReadString(&iterator, &referrer_spec);\n    int policy_int;\n    WebReferrerPolicy policy;\n    if (pickle->ReadInt(&iterator, &policy_int))\n      policy = static_cast<WebReferrerPolicy>(policy_int);\n    else\n      policy = WebKit::WebReferrerPolicyDefault;\n    navigation->referrer_ = content::Referrer(\n        referrer_spec.empty() ? GURL() : GURL(referrer_spec),\n         policy);\n \n     std::string content_state;\n     if (CompressDataHelper::ReadAndDecompressStringFromPickle(\n             *pickle.get(), &iterator, &content_state) &&\n         !content_state.empty()) {\n       navigation->state_ = content_state;\n     }\n   }\n \n   navigation->virtual_url_ = GURL(url_spec);\n  return true;\n}\n","idx":184742,"target":1}
{"code":"    CreateFileHelper(PassRefPtrWillBeRawPtr<CreateFileResult> result, const String& name, const KURL& url, FileSystemType type)\n         : m_result(result)\n         , m_name(name)\n         , m_url(url)\n         , m_type(type)\n     {\n     }\n","idx":185110,"target":1}
{"code":"        static PassRefPtrWillBeRawPtr<CreateFileResult> create()\n         {\n            return adoptRefWillBeNoop(new CreateFileResult());\n         }\n","idx":185111,"target":1}
{"code":"    static PassOwnPtr<AsyncFileSystemCallbacks> create(PassRefPtrWillBeRawPtr<CreateFileResult> result, const String& name, const KURL& url, FileSystemType type)\n     {\n         return adoptPtr(static_cast<AsyncFileSystemCallbacks*>(new CreateFileHelper(result, name, url, type)));\n     }\n","idx":185112,"target":1}
{"code":" PassRefPtrWillBeRawPtr<File> DOMFileSystemSync::createFile(const FileEntrySync* fileEntry, ExceptionState& exceptionState)\n {\n     KURL fileSystemURL = createFileSystemURL(fileEntry);\n    RefPtrWillBeRawPtr<CreateFileHelper::CreateFileResult> result(CreateFileHelper::CreateFileResult::create());\n     fileSystem()->createSnapshotFileAndReadMetadata(fileSystemURL, CreateFileHelper::create(result, fileEntry->name(), fileSystemURL, type()));\n     if (result->m_failed) {\n         exceptionState.throwDOMException(result->m_code, \"Could not create '\" + fileEntry->name() + \"'.\");\n        return nullptr;\n    }\n    return result->m_file.get();\n}\n","idx":185113,"target":1}
{"code":"        ~CreateFileResult()\n        {\n        }\n","idx":185114,"target":1}
{"code":" DirectoryEntrySync* DirectoryEntrySync::getDirectory(const String& path, const Dictionary& options, ExceptionState& exceptionState)\n {\n     FileSystemFlags flags(options);\n    RefPtr<EntrySyncCallbackHelper> helper = EntrySyncCallbackHelper::create();\n     m_fileSystem->getDirectory(this, path, flags, helper->successCallback(), helper->errorCallback(), DOMFileSystemBase::Synchronous);\n     return static_cast<DirectoryEntrySync*>(helper->getResult(exceptionState));\n }\n","idx":185115,"target":1}
{"code":" void DirectoryEntrySync::removeRecursively(ExceptionState& exceptionState)\n {\n    RefPtr<VoidSyncCallbackHelper> helper = VoidSyncCallbackHelper::create();\n     m_fileSystem->removeRecursively(this, helper->successCallback(), helper->errorCallback(), DOMFileSystemBase::Synchronous);\n     helper->getResult(exceptionState);\n }\n","idx":185117,"target":1}
{"code":" EntrySync* EntrySync::copyTo(DirectoryEntrySync* parent, const String& name, ExceptionState& exceptionState) const\n {\n    RefPtr<EntrySyncCallbackHelper> helper = EntrySyncCallbackHelper::create();\n     m_fileSystem->copy(this, parent, name, helper->successCallback(), helper->errorCallback(), DOMFileSystemBase::Synchronous);\n     return helper->getResult(exceptionState);\n }\n","idx":185118,"target":1}
{"code":" Metadata* EntrySync::getMetadata(ExceptionState& exceptionState)\n {\n    RefPtr<MetadataSyncCallbackHelper> helper = MetadataSyncCallbackHelper::create();\n     m_fileSystem->getMetadata(this, helper->successCallback(), helper->errorCallback(), DOMFileSystemBase::Synchronous);\n     return helper->getResult(exceptionState);\n }\n","idx":185119,"target":1}
{"code":"void LocalFileSystem::deleteFileSystem(ExecutionContext* context, FileSystemType type, PassOwnPtr<AsyncFileSystemCallbacks> callbacks)\n{\n    RefPtrWillBeRawPtr<ExecutionContext> contextPtr(context);\n     ASSERT(context);\n     ASSERT_WITH_SECURITY_IMPLICATION(context->isDocument());\n \n    RefPtr<CallbackWrapper> wrapper = adoptRef(new CallbackWrapper(callbacks));\n     requestFileSystemAccessInternal(context,\n         bind(&LocalFileSystem::deleteFileSystemInternal, this, contextPtr, type, wrapper),\n         bind(&LocalFileSystem::fileSystemNotAllowedInternal, this, contextPtr, wrapper));\n}\n","idx":185122,"target":1}
{"code":" void LocalFileSystem::deleteFileSystemInternal(\n     PassRefPtrWillBeRawPtr<ExecutionContext> context,\n     FileSystemType type,\n    PassRefPtr<CallbackWrapper> callbacks)\n {\n     if (!fileSystem()) {\n         fileSystemNotAvailable(context, callbacks);\n        return;\n    }\n    KURL storagePartition = KURL(KURL(), context->securityOrigin()->toString());\n    fileSystem()->deleteFileSystem(storagePartition, static_cast<WebFileSystemType>(type), callbacks->release());\n}\n","idx":185123,"target":1}
{"code":" void LocalFileSystem::fileSystemNotAllowedInternal(\n     PassRefPtrWillBeRawPtr<ExecutionContext> context,\n    PassRefPtr<CallbackWrapper> callbacks)\n {\n     context->postTask(createCrossThreadTask(&reportFailure, callbacks->release(), FileError::ABORT_ERR));\n }\n","idx":185125,"target":1}
{"code":" void LocalFileSystem::requestFileSystem(ExecutionContext* context, FileSystemType type, long long size, PassOwnPtr<AsyncFileSystemCallbacks> callbacks)\n {\n     RefPtrWillBeRawPtr<ExecutionContext> contextPtr(context);\n    RefPtr<CallbackWrapper> wrapper = adoptRef(new CallbackWrapper(callbacks));\n     requestFileSystemAccessInternal(context,\n         bind(&LocalFileSystem::fileSystemAllowedInternal, this, contextPtr, type, wrapper),\n         bind(&LocalFileSystem::fileSystemNotAllowedInternal, this, contextPtr, wrapper));\n}\n","idx":185127,"target":1}
{"code":" void LocalFileSystem::resolveURL(ExecutionContext* context, const KURL& fileSystemURL, PassOwnPtr<AsyncFileSystemCallbacks> callbacks)\n {\n     RefPtrWillBeRawPtr<ExecutionContext> contextPtr(context);\n    RefPtr<CallbackWrapper> wrapper = adoptRef(new CallbackWrapper(callbacks));\n     requestFileSystemAccessInternal(context,\n         bind(&LocalFileSystem::resolveURLInternal, this, contextPtr, fileSystemURL, wrapper),\n         bind(&LocalFileSystem::fileSystemNotAllowedInternal, this, contextPtr, wrapper));\n}\n","idx":185128,"target":1}
{"code":" void LocalFileSystem::resolveURLInternal(\n     PassRefPtrWillBeRawPtr<ExecutionContext> context,\n     const KURL& fileSystemURL,\n    PassRefPtr<CallbackWrapper> callbacks)\n {\n     if (!fileSystem()) {\n         fileSystemNotAvailable(context, callbacks);\n        return;\n    }\n    fileSystem()->resolveURL(fileSystemURL, callbacks->release());\n}\n","idx":185129,"target":1}
{"code":"DOMFileSystemSync* WorkerGlobalScopeFileSystem::webkitRequestFileSystemSync(WorkerGlobalScope& worker, int type, long long size, ExceptionState& exceptionState)\n{\n    ExecutionContext* secureContext = worker.executionContext();\n    if (!secureContext->securityOrigin()->canAccessFileSystem()) {\n        exceptionState.throwSecurityError(FileError::securityErrorMessage);\n        return 0;\n    }\n\n    FileSystemType fileSystemType = static_cast<FileSystemType>(type);\n    if (!DOMFileSystemBase::isValidType(fileSystemType)) {\n        exceptionState.throwDOMException(InvalidModificationError, \"the type must be TEMPORARY or PERSISTENT.\");\n         return 0;\n     }\n \n    RefPtr<FileSystemSyncCallbackHelper> helper = FileSystemSyncCallbackHelper::create();\n     OwnPtr<AsyncFileSystemCallbacks> callbacks = FileSystemCallbacks::create(helper->successCallback(), helper->errorCallback(), &worker, fileSystemType);\n     callbacks->setShouldBlockUntilCompletion(true);\n \n    LocalFileSystem::from(worker)->requestFileSystem(&worker, fileSystemType, size, callbacks.release());\n    return helper->getResult(exceptionState);\n}\n","idx":185130,"target":1}
{"code":"EntrySync* WorkerGlobalScopeFileSystem::webkitResolveLocalFileSystemSyncURL(WorkerGlobalScope& worker, const String& url, ExceptionState& exceptionState)\n{\n    KURL completedURL = worker.completeURL(url);\n    ExecutionContext* secureContext = worker.executionContext();\n    if (!secureContext->securityOrigin()->canAccessFileSystem() || !secureContext->securityOrigin()->canRequest(completedURL)) {\n        exceptionState.throwSecurityError(FileError::securityErrorMessage);\n        return 0;\n    }\n\n    if (!completedURL.isValid()) {\n        exceptionState.throwDOMException(EncodingError, \"the URL '\" + url + \"' is invalid.\");\n         return 0;\n     }\n \n    RefPtr<EntrySyncCallbackHelper> resolveURLHelper = EntrySyncCallbackHelper::create();\n     OwnPtr<AsyncFileSystemCallbacks> callbacks = ResolveURICallbacks::create(resolveURLHelper->successCallback(), resolveURLHelper->errorCallback(), &worker);\n     callbacks->setShouldBlockUntilCompletion(true);\n \n    LocalFileSystem::from(worker)->resolveURL(&worker, completedURL, callbacks.release());\n\n    return resolveURLHelper->getResult(exceptionState);\n}\n","idx":185131,"target":1}
{"code":"static int snd_seq_ioctl_remove_events(struct snd_seq_client *client,\n\t\t\t\t       void __user *arg)\n{\n\tstruct snd_seq_remove_events info;\n\n\tif (copy_from_user(&info, arg, sizeof(info)))\n\t\treturn -EFAULT;\n\n\t\/*\n\t * Input mostly not implemented XXX.\n\t *\/\n\tif (info.remove_mode & SNDRV_SEQ_REMOVE_INPUT) {\n\t\t\/*\n \t\t * No restrictions so for a user client we can clear\n \t\t * the whole fifo\n \t\t *\/\n\t\tif (client->type == USER_CLIENT)\n \t\t\tsnd_seq_fifo_clear(client->data.user.fifo);\n \t}\n \n\tif (info.remove_mode & SNDRV_SEQ_REMOVE_OUTPUT)\n\t\tsnd_seq_queue_remove_cells(client->number, &info);\n\n\treturn 0;\n}\n","idx":180582,"target":1}
{"code":" bool SVGElement::HasSVGParent() const {\n  return ParentOrShadowHostElement() &&\n         ParentOrShadowHostElement()->IsSVGElement();\n }\n","idx":187049,"target":1}
{"code":"status_t SoundTriggerHwService::Module::loadSoundModel(const sp<IMemory>& modelMemory,\n sound_model_handle_t *handle)\n{\n    ALOGV(\"loadSoundModel() handle\");\n if (!captureHotwordAllowed()) {\n return PERMISSION_DENIED;\n }\n\n if (modelMemory == 0 || modelMemory->pointer() == NULL) {\n        ALOGE(\"loadSoundModel() modelMemory is 0 or has NULL pointer()\");\n return BAD_VALUE;\n }\n\n     struct sound_trigger_sound_model *sound_model =\n             (struct sound_trigger_sound_model *)modelMemory->pointer();\n \n     AutoMutex lock(mLock);\n \n     if (mModels.size() >= mDescriptor.properties.max_sound_models) {\n        ALOGW(\"loadSoundModel(): Not loading, max number of models (%d) would be exceeded\",\n              mDescriptor.properties.max_sound_models);\n return INVALID_OPERATION;\n }\n\n status_t status = mHwDevice->load_sound_model(mHwDevice, sound_model,\n SoundTriggerHwService::soundModelCallback,\n this, handle);\n\n if (status != NO_ERROR) {\n return status;\n }\n audio_session_t session;\n audio_io_handle_t ioHandle;\n audio_devices_t device;\n\n    status = AudioSystem::acquireSoundTriggerSession(&session, &ioHandle, &device);\n if (status != NO_ERROR) {\n return status;\n }\n\n    sp<Model> model = new Model(*handle, session, ioHandle, device, sound_model->type);\n    mModels.replaceValueFor(*handle, model);\n\n return status;\n}\n","idx":187421,"target":1}
{"code":"status_t SoundTriggerHwService::Module::startRecognition(sound_model_handle_t handle,\n const sp<IMemory>& dataMemory)\n{\n    ALOGV(\"startRecognition() model handle %d\", handle);\n if (!captureHotwordAllowed()) {\n\n         return PERMISSION_DENIED;\n     }\n \n    if (dataMemory != 0 && dataMemory->pointer() == NULL) {\n        ALOGE(\"startRecognition() dataMemory is non-0 but has NULL pointer()\");\n         return BAD_VALUE;\n \n     }\n     AutoMutex lock(mLock);\n     if (mServiceState == SOUND_TRIGGER_STATE_DISABLED) {\n         return INVALID_OPERATION;\n }\n    sp<Model> model = getModel(handle);\n\n     if (model == 0) {\n         return BAD_VALUE;\n     }\n    if ((dataMemory == 0) ||\n            (dataMemory->size() < sizeof(struct sound_trigger_recognition_config))) {\n        return BAD_VALUE;\n    }\n \n     if (model->mState == Model::STATE_ACTIVE) {\n         return INVALID_OPERATION;\n     }\n \n    struct sound_trigger_recognition_config *config =\n            (struct sound_trigger_recognition_config *)dataMemory->pointer();\n \n     config->capture_handle = model->mCaptureIOHandle;\n    config->capture_device = model->mCaptureDevice;\n status_t status = mHwDevice->start_recognition(mHwDevice, handle, config,\n SoundTriggerHwService::recognitionCallback,\n this);\n\n if (status == NO_ERROR) {\n        model->mState = Model::STATE_ACTIVE;\n        model->mConfig = *config;\n }\n\n return status;\n}\n","idx":187422,"target":1}
{"code":" bool InputWindowInfo::frameContainsPoint(int32_t x, int32_t y) const {\n    return x >= frameLeft && x <= frameRight\n            && y >= frameTop && y <= frameBottom;\n }\n","idx":188191,"target":1}
{"code":" bool InputWindowInfo::isTrustedOverlay() const {\n     return layoutParamsType == TYPE_INPUT_METHOD\n             || layoutParamsType == TYPE_INPUT_METHOD_DIALOG\n             || layoutParamsType == TYPE_MAGNIFICATION_OVERLAY\n             || layoutParamsType == TYPE_SECURE_SYSTEM_OVERLAY;\n }\n","idx":188192,"target":1}
{"code":"HistogramBase* SparseHistogram::FactoryGet(const std::string& name,\n                                           int32_t flags) {\n  HistogramBase* histogram = StatisticsRecorder::FindHistogram(name);\n  if (!histogram) {\n    PersistentMemoryAllocator::Reference histogram_ref = 0;\n    std::unique_ptr<HistogramBase> tentative_histogram;\n    PersistentHistogramAllocator* allocator = GlobalHistogramAllocator::Get();\n    if (allocator) {\n      tentative_histogram = allocator->AllocateHistogram(\n          SPARSE_HISTOGRAM, name, 0, 0, nullptr, flags, &histogram_ref);\n    }\n\n    if (!tentative_histogram) {\n      DCHECK(!histogram_ref);  \/\/ Should never have been set.\n      DCHECK(!allocator);      \/\/ Shouldn't have failed.\n      flags &= ~HistogramBase::kIsPersistent;\n      tentative_histogram.reset(new SparseHistogram(name));\n      tentative_histogram->SetFlags(flags);\n    }\n\n    const void* tentative_histogram_ptr = tentative_histogram.get();\n    histogram = StatisticsRecorder::RegisterOrDeleteDuplicate(\n        tentative_histogram.release());\n\n    if (histogram_ref) {\n      allocator->FinalizeHistogram(histogram_ref,\n                                   histogram == tentative_histogram_ptr);\n    }\n\n    ReportHistogramActivity(*histogram, HISTOGRAM_CREATED);\n  } else {\n     ReportHistogramActivity(*histogram, HISTOGRAM_LOOKUP);\n   }\n \n  DCHECK_EQ(SPARSE_HISTOGRAM, histogram->GetHistogramType());\n   return histogram;\n }\n","idx":186462,"target":1}
{"code":"void FAST_FUNC dealloc_bunzip(bunzip_data *bd)\n{\n\tfree(bd->dbuf);\n\tfree(bd);\n}\n","idx":1784,"target":0}
{"code":"static unsigned get_bits(bunzip_data *bd, int bits_wanted)\n{\n\tunsigned bits = 0;\n\t\/* Cache bd->inbufBitCount in a CPU register (hopefully): *\/\n\tint bit_count = bd->inbufBitCount;\n\n\t\/* If we need to get more data from the byte buffer, do so.  (Loop getting\n\t   one byte at a time to enforce endianness and avoid unaligned access.) *\/\n\twhile (bit_count < bits_wanted) {\n\n\t\t\/* If we need to read more data from file into byte buffer, do so *\/\n\t\tif (bd->inbufPos == bd->inbufCount) {\n\t\t\t\/* if \"no input fd\" case: in_fd == -1, read fails, we jump *\/\n\t\t\tbd->inbufCount = read(bd->in_fd, bd->inbuf, IOBUF_SIZE);\n\t\t\tif (bd->inbufCount <= 0)\n\t\t\t\tlongjmp(bd->jmpbuf, RETVAL_UNEXPECTED_INPUT_EOF);\n\t\t\tbd->inbufPos = 0;\n\t\t}\n\n\t\t\/* Avoid 32-bit overflow (dump bit buffer to top of output) *\/\n\t\tif (bit_count >= 24) {\n\t\t\tbits = bd->inbufBits & ((1U << bit_count) - 1);\n\t\t\tbits_wanted -= bit_count;\n\t\t\tbits <<= bits_wanted;\n\t\t\tbit_count = 0;\n\t\t}\n\n\t\t\/* Grab next 8 bits of input from buffer. *\/\n\t\tbd->inbufBits = (bd->inbufBits << 8) | bd->inbuf[bd->inbufPos++];\n\t\tbit_count += 8;\n\t}\n\n\t\/* Calculate result *\/\n\tbit_count -= bits_wanted;\n\tbd->inbufBitCount = bit_count;\n\tbits |= (bd->inbufBits >> bit_count) & ((1 << bits_wanted) - 1);\n\n\treturn bits;\n}\n","idx":1785,"target":0}
{"code":"int main(int argc, char **argv)\n{\n\tchar c;\n\n\tint i = unpack_bz2_stream(0, 1);\n\tif (i < 0)\n\t\tfprintf(stderr, \"%s\\n\", bunzip_errors[-i]);\n\telse if (read(STDIN_FILENO, &c, 1))\n\t\tfprintf(stderr, \"Trailing garbage ignored\\n\");\n\treturn -i;\n}\n","idx":1786,"target":0}
{"code":"int FAST_FUNC start_bunzip(bunzip_data **bdp, int in_fd,\n\t\tconst void *inbuf, int len)\n{\n\tbunzip_data *bd;\n\tunsigned i;\n\tenum {\n\t\tBZh0 = ('B' << 24) + ('Z' << 16) + ('h' << 8) + '0',\n\t\th0 = ('h' << 8) + '0',\n\t};\n\n\t\/* Figure out how much data to allocate *\/\n\ti = sizeof(bunzip_data);\n\tif (in_fd != -1) i += IOBUF_SIZE;\n\n\t\/* Allocate bunzip_data.  Most fields initialize to zero. *\/\n\tbd = *bdp = xzalloc(i);\n\n\t\/* Setup input buffer *\/\n\tbd->in_fd = in_fd;\n\tif (-1 == in_fd) {\n\t\t\/* in this case, bd->inbuf is read-only *\/\n\t\tbd->inbuf = (void*)inbuf; \/* cast away const-ness *\/\n\t} else {\n\t\tbd->inbuf = (uint8_t*)(bd + 1);\n\t\tmemcpy(bd->inbuf, inbuf, len);\n\t}\n\tbd->inbufCount = len;\n\n\t\/* Init the CRC32 table (big endian) *\/\n\tcrc32_filltable(bd->crc32Table, 1);\n\n\t\/* Setup for I\/O error handling via longjmp *\/\n\ti = setjmp(bd->jmpbuf);\n\tif (i) return i;\n\n\t\/* Ensure that file starts with \"BZh['1'-'9'].\" *\/\n\t\/* Update: now caller verifies 1st two bytes, makes .gz\/.bz2\n\t * integration easier *\/\n\t\/* was: *\/\n\t\/* i = get_bits(bd, 32); *\/\n\t\/* if ((unsigned)(i - BZh0 - 1) >= 9) return RETVAL_NOT_BZIP_DATA; *\/\n\ti = get_bits(bd, 16);\n\tif ((unsigned)(i - h0 - 1) >= 9) return RETVAL_NOT_BZIP_DATA;\n\n\t\/* Fourth byte (ascii '1'-'9') indicates block size in units of 100k of\n\t   uncompressed data.  Allocate intermediate buffer for block. *\/\n\t\/* bd->dbufSize = 100000 * (i - BZh0); *\/\n\tbd->dbufSize = 100000 * (i - h0);\n\n\t\/* Cannot use xmalloc - may leak bd in NOFORK case! *\/\n\tbd->dbuf = malloc_or_warn(bd->dbufSize * sizeof(bd->dbuf[0]));\n\tif (!bd->dbuf) {\n\t\tfree(bd);\n\t\txfunc_die();\n\t}\n\treturn RETVAL_OK;\n}\n","idx":1788,"target":0}
{"code":"unpack_bz2_stream(transformer_state_t *xstate)\n{\n\tIF_DESKTOP(long long total_written = 0;)\n\tbunzip_data *bd;\n\tchar *outbuf;\n\tint i;\n\tunsigned len;\n\n\tif (check_signature16(xstate, BZIP2_MAGIC))\n\t\treturn -1;\n\n\toutbuf = xmalloc(IOBUF_SIZE);\n\tlen = 0;\n\twhile (1) { \/* \"Process one BZ... stream\" loop *\/\n\n\t\ti = start_bunzip(&bd, xstate->src_fd, outbuf + 2, len);\n\n\t\tif (i == 0) {\n\t\t\twhile (1) { \/* \"Produce some output bytes\" loop *\/\n\t\t\t\ti = read_bunzip(bd, outbuf, IOBUF_SIZE);\n\t\t\t\tif (i < 0) \/* error? *\/\n\t\t\t\t\tbreak;\n\t\t\t\ti = IOBUF_SIZE - i; \/* number of bytes produced *\/\n\t\t\t\tif (i == 0) \/* EOF? *\/\n\t\t\t\t\tbreak;\n\t\t\t\tif (i != transformer_write(xstate, outbuf, i)) {\n\t\t\t\t\ti = RETVAL_SHORT_WRITE;\n\t\t\t\t\tgoto release_mem;\n\t\t\t\t}\n\t\t\t\tIF_DESKTOP(total_written += i;)\n\t\t\t}\n\t\t}\n\n\t\tif (i != RETVAL_LAST_BLOCK\n\t\t\/* Observed case when i == RETVAL_OK:\n\t\t * \"bzcat z.bz2\", where \"z.bz2\" is a bzipped zero-length file\n\t\t * (to be exact, z.bz2 is exactly these 14 bytes:\n\t\t * 42 5a 68 39 17 72 45 38  50 90 00 00 00 00).\n\t\t *\/\n\t\t && i != RETVAL_OK\n\t\t) {\n\t\t\tbb_error_msg(\"bunzip error %d\", i);\n\t\t\tbreak;\n\t\t}\n\t\tif (bd->headerCRC != bd->totalCRC) {\n\t\t\tbb_error_msg(\"CRC error\");\n\t\t\tbreak;\n\t\t}\n\n\t\t\/* Successfully unpacked one BZ stream *\/\n\t\ti = RETVAL_OK;\n\n\t\t\/* Do we have \"BZ...\" after last processed byte?\n\t\t * pbzip2 (parallelized bzip2) produces such files.\n\t\t *\/\n\t\tlen = bd->inbufCount - bd->inbufPos;\n\t\tmemcpy(outbuf, &bd->inbuf[bd->inbufPos], len);\n\t\tif (len < 2) {\n\t\t\tif (safe_read(xstate->src_fd, outbuf + len, 2 - len) != 2 - len)\n\t\t\t\tbreak;\n\t\t\tlen = 2;\n\t\t}\n\t\tif (*(uint16_t*)outbuf != BZIP2_MAGIC) \/* \"BZ\"? *\/\n\t\t\tbreak;\n\t\tdealloc_bunzip(bd);\n\t\tlen -= 2;\n\t}\n\n release_mem:\n\tdealloc_bunzip(bd);\n\tfree(outbuf);\n\n\treturn i ? i : IF_DESKTOP(total_written) + 0;\n}\n","idx":1789,"target":0}
{"code":"static struct ucounts *get_ucounts(struct user_namespace *ns, kuid_t uid)\n{\n\tstruct hlist_head *hashent = ucounts_hashentry(ns, uid);\n\tstruct ucounts *ucounts, *new;\n\n\tspin_lock_irq(&ucounts_lock);\n\tucounts = find_ucounts(ns, uid, hashent);\n\tif (!ucounts) {\n\t\tspin_unlock_irq(&ucounts_lock);\n\n\t\tnew = kzalloc(sizeof(*new), GFP_KERNEL);\n\t\tif (!new)\n\t\t\treturn NULL;\n \n \t\tnew->ns = ns;\n \t\tnew->uid = uid;\n\t\tatomic_set(&new->count, 0);\n \n \t\tspin_lock_irq(&ucounts_lock);\n \t\tucounts = find_ucounts(ns, uid, hashent);\n\t\tif (ucounts) {\n\t\t\tkfree(new);\n\t\t} else {\n\t\t\thlist_add_head(&new->node, hashent);\n \t\t\tucounts = new;\n \t\t}\n \t}\n\tif (!atomic_add_unless(&ucounts->count, 1, INT_MAX))\n \t\tucounts = NULL;\n \tspin_unlock_irq(&ucounts_lock);\n \treturn ucounts;\n }\n","idx":181487,"target":1}
{"code":"static void put_ucounts(struct ucounts *ucounts)\n {\n \tunsigned long flags;\n \n\tif (atomic_dec_and_test(&ucounts->count)) {\n\t\tspin_lock_irqsave(&ucounts_lock, flags);\n \t\thlist_del_init(&ucounts->node);\n\t\tspin_unlock_irqrestore(&ucounts_lock, flags);\n \n\t\tkfree(ucounts);\n\t}\n }\n","idx":181488,"target":1}
{"code":" INST_HANDLER (lds) {\t\/\/ LDS Rd, k\n \tint d = ((buf[0] >> 4) & 0xf) | ((buf[1] & 0x1) << 4);\n \tint k = (buf[3] << 8) | buf[2];\n \top->ptr = k;\n\n\t__generic_ld_st (op, \"ram\", 0, 1, 0, k, 0);\n\tESIL_A (\"r%d,=,\", d);\n}\n","idx":182406,"target":1}
{"code":"bool ldb_dn_add_base(struct ldb_dn *dn, struct ldb_dn *base)\n{\n\tconst char *s;\n\tchar *t;\n\n\tif ( !base || base->invalid || !dn || dn->invalid) {\n\t\treturn false;\n\t}\n\n\tif (dn->components) {\n\t\tunsigned int i;\n\n\t\tif ( ! ldb_dn_validate(base)) {\n\t\t\treturn false;\n\t\t}\n\n\t\ts = NULL;\n\t\tif (dn->valid_case) {\n\t\t\tif ( ! (s = ldb_dn_get_casefold(base))) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\tdn->components = talloc_realloc(dn,\n\t\t\t\t\t\tdn->components,\n\t\t\t\t\t\tstruct ldb_dn_component,\n\t\t\t\t\t\tdn->comp_num + base->comp_num);\n\t\tif ( ! dn->components) {\n\t\t\tldb_dn_mark_invalid(dn);\n\t\t\treturn false;\n\t\t}\n\n\t\tfor (i = 0; i < base->comp_num; dn->comp_num++, i++) {\n\t\t\tdn->components[dn->comp_num] =\n\t\t\t\tldb_dn_copy_component(dn->components,\n\t\t\t\t\t\t\t&base->components[i]);\n\t\t\tif (dn->components[dn->comp_num].value.data == NULL) {\n\t\t\t\tldb_dn_mark_invalid(dn);\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\tif (dn->casefold && s) {\n\t\t\tif (*dn->casefold) {\n\t\t\t\tt = talloc_asprintf(dn, \"%s,%s\",\n\t\t\t\t\t\t    dn->casefold, s);\n\t\t\t} else {\n\t\t\t\tt = talloc_strdup(dn, s);\n\t\t\t}\n\t\t\tLDB_FREE(dn->casefold);\n\t\t\tdn->casefold = t;\n\t\t}\n\t}\n\n\tif (dn->linearized) {\n\n\t\ts = ldb_dn_get_linearized(base);\n\t\tif ( ! s) {\n\t\t\treturn false;\n\t\t}\n\n\t\tif (*dn->linearized) {\n\t\t\tt = talloc_asprintf(dn, \"%s,%s\",\n\t\t\t\t\t    dn->linearized, s);\n\t\t} else {\n\t\t\tt = talloc_strdup(dn, s);\n\t\t}\n\t\tif ( ! t) {\n\t\t\tldb_dn_mark_invalid(dn);\n\t\t\treturn false;\n\t\t}\n\t\tLDB_FREE(dn->linearized);\n\t\tdn->linearized = t;\n\t}\n\n\t\/* Wipe the ext_linearized DN,\n\t * the GUID and SID are almost certainly no longer valid *\/\n\tLDB_FREE(dn->ext_linearized);\n\tLDB_FREE(dn->ext_components);\n\tdn->ext_comp_num = 0;\n\n\treturn true;\n}\n","idx":2324,"target":0}
{"code":"bool ldb_dn_add_base_fmt(struct ldb_dn *dn, const char *base_fmt, ...)\n{\n\tstruct ldb_dn *base;\n\tchar *base_str;\n\tva_list ap;\n\tbool ret;\n\n\tif ( !dn || dn->invalid) {\n\t\treturn false;\n\t}\n\n\tva_start(ap, base_fmt);\n\tbase_str = talloc_vasprintf(dn, base_fmt, ap);\n\tva_end(ap);\n\n\tif (base_str == NULL) {\n\t\treturn false;\n\t}\n\n\tbase = ldb_dn_new(base_str, dn->ldb, base_str);\n\n\tret = ldb_dn_add_base(dn, base);\n\n\ttalloc_free(base_str);\n\n\treturn ret;\n}\n","idx":2325,"target":0}
{"code":"bool ldb_dn_add_child_fmt(struct ldb_dn *dn, const char *child_fmt, ...)\n{\n\tstruct ldb_dn *child;\n\tchar *child_str;\n\tva_list ap;\n\tbool ret;\n\n\tif ( !dn || dn->invalid) {\n\t\treturn false;\n\t}\n\n\tva_start(ap, child_fmt);\n\tchild_str = talloc_vasprintf(dn, child_fmt, ap);\n\tva_end(ap);\n\n\tif (child_str == NULL) {\n\t\treturn false;\n\t}\n\n\tchild = ldb_dn_new(child_str, dn->ldb, child_str);\n\n\tret = ldb_dn_add_child(dn, child);\n\n\ttalloc_free(child_str);\n\n\treturn ret;\n}\n","idx":2327,"target":0}
{"code":"char *ldb_dn_alloc_linearized(TALLOC_CTX *mem_ctx, struct ldb_dn *dn)\n{\n\treturn talloc_strdup(mem_ctx, ldb_dn_get_linearized(dn));\n}\n","idx":2328,"target":0}
{"code":"static char *ldb_dn_canonical(TALLOC_CTX *mem_ctx, struct ldb_dn *dn, int ex_format) {\n\tunsigned int i;\n\tTALLOC_CTX *tmpctx;\n\tchar *cracked = NULL;\n\tconst char *format = (ex_format ? \"\\n\" : \"\/\" );\n\n\tif ( ! ldb_dn_validate(dn)) {\n\t\treturn NULL;\n\t}\n\n\ttmpctx = talloc_new(mem_ctx);\n\n\t\/* Walk backwards down the DN, grabbing 'dc' components at first *\/\n\tfor (i = dn->comp_num - 1; i != (unsigned int) -1; i--) {\n\t\tif (ldb_attr_cmp(dn->components[i].name, \"dc\") != 0) {\n\t\t\tbreak;\n\t\t}\n\t\tif (cracked) {\n\t\t\tcracked = talloc_asprintf(tmpctx, \"%s.%s\",\n\t\t\t\t\t\t  ldb_dn_escape_value(tmpctx,\n\t\t\t\t\t\t\tdn->components[i].value),\n\t\t\t\t\t\t  cracked);\n\t\t} else {\n\t\t\tcracked = ldb_dn_escape_value(tmpctx,\n\t\t\t\t\t\t\tdn->components[i].value);\n\t\t}\n\t\tif (!cracked) {\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t\/* Only domain components?  Finish here *\/\n\tif (i == (unsigned int) -1) {\n\t\tcracked = talloc_strdup_append_buffer(cracked, format);\n\t\ttalloc_steal(mem_ctx, cracked);\n\t\tgoto done;\n\t}\n\n\t\/* Now walk backwards appending remaining components *\/\n\tfor (; i > 0; i--) {\n\t\tcracked = talloc_asprintf_append_buffer(cracked, \"\/%s\",\n\t\t\t\t\t\t\tldb_dn_escape_value(tmpctx,\n\t\t\t\t\t\t\tdn->components[i].value));\n\t\tif (!cracked) {\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t\/* Last one, possibly a newline for the 'ex' format *\/\n\tcracked = talloc_asprintf_append_buffer(cracked, \"%s%s\", format,\n\t\t\t\t\t\tldb_dn_escape_value(tmpctx,\n\t\t\t\t\t\t\tdn->components[i].value));\n\n\ttalloc_steal(mem_ctx, cracked);\ndone:\n\ttalloc_free(tmpctx);\n\treturn cracked;\n}\n","idx":2329,"target":0}
{"code":"char *ldb_dn_canonical_ex_string(TALLOC_CTX *mem_ctx, struct ldb_dn *dn) {\n\treturn ldb_dn_canonical(mem_ctx, dn, 1);\n}\n","idx":2330,"target":0}
{"code":"char *ldb_dn_canonical_string(TALLOC_CTX *mem_ctx, struct ldb_dn *dn) {\n\treturn ldb_dn_canonical(mem_ctx, dn, 0);\n\n}\n","idx":2331,"target":0}
{"code":"static bool ldb_dn_casefold_internal(struct ldb_dn *dn)\n{\n\tunsigned int i;\n\tint ret;\n\n\tif ( ! dn || dn->invalid) return false;\n\n\tif (dn->valid_case) return true;\n\n\tif (( ! dn->components) && ( ! ldb_dn_explode(dn))) {\n\t\treturn false;\n\t}\n\n\tfor (i = 0; i < dn->comp_num; i++) {\n\t\tconst struct ldb_schema_attribute *a;\n\n\t\tdn->components[i].cf_name =\n\t\t\tldb_attr_casefold(dn->components,\n\t\t\t\t\t  dn->components[i].name);\n\t\tif (!dn->components[i].cf_name) {\n\t\t\tgoto failed;\n\t\t}\n\n\t\ta = ldb_schema_attribute_by_name(dn->ldb,\n\t\t\t\t\t\t dn->components[i].cf_name);\n\n\t\tret = a->syntax->canonicalise_fn(dn->ldb, dn->components,\n\t\t\t\t\t\t &(dn->components[i].value),\n\t\t\t\t\t\t &(dn->components[i].cf_value));\n\t\tif (ret != 0) {\n\t\t\tgoto failed;\n\t\t}\n\t}\n\n\tdn->valid_case = true;\n\n\treturn true;\n\nfailed:\n\tfor (i = 0; i < dn->comp_num; i++) {\n\t\tLDB_FREE(dn->components[i].cf_name);\n\t\tLDB_FREE(dn->components[i].cf_value.data);\n\t}\n\treturn false;\n}\n","idx":2332,"target":0}
{"code":"bool ldb_dn_check_special(struct ldb_dn *dn, const char *check)\n{\n\tif ( ! dn || dn->invalid) return false;\n\treturn ! strcmp(dn->linearized, check);\n}\n","idx":2333,"target":0}
{"code":"int ldb_dn_compare(struct ldb_dn *dn0, struct ldb_dn *dn1)\n{\n\tunsigned int i;\n\tint ret;\n\n\tif (( ! dn0) || dn0->invalid || ! dn1 || dn1->invalid) {\n\t\treturn -1;\n\t}\n\n\tif (( ! dn0->valid_case) || ( ! dn1->valid_case)) {\n\t\tif (dn0->linearized && dn1->linearized) {\n\t\t\t\/* try with a normal compare first, if we are lucky\n\t\t\t * we will avoid exploding and casfolding *\/\n\t\t\tif (strcmp(dn0->linearized, dn1->linearized) == 0) {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\n\t\tif ( ! ldb_dn_casefold_internal(dn0)) {\n\t\t\treturn 1;\n\t\t}\n\n\t\tif ( ! ldb_dn_casefold_internal(dn1)) {\n\t\t\treturn -1;\n\t\t}\n\n\t}\n\n\tif (dn0->comp_num != dn1->comp_num) {\n\t\treturn (dn1->comp_num - dn0->comp_num);\n\t}\n\n\tif (dn0->comp_num == 0) {\n\t\tif (dn0->special && dn1->special) {\n\t\t\treturn strcmp(dn0->linearized, dn1->linearized);\n\t\t} else if (dn0->special) {\n\t\t\treturn 1;\n\t\t} else if (dn1->special) {\n\t\t\treturn -1;\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tfor (i = 0; i < dn0->comp_num; i++) {\n\t\tchar *dn0_name = dn0->components[i].cf_name;\n\t\tchar *dn1_name = dn1->components[i].cf_name;\n\n\t\tchar *dn0_vdata = (char *)dn0->components[i].cf_value.data;\n\t\tchar *dn1_vdata = (char *)dn1->components[i].cf_value.data;\n\n\t\tsize_t dn0_vlen = dn0->components[i].cf_value.length;\n\t\tsize_t dn1_vlen = dn1->components[i].cf_value.length;\n\n\t\t\/* compare attr names *\/\n\t\tret = strcmp(dn0_name, dn1_name);\n\t\tif (ret != 0) {\n\t\t\treturn ret;\n\t\t}\n\n\t\t\/* compare attr.cf_value. *\/\n\t\tif (dn0_vlen != dn1_vlen) {\n\t\t\treturn dn0_vlen - dn1_vlen;\n\t\t}\n\t\tret = strncmp(dn0_vdata, dn1_vdata, dn0_vlen);\n\t\tif (ret != 0) {\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n","idx":2334,"target":0}
{"code":"int ldb_dn_compare_base(struct ldb_dn *base, struct ldb_dn *dn)\n{\n\tint ret;\n\tunsigned int n_base, n_dn;\n\n\tif ( ! base || base->invalid) return 1;\n\tif ( ! dn || dn->invalid) return -1;\n\n\tif (( ! base->valid_case) || ( ! dn->valid_case)) {\n\t\tif (base->linearized && dn->linearized && dn->special == base->special) {\n\t\t\t\/* try with a normal compare first, if we are lucky\n\t\t\t * we will avoid exploding and casfolding *\/\n\t\t\tint dif;\n\t\t\tdif = strlen(dn->linearized) - strlen(base->linearized);\n\t\t\tif (dif < 0) {\n\t\t\t\treturn dif;\n\t\t\t}\n\t\t\tif (strcmp(base->linearized,\n\t\t\t\t   &dn->linearized[dif]) == 0) {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\n\t\tif ( ! ldb_dn_casefold_internal(base)) {\n\t\t\treturn 1;\n\t\t}\n\n\t\tif ( ! ldb_dn_casefold_internal(dn)) {\n\t\t\treturn -1;\n\t\t}\n\n\t}\n\n\t\/* if base has more components,\n\t * they don't have the same base *\/\n\tif (base->comp_num > dn->comp_num) {\n\t\treturn (dn->comp_num - base->comp_num);\n\t}\n\n\tif ((dn->comp_num == 0) || (base->comp_num == 0)) {\n\t\tif (dn->special && base->special) {\n\t\t\treturn strcmp(base->linearized, dn->linearized);\n\t\t} else if (dn->special) {\n\t\t\treturn -1;\n\t\t} else if (base->special) {\n\t\t\treturn 1;\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tn_base = base->comp_num - 1;\n\tn_dn = dn->comp_num - 1;\n\n\twhile (n_base != (unsigned int) -1) {\n\t\tchar *b_name = base->components[n_base].cf_name;\n\t\tchar *dn_name = dn->components[n_dn].cf_name;\n\n\t\tchar *b_vdata = (char *)base->components[n_base].cf_value.data;\n\t\tchar *dn_vdata = (char *)dn->components[n_dn].cf_value.data;\n\n\t\tsize_t b_vlen = base->components[n_base].cf_value.length;\n\t\tsize_t dn_vlen = dn->components[n_dn].cf_value.length;\n\n\t\t\/* compare attr names *\/\n\t\tret = strcmp(b_name, dn_name);\n\t\tif (ret != 0) return ret;\n\n\t\t\/* compare attr.cf_value. *\/\n\t\tif (b_vlen != dn_vlen) {\n\t\t\treturn b_vlen - dn_vlen;\n\t\t}\n\t\tret = strncmp(b_vdata, dn_vdata, b_vlen);\n\t\tif (ret != 0) return ret;\n\n\t\tn_base--;\n\t\tn_dn--;\n\t}\n\n\treturn 0;\n}\n","idx":2335,"target":0}
{"code":"struct ldb_dn *ldb_dn_copy(TALLOC_CTX *mem_ctx, struct ldb_dn *dn)\n{\n\tstruct ldb_dn *new_dn;\n\n\tif (!dn || dn->invalid) {\n\t\treturn NULL;\n\t}\n\n\tnew_dn = talloc_zero(mem_ctx, struct ldb_dn);\n\tif ( !new_dn) {\n\t\treturn NULL;\n\t}\n\n\t*new_dn = *dn;\n\n\tif (dn->components) {\n\t\tunsigned int i;\n\n\t\tnew_dn->components =\n\t\t\ttalloc_zero_array(new_dn,\n\t\t\t\t\t  struct ldb_dn_component,\n\t\t\t\t\t  dn->comp_num);\n\t\tif ( ! new_dn->components) {\n\t\t\ttalloc_free(new_dn);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tfor (i = 0; i < dn->comp_num; i++) {\n\t\t\tnew_dn->components[i] =\n\t\t\t\tldb_dn_copy_component(new_dn->components,\n\t\t\t\t\t\t      &dn->components[i]);\n\t\t\tif ( ! new_dn->components[i].value.data) {\n\t\t\t\ttalloc_free(new_dn);\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (dn->ext_components) {\n\t\tunsigned int i;\n\n\t\tnew_dn->ext_components =\n\t\t\ttalloc_zero_array(new_dn,\n\t\t\t\t\t  struct ldb_dn_ext_component,\n\t\t\t\t\t  dn->ext_comp_num);\n\t\tif ( ! new_dn->ext_components) {\n\t\t\ttalloc_free(new_dn);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tfor (i = 0; i < dn->ext_comp_num; i++) {\n\t\t\tnew_dn->ext_components[i] =\n\t\t\t\t ldb_dn_ext_copy_component(\n\t\t\t\t\t\tnew_dn->ext_components,\n\t\t\t\t\t\t&dn->ext_components[i]);\n\t\t\tif ( ! new_dn->ext_components[i].value.data) {\n\t\t\t\ttalloc_free(new_dn);\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (dn->casefold) {\n\t\tnew_dn->casefold = talloc_strdup(new_dn, dn->casefold);\n\t\tif ( ! new_dn->casefold) {\n\t\t\ttalloc_free(new_dn);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tif (dn->linearized) {\n\t\tnew_dn->linearized = talloc_strdup(new_dn, dn->linearized);\n\t\tif ( ! new_dn->linearized) {\n\t\t\ttalloc_free(new_dn);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tif (dn->ext_linearized) {\n\t\tnew_dn->ext_linearized = talloc_strdup(new_dn,\n\t\t\t\t\t\t\tdn->ext_linearized);\n\t\tif ( ! new_dn->ext_linearized) {\n\t\t\ttalloc_free(new_dn);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\treturn new_dn;\n}\n","idx":2336,"target":0}
{"code":"static struct ldb_dn_component ldb_dn_copy_component(\n\t\t\t\t\t\tTALLOC_CTX *mem_ctx,\n\t\t\t\t\t\tstruct ldb_dn_component *src)\n{\n\tstruct ldb_dn_component dst;\n\n\tmemset(&dst, 0, sizeof(dst));\n\n\tif (src == NULL) {\n\t\treturn dst;\n\t}\n\n\tdst.value = ldb_val_dup(mem_ctx, &(src->value));\n\tif (dst.value.data == NULL) {\n\t\treturn dst;\n\t}\n\n\tdst.name = talloc_strdup(mem_ctx, src->name);\n\tif (dst.name == NULL) {\n\t\tLDB_FREE(dst.value.data);\n\t\treturn dst;\n\t}\n\n\tif (src->cf_value.data) {\n\t\tdst.cf_value = ldb_val_dup(mem_ctx, &(src->cf_value));\n\t\tif (dst.cf_value.data == NULL) {\n\t\t\tLDB_FREE(dst.value.data);\n\t\t\tLDB_FREE(dst.name);\n\t\t\treturn dst;\n\t\t}\n\n\t\tdst.cf_name = talloc_strdup(mem_ctx, src->cf_name);\n\t\tif (dst.cf_name == NULL) {\n\t\t\tLDB_FREE(dst.cf_name);\n\t\t\tLDB_FREE(dst.value.data);\n\t\t\tLDB_FREE(dst.name);\n\t\t\treturn dst;\n\t\t}\n\t} else {\n\t\tdst.cf_value.data = NULL;\n\t\tdst.cf_name = NULL;\n\t}\n\n\treturn dst;\n}\n","idx":2337,"target":0}
{"code":"static struct ldb_dn_ext_component ldb_dn_ext_copy_component(\n\t\t\t\t\t\tTALLOC_CTX *mem_ctx,\n\t\t\t\t\t\tstruct ldb_dn_ext_component *src)\n{\n\tstruct ldb_dn_ext_component dst;\n\n\tmemset(&dst, 0, sizeof(dst));\n\n\tif (src == NULL) {\n\t\treturn dst;\n\t}\n\n\tdst.value = ldb_val_dup(mem_ctx, &(src->value));\n\tif (dst.value.data == NULL) {\n\t\treturn dst;\n\t}\n\n\tdst.name = talloc_strdup(mem_ctx, src->name);\n\tif (dst.name == NULL) {\n\t\tLDB_FREE(dst.value.data);\n\t\treturn dst;\n\t}\n\n\treturn dst;\n}\n","idx":2339,"target":0}
{"code":"static int ldb_dn_extended_component_compare(const void *p1, const void *p2)\n{\n\tconst struct ldb_dn_ext_component *ec1 = (const struct ldb_dn_ext_component *)p1;\n\tconst struct ldb_dn_ext_component *ec2 = (const struct ldb_dn_ext_component *)p2;\n\treturn strcmp(ec1->name, ec2->name);\n}\n","idx":2340,"target":0}
{"code":"void ldb_dn_extended_filter(struct ldb_dn *dn, const char * const *accept_list)\n{\n\tunsigned int i;\n\tfor (i=0; i<dn->ext_comp_num; i++) {\n\t\tif (!ldb_attr_in_list(accept_list, dn->ext_components[i].name)) {\n\t\t\tmemmove(&dn->ext_components[i],\n\t\t\t\t&dn->ext_components[i+1],\n\t\t\t\t(dn->ext_comp_num-(i+1))*sizeof(dn->ext_components[0]));\n\t\t\tdn->ext_comp_num--;\n\t\t\ti--;\n\t\t}\n\t}\n\tLDB_FREE(dn->ext_linearized);\n}\n","idx":2341,"target":0}
{"code":"const char *ldb_dn_get_casefold(struct ldb_dn *dn)\n{\n\tunsigned int i;\n\tsize_t len;\n\tchar *d, *n;\n\n\tif (dn->casefold) return dn->casefold;\n\n\tif (dn->special) {\n\t\tdn->casefold = talloc_strdup(dn, dn->linearized);\n\t\tif (!dn->casefold) return NULL;\n\t\tdn->valid_case = true;\n\t\treturn dn->casefold;\n\t}\n\n\tif ( ! ldb_dn_casefold_internal(dn)) {\n\t\treturn NULL;\n\t}\n\n\tif (dn->comp_num == 0) {\n\t\tdn->casefold = talloc_strdup(dn, \"\");\n\t\treturn dn->casefold;\n\t}\n\n\t\/* calculate maximum possible length of DN *\/\n\tfor (len = 0, i = 0; i < dn->comp_num; i++) {\n\t\t\/* name len *\/\n\t\tlen += strlen(dn->components[i].cf_name);\n\t\t\/* max escaped data len *\/\n\t\tlen += (dn->components[i].cf_value.length * 3);\n\t\tlen += 2; \/* '=' and ',' *\/\n\t}\n\tdn->casefold = talloc_array(dn, char, len);\n\tif ( ! dn->casefold) return NULL;\n\n\td = dn->casefold;\n\n\tfor (i = 0; i < dn->comp_num; i++) {\n\n\t\t\/* copy the name *\/\n\t\tn = dn->components[i].cf_name;\n\t\twhile (*n) *d++ = *n++;\n\n\t\t*d++ = '=';\n\n\t\t\/* and the value *\/\n\t\td += ldb_dn_escape_internal( d,\n\t\t\t\t(char *)dn->components[i].cf_value.data,\n\t\t\t\tdn->components[i].cf_value.length);\n\t\t*d++ = ',';\n\t}\n\t*(--d) = '\\0';\n\n\t\/* don't waste more memory than necessary *\/\n\tdn->casefold = talloc_realloc(dn, dn->casefold,\n\t\t\t\t      char, strlen(dn->casefold) + 1);\n\n\treturn dn->casefold;\n}\n","idx":2342,"target":0}
{"code":"int ldb_dn_get_comp_num(struct ldb_dn *dn)\n{\n\tif ( ! ldb_dn_validate(dn)) {\n\t\treturn -1;\n\t}\n\treturn dn->comp_num;\n}\n","idx":2343,"target":0}
{"code":"const struct ldb_val *ldb_dn_get_component_val(struct ldb_dn *dn,\n\t\t\t\t\t\tunsigned int num)\n{\n\tif ( ! ldb_dn_validate(dn)) {\n\t\treturn NULL;\n\t}\n\tif (num >= dn->comp_num) return NULL;\n\treturn &dn->components[num].value;\n}\n","idx":2344,"target":0}
{"code":"const struct ldb_val *ldb_dn_get_extended_component(struct ldb_dn *dn,\n\t\t\t\t\t\t    const char *name)\n{\n\tunsigned int i;\n\tif ( ! ldb_dn_validate(dn)) {\n\t\treturn NULL;\n\t}\n\tfor (i=0; i < dn->ext_comp_num; i++) {\n\t\tif (ldb_attr_cmp(dn->ext_components[i].name, name) == 0) {\n\t\t\treturn &dn->ext_components[i].value;\n\t\t}\n\t}\n\treturn NULL;\n}\n","idx":2346,"target":0}
{"code":"char *ldb_dn_get_extended_linearized(TALLOC_CTX *mem_ctx, struct ldb_dn *dn, int mode)\n{\n\tconst char *linearized = ldb_dn_get_linearized(dn);\n\tchar *p = NULL;\n\tunsigned int i;\n\n\tif (!linearized) {\n\t\treturn NULL;\n\t}\n\n\tif (!ldb_dn_has_extended(dn)) {\n\t\treturn talloc_strdup(mem_ctx, linearized);\n\t}\n\n\tif (!ldb_dn_validate(dn)) {\n\t\treturn NULL;\n\t}\n\n\t\/* sort the extended components by name. The idea is to make\n\t * the resulting DNs consistent, plus to ensure that we put\n\t * 'DELETED' first, so it can be very quickly recognised\n\t *\/\n\tTYPESAFE_QSORT(dn->ext_components, dn->ext_comp_num,\n\t\t       ldb_dn_extended_component_compare);\n\n\tfor (i = 0; i < dn->ext_comp_num; i++) {\n\t\tconst struct ldb_dn_extended_syntax *ext_syntax;\n\t\tconst char *name = dn->ext_components[i].name;\n\t\tstruct ldb_val ec_val = dn->ext_components[i].value;\n\t\tstruct ldb_val val;\n\t\tint ret;\n\n\t\text_syntax = ldb_dn_extended_syntax_by_name(dn->ldb, name);\n\t\tif (!ext_syntax) {\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (mode == 1) {\n\t\t\tret = ext_syntax->write_clear_fn(dn->ldb, mem_ctx,\n\t\t\t\t\t\t\t&ec_val, &val);\n\t\t} else if (mode == 0) {\n\t\t\tret = ext_syntax->write_hex_fn(dn->ldb, mem_ctx,\n\t\t\t\t\t\t\t&ec_val, &val);\n\t\t} else {\n\t\t\tret = -1;\n\t\t}\n\n\t\tif (ret != LDB_SUCCESS) {\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (i == 0) {\n\t\t\tp = talloc_asprintf(mem_ctx, \"<%s=%s>\", \n\t\t\t\t\t    name, val.data);\n\t\t} else {\n\t\t\tp = talloc_asprintf_append_buffer(p, \";<%s=%s>\",\n\t\t\t\t\t\t\t  name, val.data);\n\t\t}\n\n\t\ttalloc_free(val.data);\n\n\t\tif (!p) {\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tif (dn->ext_comp_num && *linearized) {\n\t\tp = talloc_asprintf_append_buffer(p, \";%s\", linearized);\n\t}\n\n\tif (!p) {\n\t\treturn NULL;\n\t}\n\n\treturn p;\n}\n","idx":2347,"target":0}
{"code":"struct ldb_context *ldb_dn_get_ldb_context(struct ldb_dn *dn)\n{\n\treturn dn->ldb;\n}\n","idx":2348,"target":0}
{"code":"const char *ldb_dn_get_linearized(struct ldb_dn *dn)\n{\n\tunsigned int i;\n\tsize_t len;\n\tchar *d, *n;\n\n\tif ( ! dn || ( dn->invalid)) return NULL;\n\n\tif (dn->linearized) return dn->linearized;\n\n\tif ( ! dn->components) {\n\t\tldb_dn_mark_invalid(dn);\n\t\treturn NULL;\n\t}\n\n\tif (dn->comp_num == 0) {\n\t\tdn->linearized = talloc_strdup(dn, \"\");\n\t\tif ( ! dn->linearized) return NULL;\n\t\treturn dn->linearized;\n\t}\n\n\t\/* calculate maximum possible length of DN *\/\n\tfor (len = 0, i = 0; i < dn->comp_num; i++) {\n\t\t\/* name len *\/\n\t\tlen += strlen(dn->components[i].name);\n\t\t\/* max escaped data len *\/\n\t\tlen += (dn->components[i].value.length * 3);\n\t\tlen += 2; \/* '=' and ',' *\/\n\t}\n\tdn->linearized = talloc_array(dn, char, len);\n\tif ( ! dn->linearized) return NULL;\n\n\td = dn->linearized;\n\n\tfor (i = 0; i < dn->comp_num; i++) {\n\n\t\t\/* copy the name *\/\n\t\tn = dn->components[i].name;\n\t\twhile (*n) *d++ = *n++;\n\n\t\t*d++ = '=';\n\n\t\t\/* and the value *\/\n\t\td += ldb_dn_escape_internal( d,\n\t\t\t\t(char *)dn->components[i].value.data,\n\t\t\t\tdn->components[i].value.length);\n\t\t*d++ = ',';\n\t}\n\n\t*(--d) = '\\0';\n\n\t\/* don't waste more memory than necessary *\/\n\tdn->linearized = talloc_realloc(dn, dn->linearized,\n\t\t\t\t\tchar, (d - dn->linearized + 1));\n\n\treturn dn->linearized;\n}\n","idx":2349,"target":0}
{"code":"struct ldb_dn *ldb_dn_get_parent(TALLOC_CTX *mem_ctx, struct ldb_dn *dn)\n{\n\tstruct ldb_dn *new_dn;\n\n\tnew_dn = ldb_dn_copy(mem_ctx, dn);\n\tif ( !new_dn ) {\n\t\treturn NULL;\n\t}\n\n\tif ( ! ldb_dn_remove_child_components(new_dn, 1)) {\n\t\ttalloc_free(new_dn);\n\t\treturn NULL;\n\t}\n\n\treturn new_dn;\n}\n","idx":2350,"target":0}
{"code":"const char *ldb_dn_get_rdn_name(struct ldb_dn *dn)\n{\n\tif ( ! ldb_dn_validate(dn)) {\n\t\treturn NULL;\n\t}\n\tif (dn->comp_num == 0) return NULL;\n\treturn dn->components[0].name;\n}\n","idx":2351,"target":0}
{"code":"const struct ldb_val *ldb_dn_get_rdn_val(struct ldb_dn *dn)\n{\n\tif ( ! ldb_dn_validate(dn)) {\n\t\treturn NULL;\n\t}\n\tif (dn->comp_num == 0) return NULL;\n\treturn &dn->components[0].value;\n}\n","idx":2352,"target":0}
{"code":"bool ldb_dn_has_extended(struct ldb_dn *dn)\n{\n\tif ( ! dn || dn->invalid) return false;\n\tif (dn->ext_linearized && (dn->ext_linearized[0] == '<')) return true;\n\treturn dn->ext_comp_num != 0;\n}\n","idx":2353,"target":0}
{"code":"bool ldb_dn_is_null(struct ldb_dn *dn)\n{\n\tif ( ! dn || dn->invalid) return false;\n\tif (ldb_dn_has_extended(dn)) return false;\n\tif (dn->linearized && (dn->linearized[0] == '\\0')) return true;\n\treturn false;\n}\n","idx":2354,"target":0}
{"code":"bool ldb_dn_is_special(struct ldb_dn *dn)\n{\n\tif ( ! dn || dn->invalid) return false;\n\treturn dn->special;\n}\n","idx":2355,"target":0}
{"code":"bool ldb_dn_remove_base_components(struct ldb_dn *dn, unsigned int num)\n{\n\tunsigned int i;\n\n\tif ( ! ldb_dn_validate(dn)) {\n\t\treturn false;\n\t}\n\n\tif (dn->comp_num < num) {\n\t\treturn false;\n\t}\n\n\t\/* free components *\/\n\tfor (i = dn->comp_num - num; i < dn->comp_num; i++) {\n\t\tLDB_FREE(dn->components[i].name);\n\t\tLDB_FREE(dn->components[i].value.data);\n\t\tLDB_FREE(dn->components[i].cf_name);\n\t\tLDB_FREE(dn->components[i].cf_value.data);\n\t}\n\n\tdn->comp_num -= num;\n\n\tif (dn->valid_case) {\n\t\tfor (i = 0; i < dn->comp_num; i++) {\n\t\t\tLDB_FREE(dn->components[i].cf_name);\n\t\t\tLDB_FREE(dn->components[i].cf_value.data);\n\t\t}\n\t\tdn->valid_case = false;\n\t}\n\n\tLDB_FREE(dn->casefold);\n\tLDB_FREE(dn->linearized);\n\n\t\/* Wipe the ext_linearized DN,\n\t * the GUID and SID are almost certainly no longer valid *\/\n\tLDB_FREE(dn->ext_linearized);\n\tLDB_FREE(dn->ext_components);\n\tdn->ext_comp_num = 0;\n\n\treturn true;\n}\n","idx":2357,"target":0}
{"code":"void ldb_dn_remove_extended_components(struct ldb_dn *dn)\n{\n\tLDB_FREE(dn->ext_linearized);\n\tLDB_FREE(dn->ext_components);\n\tdn->ext_comp_num = 0;\n}\n","idx":2359,"target":0}
{"code":"bool ldb_dn_replace_components(struct ldb_dn *dn, struct ldb_dn *new_dn)\n{\n\tint i;\n\n\tif ( ! ldb_dn_validate(dn) || ! ldb_dn_validate(new_dn)) {\n\t\treturn false;\n\t}\n\n\t\/* free components *\/\n\tfor (i = 0; i < dn->comp_num; i++) {\n\t\tLDB_FREE(dn->components[i].name);\n\t\tLDB_FREE(dn->components[i].value.data);\n\t\tLDB_FREE(dn->components[i].cf_name);\n\t\tLDB_FREE(dn->components[i].cf_value.data);\n\t}\n\n\tdn->components = talloc_realloc(dn,\n\t\t\t\t\tdn->components,\n\t\t\t\t\tstruct ldb_dn_component,\n\t\t\t\t\tnew_dn->comp_num);\n\tif (dn->components == NULL) {\n\t\tldb_dn_mark_invalid(dn);\n\t\treturn false;\n\t}\n\n\tdn->comp_num = new_dn->comp_num;\n\tdn->valid_case = new_dn->valid_case;\n\n\tfor (i = 0; i < dn->comp_num; i++) {\n\t\tdn->components[i] = ldb_dn_copy_component(dn->components, &new_dn->components[i]);\n\t\tif (dn->components[i].name == NULL) {\n\t\t\tldb_dn_mark_invalid(dn);\n\t\t\treturn false;\n\t\t}\n\t}\n\tif (new_dn->linearized == NULL) {\n\t\tdn->linearized = NULL;\n\t} else {\n\t\tdn->linearized = talloc_strdup(dn, new_dn->linearized);\n\t\tif (dn->linearized == NULL) {\n\t\t\tldb_dn_mark_invalid(dn);\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}\n","idx":2360,"target":0}
{"code":"int ldb_dn_set_component(struct ldb_dn *dn, int num,\n\t\t\t const char *name, const struct ldb_val val)\n{\n\tchar *n;\n\tstruct ldb_val v;\n\n\tif ( ! ldb_dn_validate(dn)) {\n\t\treturn LDB_ERR_OTHER;\n\t}\n\n\tif (num >= dn->comp_num) {\n\t\treturn LDB_ERR_OTHER;\n\t}\n\n\tn = talloc_strdup(dn, name);\n\tif ( ! n) {\n\t\treturn LDB_ERR_OTHER;\n\t}\n\n\tv.length = val.length;\n\tv.data = (uint8_t *)talloc_memdup(dn, val.data, v.length+1);\n\tif ( ! v.data) {\n\t\ttalloc_free(n);\n\t\treturn LDB_ERR_OTHER;\n\t}\n\n\ttalloc_free(dn->components[num].name);\n\ttalloc_free(dn->components[num].value.data);\n\tdn->components[num].name = n;\n\tdn->components[num].value = v;\n\n\tif (dn->valid_case) {\n\t\tunsigned int i;\n\t\tfor (i = 0; i < dn->comp_num; i++) {\n\t\t\tLDB_FREE(dn->components[i].cf_name);\n\t\t\tLDB_FREE(dn->components[i].cf_value.data);\n\t\t}\n\t\tdn->valid_case = false;\n\t}\n\tLDB_FREE(dn->casefold);\n\tLDB_FREE(dn->linearized);\n\n\t\/* Wipe the ext_linearized DN,\n\t * the GUID and SID are almost certainly no longer valid *\/\n\tLDB_FREE(dn->ext_linearized);\n\tLDB_FREE(dn->ext_components);\n\tdn->ext_comp_num = 0;\n\n\treturn LDB_SUCCESS;\n}\n","idx":2361,"target":0}
{"code":" char *ldb_dn_escape_value(TALLOC_CTX *mem_ctx, struct ldb_val value)\n {\n        char *dst;\n        if (!value.length)\n                return NULL;\n \n\t\/* allocate destination string, it will be at most 3 times the source *\/\n\tdst = talloc_array(mem_ctx, char, value.length * 3 + 1);\n\tif ( ! dst) {\n\t\ttalloc_free(dst);\n                return NULL;\n        }\n \n       ldb_dn_escape_internal(dst, (const char *)value.data, value.length);\n       dst = talloc_realloc(mem_ctx, dst, char, strlen(dst) + 1);\n \n        return dst;\n }\n","idx":177846,"target":1}
{"code":"static MagickBooleanType CheckMemoryOverflow(const size_t count,\n  const size_t quantum)\n{\n  size_t\n    size;\n  size=count*quantum;\n  if ((count == 0) || (quantum != (size\/count)))\n    {\n      errno=ENOMEM;\n      return(MagickTrue);\n    }\n  return(MagickFalse);\n}\n","idx":181711,"target":1}
{"code":"MagickExport void CatchException(ExceptionInfo *exception)\n{\n   register const ExceptionInfo\n     *p;\n \n   assert(exception != (ExceptionInfo *) NULL);\n   assert(exception->signature == MagickSignature);\n   if (exception->exceptions  == (void *) NULL)\n    return;\n  LockSemaphoreInfo(exception->semaphore);\n   ResetLinkedListIterator((LinkedListInfo *) exception->exceptions);\n   p=(const ExceptionInfo *) GetNextValueInLinkedList((LinkedListInfo *)\n     exception->exceptions);\n  while (p != (const ExceptionInfo *) NULL)\n   {\n    if ((p->severity >= WarningException) && (p->severity < ErrorException))\n      MagickWarning(p->severity,p->reason,p->description);\n    if ((p->severity >= ErrorException) && (p->severity < FatalErrorException))\n      MagickError(p->severity,p->reason,p->description);\n     if (p->severity >= FatalErrorException)\n       MagickFatalError(p->severity,p->reason,p->description);\n     p=(const ExceptionInfo *) GetNextValueInLinkedList((LinkedListInfo *)\n       exception->exceptions);\n   }\n  UnlockSemaphoreInfo(exception->semaphore);\n  ClearMagickException(exception);\n}\n","idx":181713,"target":1}
{"code":" MagickExport void *AcquireAlignedMemory(const size_t count,const size_t quantum)\n {\n #define AlignedExtent(size,alignment) \\\n  (((size)+((alignment)-1)) & ~((alignment)-1))\n\n  size_t\n    alignment,\n    extent,\n    size;\n\n   void\n     *memory;\n \n  if (CheckMemoryOverflow(count,quantum) != MagickFalse)\n     return((void *) NULL);\n   memory=NULL;\n   alignment=CACHE_LINE_SIZE;\n  size=count*quantum;\n  extent=AlignedExtent(size,alignment);\n  if ((size == 0) || (alignment < sizeof(void *)) || (extent < size))\n    return((void *) NULL);\n#if defined(MAGICKCORE_HAVE_POSIX_MEMALIGN)\n  if (posix_memalign(&memory,alignment,extent) != 0)\n    memory=NULL;\n#elif defined(MAGICKCORE_HAVE__ALIGNED_MALLOC)\n  memory=_aligned_malloc(extent,alignment);\n#else\n  {\n    void\n      *p;\n\n    extent=(size+alignment-1)+sizeof(void *);\n    if (extent > size)\n      {\n        p=malloc(extent);\n        if (p != NULL)\n          {\n            memory=(void *) AlignedExtent((size_t) p+sizeof(void *),alignment);\n            *((void **) memory-1)=p;\n          }\n      }\n  }\n#endif\n  return(memory);\n}\n","idx":181714,"target":1}
{"code":"MagickExport void *AcquireQuantumMemory(const size_t count,const size_t quantum)\n{\n   size_t\n     extent;\n \n  if (CheckMemoryOverflow(count,quantum) != MagickFalse)\n     return((void *) NULL);\n   extent=count*quantum;\n   return(AcquireMagickMemory(extent));\n}\n","idx":181715,"target":1}
{"code":"MagickExport void *ResizeQuantumMemory(void *memory,const size_t count,\n  const size_t quantum)\n{\n   size_t\n     extent;\n \n  if (CheckMemoryOverflow(count,quantum) != MagickFalse)\n     {\n       memory=RelinquishMagickMemory(memory);\n       return((void *) NULL);\n    }\n  extent=count*quantum;\n  return(ResizeMagickMemory(memory,extent));\n}\n","idx":181717,"target":1}
{"code":"static int svc_can_register(const uint16_t *name, size_t name_len, pid_t spid, uid_t uid)\n\n {\n     const char *perm = \"add\";\n \n    if (uid >= AID_APP) {\n         return 0; \/* Don't allow apps to register services *\/\n     }\n \n return check_mac_perms_from_lookup(spid, uid, perm, str8(name, name_len)) ? 1 : 0;\n}\n","idx":187425,"target":1}
{"code":"Chapters::Atom::Atom()\n{\n }\n","idx":188260,"target":1}
{"code":"AudioTrack::AudioTrack(\n    Segment* pSegment,\n    long long element_start,\n    long long element_size) :\n    Track(pSegment, element_start, element_size)\n{\n}\n","idx":188261,"target":1}
{"code":"Block::Block(long long start, long long size_, long long discard_padding) :\n    m_start(start),\n    m_size(size_),\n    m_track(0),\n    m_timecode(-1),\n    m_flags(0),\n    m_frames(NULL),\n    m_frame_count(-1),\n    m_discard_padding(discard_padding)\n{\n}\n","idx":188262,"target":1}
{"code":"BlockEntry::BlockEntry(Cluster* p, long idx) :\n    m_pCluster(p),\n    m_index(idx)\n{\n }\n","idx":188263,"target":1}
{"code":"BlockGroup::BlockGroup(\n    Cluster* pCluster,\n    long idx,\n    long long block_start,\n    long long block_size,\n    long long prev,\n    long long next,\n    long long duration,\n    long long discard_padding) :\n    BlockEntry(pCluster, idx),\n    m_block(block_start, block_size, discard_padding),\n    m_prev(prev),\n    m_next(next),\n    m_duration(duration)\n{\n}\n","idx":188264,"target":1}
{"code":"Chapters::Chapters(\n    Segment* pSegment,\n    long long payload_start,\n    long long payload_size,\n    long long element_start,\n    long long element_size) :\n    m_pSegment(pSegment),\n    m_start(payload_start),\n    m_size(payload_size),\n    m_element_start(element_start),\n    m_element_size(element_size),\n    m_editions(NULL),\n    m_editions_size(0),\n    m_editions_count(0)\n{\n}\n","idx":188265,"target":1}
{"code":"void Chapters::Edition::Clear()\n{\n    while (m_atoms_count > 0)\n    {\n        Atom& a = m_atoms[--m_atoms_count];\n        a.Clear();\n     }\n \n    delete[] m_atoms;\n    m_atoms = NULL;\n \n    m_atoms_size = 0;\n }\n","idx":188266,"target":1}
{"code":"void Chapters::Atom::Clear()\n{\n    delete[] m_string_uid;\n    m_string_uid = NULL;\n    while (m_displays_count > 0)\n    {\n        Display& d = m_displays[--m_displays_count];\n        d.Clear();\n    }\n    delete[] m_displays;\n    m_displays = NULL;\n    m_displays_size = 0;\n}\n","idx":188267,"target":1}
{"code":"void Chapters::Display::Clear()\n{\n    delete[] m_string;\n    m_string = NULL;\n    delete[] m_language;\n    m_language = NULL;\n    delete[] m_country;\n    m_country = NULL;\n}\n","idx":188268,"target":1}
{"code":"void Track::Info::Clear()\n{\n    delete[] nameAsUTF8;\n    nameAsUTF8 = NULL;\n \n    delete[] language;\n    language = NULL;\n \n    delete[] codecId;\n    codecId = NULL;\n    delete[] codecPrivate;\n    codecPrivate = NULL;\n    codecPrivateSize = 0;\n    delete[] codecNameAsUTF8;\n    codecNameAsUTF8 = NULL;\n}\n","idx":188269,"target":1}
{"code":"Cluster::Cluster() :\n    m_pSegment(NULL),\n    m_element_start(0),\n    m_index(0),\n    m_pos(0),\n    m_element_size(0),\n    m_timecode(0),\n    m_entries(NULL),\n    m_entries_size(0),\n    m_entries_count(0)  \/\/means \"no entries\"\n{\n}\n","idx":188270,"target":1}
{"code":"Cluster::Cluster(\n    Segment* pSegment,\n    long idx,\n    long long element_start\n    \/* long long element_size *\/ ) :\n    m_pSegment(pSegment),\n    m_element_start(element_start),\n    m_index(idx),\n    m_pos(element_start),\n    m_element_size(-1 \/* element_size *\/ ),\n    m_timecode(-1),\n    m_entries(NULL),\n    m_entries_size(0),\n    m_entries_count(-1)  \/\/means \"has not been parsed yet\"\n{\n}\n","idx":188271,"target":1}
{"code":" ContentEncoding::ContentCompression::ContentCompression()\n    : algo(0),\n      settings(NULL),\n      settings_len(0) {\n}\n","idx":188272,"target":1}
{"code":" ContentEncoding::ContentEncoding()\n : compression_entries_(NULL),\n      compression_entries_end_(NULL),\n      encryption_entries_(NULL),\n\n       encryption_entries_end_(NULL),\n       encoding_order_(0),\n       encoding_scope_(1),\n      encoding_type_(0) {\n}\n","idx":188273,"target":1}
{"code":" ContentEncoding::ContentEncryption::ContentEncryption()\n : algo(0),\n      key_id(NULL),\n      key_id_len(0),\n      signature(NULL),\n      signature_len(0),\n\n       sig_key_id(NULL),\n       sig_key_id_len(0),\n       sig_algo(0),\n      sig_hash_algo(0) {\n}\n","idx":188274,"target":1}
{"code":"long Track::Create(\n    Segment* pSegment,\n    const Info& info,\n    long long element_start,\n    long long element_size,\n    Track*& pResult)\n{\n    if (pResult)\n        return -1;\n \n    Track* const pTrack = new (std::nothrow) Track(pSegment,\n                                                   element_start,\n                                                   element_size);\n \n    if (pTrack == NULL)\n        return -1;  \/\/generic error\n \n    const int status = info.Copy(pTrack->m_info);\n \n    if (status)  \/\/ error\n    {\n        delete pTrack;\n        return status;\n    }\n \n    pResult = pTrack;\n    return 0;  \/\/success\n }\n","idx":188277,"target":1}
{"code":"long Cluster::CreateSimpleBlock(\n    long long st,\n    long long sz)\n{\n    assert(m_entries);\n    assert(m_entries_size > 0);\n    assert(m_entries_count >= 0);\n    assert(m_entries_count < m_entries_size);\n    const long idx = m_entries_count;\n    BlockEntry** const ppEntry = m_entries + idx;\n    BlockEntry*& pEntry = *ppEntry;\n    pEntry = new (std::nothrow) SimpleBlock(this, idx, st, sz);\n    if (pEntry == NULL)\n        return -1;  \/\/generic error\n    SimpleBlock* const p = static_cast<SimpleBlock*>(pEntry);\n    const long status = p->Parse();\n    if (status == 0)\n    {\n        ++m_entries_count;\n        return 0;\n    }\n    delete pEntry;\n    pEntry = 0;\n    return status;\n}\n","idx":188282,"target":1}
{"code":"CuePoint::CuePoint(long idx, long long pos) :\n    m_element_start(0),\n    m_element_size(0),\n    m_index(idx),\n    m_timecode(-1 * pos),\n    m_track_positions(NULL),\n    m_track_positions_count(0)\n{\n    assert(pos > 0);\n }\n","idx":188283,"target":1}
{"code":"Cues::Cues(\n    Segment* pSegment,\n    long long start_,\n    long long size_,\n    long long element_start,\n    long long element_size) :\n    m_pSegment(pSegment),\n    m_start(start_),\n    m_size(size_),\n    m_element_start(element_start),\n    m_element_size(element_size),\n    m_cue_points(NULL),\n    m_count(0),\n    m_preload_count(0),\n    m_pos(start_)\n{\n }\n","idx":188284,"target":1}
{"code":"Chapters::Display::Display()\n{\n}\n","idx":188285,"target":1}
{"code":"bool Cues::DoneParsing() const\n{\n    const long long stop = m_start + m_size;\n    return (m_pos >= stop);\n}\n","idx":188289,"target":1}
{"code":"bool Segment::DoneParsing() const\n{\n    if (m_size < 0)\n    {\n        long long total, avail;\n \n        const int status = m_pReader->Length(&total, &avail);\n \n        if (status < 0)  \/\/error\n            return true;  \/\/must assume done\n \n        if (total < 0)\n            return false;  \/\/assume live stream\n \n        return (m_pos >= total);\n    }\n \n    const long long stop = m_start + m_size;\n \n    return (m_pos >= stop);\n }\n","idx":188290,"target":1}
{"code":"EBMLHeader::EBMLHeader() :\n    m_docType(NULL)\n{\n    Init();\n}\n","idx":188291,"target":1}
{"code":"bool Cluster::EOS() const\n\/\/\/\/ long long element_size)\n {\n    return (m_pSegment == NULL);\n }\n","idx":188292,"target":1}
{"code":"bool BlockEntry::EOS() const\n{\n    return (GetKind() == kBlockEOS);\n}\n","idx":188293,"target":1}
{"code":"Track::EOSBlock::EOSBlock() :\n    BlockEntry(NULL, LONG_MIN)\n{\n}\n","idx":188294,"target":1}
{"code":"Chapters::Edition::Edition()\n{\n }\n","idx":188295,"target":1}
{"code":"bool Chapters::Edition::ExpandAtomsArray()\n{\n    if (m_atoms_size > m_atoms_count)\n        return true;  \/\/ nothing else to do\n \n    const int size = (m_atoms_size == 0) ? 1 : 2 * m_atoms_size;\n \n    Atom* const atoms = new (std::nothrow) Atom[size];\n \n    if (atoms == NULL)\n        return false;\n \n    for (int idx = 0; idx < m_atoms_count; ++idx)\n    {\n        m_atoms[idx].ShallowCopy(atoms[idx]);\n     }\n \n    delete[] m_atoms;\n    m_atoms = atoms;\n \n    m_atoms_size = size;\n    return true;\n }\n","idx":188296,"target":1}
{"code":"bool Chapters::Atom::ExpandDisplaysArray()\n{\n    if (m_displays_size > m_displays_count)\n        return true;  \/\/ nothing else to do\n    const int size = (m_displays_size == 0) ? 1 : 2 * m_displays_size;\n    Display* const displays = new (std::nothrow) Display[size];\n    if (displays == NULL)\n        return false;\n    for (int idx = 0; idx < m_displays_count; ++idx)\n    {\n        m_displays[idx].ShallowCopy(displays[idx]);\n    }\n    delete[] m_displays;\n    m_displays = displays;\n    m_displays_size = size;\n    return true;\n}\n","idx":188297,"target":1}
{"code":"bool Chapters::ExpandEditionsArray()\n{\n    if (m_editions_size > m_editions_count)\n        return true;  \/\/ nothing else to do\n \n    const int size = (m_editions_size == 0) ? 1 : 2 * m_editions_size;\n \n    Edition* const editions = new (std::nothrow) Edition[size];\n \n    if (editions == NULL)\n        return false;\n \n    for (int idx = 0; idx < m_editions_count; ++idx)\n    {\n        m_editions[idx].ShallowCopy(editions[idx]);\n     }\n \n    delete[] m_editions;\n    m_editions = editions;\n \n    m_editions_size = size;\n    return true;\n }\n","idx":188298,"target":1}
{"code":"bool Cues::Find(\n    long long time_ns,\n    const Track* pTrack,\n    const CuePoint*& pCP,\n    const CuePoint::TrackPosition*& pTP) const\n{\n    assert(time_ns >= 0);\n    assert(pTrack);\n \n #if 0\n     LoadCuePoint();  \/\/establish invariant\n\n    assert(m_cue_points);\n    assert(m_count > 0);\n\n CuePoint** const ii = m_cue_points;\n CuePoint** i = ii;\n\n CuePoint** const jj = ii + m_count + m_preload_count;\n CuePoint** j = jj;\n\n    pCP = *i;\n    assert(pCP);\n\n if (time_ns <= pCP->GetTime(m_pSegment))\n {\n        pTP = pCP->Find(pTrack);\n return (pTP != NULL);\n }\n\n IMkvReader* const pReader = m_pSegment->m_pReader;\n\n while (i < j)\n {\n\n CuePoint** const k = i + (j - i) \/ 2;\n        assert(k < jj);\n\n CuePoint* const pCP = *k;\n        assert(pCP);\n\n        pCP->Load(pReader);\n\n const long long t = pCP->GetTime(m_pSegment);\n\n if (t <= time_ns)\n            i = k + 1;\n else\n            j = k;\n\n        assert(i <= j);\n }\n\n    assert(i == j);\n    assert(i <= jj);\n    assert(i > ii);\n\n    pCP = *--i;\n\n     assert(pCP);\n     assert(pCP->GetTime(m_pSegment) <= time_ns);\n #else\n    if (m_cue_points == NULL)\n        return false;\n \n    if (m_count == 0)\n        return false;\n \n    CuePoint** const ii = m_cue_points;\n    CuePoint** i = ii;\n \n    CuePoint** const jj = ii + m_count;\n    CuePoint** j = jj;\n \n    pCP = *i;\n    assert(pCP);\n \n    if (time_ns <= pCP->GetTime(m_pSegment))\n    {\n        pTP = pCP->Find(pTrack);\n        return (pTP != NULL);\n    }\n    while (i < j)\n    {\n        CuePoint** const k = i + (j - i) \/ 2;\n        assert(k < jj);\n        CuePoint* const pCP = *k;\n        assert(pCP);\n        const long long t = pCP->GetTime(m_pSegment);\n        if (t <= time_ns)\n            i = k + 1;\n        else\n            j = k;\n        assert(i <= j);\n    }\n    assert(i == j);\n    assert(i <= jj);\n    assert(i > ii);\n    pCP = *--i;\n    assert(pCP);\n    assert(pCP->GetTime(m_pSegment) <= time_ns);\n#endif\n     pTP = pCP->Find(pTrack);\n     return (pTP != NULL);\n}\n","idx":188299,"target":1}
{"code":"const CuePoint::TrackPosition* CuePoint::Find(const Track* pTrack) const\n{\n    assert(pTrack);\n \n    const long long n = pTrack->GetNumber();\n \n    const TrackPosition* i = m_track_positions;\n    const TrackPosition* const j = i + m_track_positions_count;\n \n    while (i != j)\n    {\n        const TrackPosition& p = *i++;\n \n        if (p.m_track == n)\n            return &p;\n    }\n    return NULL;  \/\/no matching track number found\n }\n","idx":188300,"target":1}
{"code":"const Cluster* Segment::FindCluster(long long time_ns) const\n{\n    if ((m_clusters == NULL) || (m_clusterCount <= 0))\n        return &m_eos;\n \n    {\n        Cluster* const pCluster = m_clusters[0];\n        assert(pCluster);\n        assert(pCluster->m_index == 0);\n \n        if (time_ns <= pCluster->GetTime())\n            return pCluster;\n    }\n \n \n    long i = 0;\n    long j = m_clusterCount;\n \n    while (i < j)\n    {\n        const long k = i + (j - i) \/ 2;\n        assert(k < m_clusterCount);\n        Cluster* const pCluster = m_clusters[k];\n        assert(pCluster);\n        assert(pCluster->m_index == k);\n        const long long t = pCluster->GetTime();\n        if (t <= time_ns)\n            i = k + 1;\n        else\n            j = k;\n        assert(i <= j);\n    }\n    assert(i == j);\n    assert(i > 0);\n    assert(i <= m_clusterCount);\n    const long k = i - 1;\n \n     Cluster* const pCluster = m_clusters[k];\n     assert(pCluster);\n     assert(pCluster->m_index == k);\n    assert(pCluster->GetTime() <= time_ns);\n \n    return pCluster;\n }\n","idx":188301,"target":1}
{"code":"const Chapters::Atom* Chapters::Edition::GetAtom(int index) const\n{\n    if (index < 0)\n        return NULL;\n \n    if (index >= m_atoms_count)\n        return NULL;\n \n    return m_atoms + index;\n }\n","idx":188303,"target":1}
{"code":"int Chapters::Edition::GetAtomCount() const\n{\n    return m_atoms_count;\n }\n","idx":188304,"target":1}
{"code":"long long AudioTrack::GetBitDepth() const\n{\n    return m_bitDepth;\n}\n","idx":188305,"target":1}
{"code":"const Block* Track::EOSBlock::GetBlock() const\n{\n    return NULL;\n}\n","idx":188306,"target":1}
{"code":"const Block* SimpleBlock::GetBlock() const\n{\n    return &m_block;\n}\n","idx":188307,"target":1}
{"code":"long long AudioTrack::GetChannels() const\n{\n    return m_channels;\n }\n","idx":188311,"target":1}
{"code":"const Chapters* Segment::GetChapters() const\n{\n  return m_pChapters;\n}\n","idx":188312,"target":1}
{"code":"const Cluster* BlockEntry::GetCluster() const\n{\n    return m_pCluster;\n}\n","idx":188313,"target":1}
{"code":"unsigned long long Track::GetCodecDelay() const\n{\n    return m_info.codecDelay;\n}\n","idx":188314,"target":1}
{"code":"const char* Track::GetCodecId() const\n{\n    return m_info.codecId;\n}\n","idx":188315,"target":1}
{"code":"const char* Track::GetCodecNameAsUTF8() const\n{\n    return m_info.codecNameAsUTF8;\n}\n","idx":188316,"target":1}
{"code":"const unsigned char* Track::GetCodecPrivate(size_t& size) const\n{\n    size = m_info.codecPrivateSize;\n    return m_info.codecPrivate;\n}\n","idx":188317,"target":1}
{"code":"Track::GetContentEncodingByIndex(unsigned long idx) const {\n   const ptrdiff_t count =\n       content_encoding_entries_end_ - content_encoding_entries_;\n   assert(count >= 0);\n\n if (idx >= static_cast<unsigned long>(count))\n return NULL;\n\n return content_encoding_entries_[idx];\n}\n","idx":188318,"target":1}
{"code":"int SeekHead::GetCount() const\n{\n    return m_entry_count;\n }\n","idx":188319,"target":1}
{"code":"long Cues::GetCount() const\n{\n    if (m_cue_points == NULL)\n        return -1;\n \n    return m_count;  \/\/TODO: really ignore preload count?\n}\n","idx":188320,"target":1}
{"code":"unsigned long Segment::GetCount() const\n{\n    return m_clusterCount;\n}\n","idx":188321,"target":1}
{"code":"const char* Chapters::Display::GetCountry() const\n{\n    return m_country;\n}\n","idx":188322,"target":1}
{"code":"const Cues* Segment::GetCues() const\n{\n    return m_pCues;\n}\n","idx":188323,"target":1}
{"code":"unsigned long long Track::GetDefaultDuration() const\n{\n    return m_info.defaultDuration;\n}\n","idx":188324,"target":1}
{"code":"long long Block::GetDiscardPadding() const\n{\n    return m_discard_padding;\n}\n","idx":188325,"target":1}
{"code":"const Chapters::Display* Chapters::Atom::GetDisplay(int index) const\n{\n    if (index < 0)\n        return NULL;\n    if (index >= m_displays_count)\n        return NULL;\n    return m_displays + index;\n}\n","idx":188326,"target":1}
{"code":"int Chapters::Atom::GetDisplayCount() const\n{\n    return m_displays_count;\n}\n","idx":188327,"target":1}
{"code":"long long Segment::GetDuration() const\n{\n    assert(m_pInfo);\n    return m_pInfo->GetDuration();\n}\n","idx":188328,"target":1}
{"code":"long long SegmentInfo::GetDuration() const\n{\n    if (m_duration < 0)\n        return -1;\n    assert(m_timecodeScale >= 1);\n    const double dd = double(m_duration) * double(m_timecodeScale);\n    const long long d = static_cast<long long>(dd);\n    return d;\n}\n","idx":188329,"target":1}
{"code":"long long BlockGroup::GetDurationTimeCode() const\n{\n    return m_duration;\n}\n","idx":188330,"target":1}
{"code":"const BlockEntry* Track::GetEOS() const\n{\n    return &m_eos;\n}\n","idx":188331,"target":1}
{"code":"const Chapters::Edition* Chapters::GetEdition(int idx) const\n{\n    if (idx < 0)\n        return NULL;\n \n    if (idx >= m_editions_count)\n        return NULL;\n \n    return m_editions + idx;\n }\n","idx":188332,"target":1}
{"code":"ProcXSendExtensionEvent(ClientPtr client)\n{\n    int ret;\n    DeviceIntPtr dev;\n    xEvent *first;\n    XEventClass *list;\n    struct tmask tmp[EMASKSIZE];\n\n    REQUEST(xSendExtensionEventReq);\n    REQUEST_AT_LEAST_SIZE(xSendExtensionEventReq);\n\n    if (stuff->length !=\n        bytes_to_int32(sizeof(xSendExtensionEventReq)) + stuff->count +\n        (stuff->num_events * bytes_to_int32(sizeof(xEvent))))\n        return BadLength;\n\n    ret = dixLookupDevice(&dev, stuff->deviceid, client, DixWriteAccess);\n    if (ret != Success)\n        return ret;\n\n    if (stuff->num_events == 0)\n        return ret;\n\n    \/* The client's event type must be one defined by an extension. *\/\n\n    first = ((xEvent *) &stuff[1]);\n    if (!((EXTENSION_EVENT_BASE <= first->u.u.type) &&\n          (first->u.u.type < lastEvent))) {\n        client->errorValue = first->u.u.type;\n        return BadValue;\n    }\n\n    list = (XEventClass *) (first + stuff->num_events);\n    if ((ret = CreateMaskFromList(client, list, stuff->count, tmp, dev,\n                                  X_SendExtensionEvent)) != Success)\n        return ret;\n\n    ret = (SendEvent(client, dev, stuff->destination,\n                     stuff->propagate, (xEvent *) &stuff[1],\n                     tmp[stuff->deviceid].mask, stuff->num_events));\n\n    return ret;\n}\n","idx":4784,"target":0}
{"code":"  CFF_Done_FD_Select( CFF_FDSelect  fdselect,\n                      FT_Stream     stream )\n  {\n    if ( fdselect->data )\n      FT_FRAME_RELEASE( fdselect->data );\n\n    fdselect->data_size   = 0;\n    fdselect->format      = 0;\n    fdselect->range_count = 0;\n  }\n","idx":4207,"target":0}
{"code":"  CFF_Load_FD_Select( CFF_FDSelect  fdselect,\n                      FT_UInt       num_glyphs,\n                      FT_Stream     stream,\n                      FT_ULong      offset )\n  {\n    FT_Error  error;\n    FT_Byte   format;\n    FT_UInt   num_ranges;\n\n\n    \/* read format *\/\n    if ( FT_STREAM_SEEK( offset ) || FT_READ_BYTE( format ) )\n      goto Exit;\n\n    fdselect->format      = format;\n    fdselect->cache_count = 0;   \/* clear cache *\/\n\n    switch ( format )\n    {\n    case 0:     \/* format 0, that's simple *\/\n      fdselect->data_size = num_glyphs;\n      goto Load_Data;\n\n    case 3:     \/* format 3, a tad more complex *\/\n      if ( FT_READ_USHORT( num_ranges ) )\n        goto Exit;\n\n      fdselect->data_size = num_ranges * 3 + 2;\n\n    Load_Data:\n      if ( FT_FRAME_EXTRACT( fdselect->data_size, fdselect->data ) )\n        goto Exit;\n      break;\n\n    default:    \/* hmm... that's wrong *\/\n      error = CFF_Err_Invalid_File_Format;\n    }\n\n  Exit:\n    return error;\n  }\n","idx":4208,"target":0}
{"code":"  cff_charset_compute_cids( CFF_Charset  charset,\n                            FT_UInt      num_glyphs,\n                            FT_Memory    memory )\n  {\n    FT_Error   error   = FT_Err_Ok;\n    FT_UInt    i;\n    FT_UShort  max_cid = 0;\n\n\n    if ( charset->max_cid > 0 )\n      goto Exit;\n\n    for ( i = 0; i < num_glyphs; i++ )\n      if ( charset->sids[i] > max_cid )\n        max_cid = charset->sids[i];\n    max_cid++;\n\n    if ( FT_NEW_ARRAY( charset->cids, max_cid ) )\n      goto Exit;\n\n    for ( i = 0; i < num_glyphs; i++ )\n      charset->cids[charset->sids[i]] = (FT_UShort)i;\n\n    charset->max_cid    = max_cid;\n    charset->num_glyphs = num_glyphs;\n\n  Exit:\n    return error;\n  }\n","idx":4209,"target":0}
{"code":"  cff_charset_done( CFF_Charset  charset,\n                    FT_Stream    stream )\n  {\n    FT_Memory  memory = stream->memory;\n\n\n    cff_charset_free_cids( charset, memory );\n\n    FT_FREE( charset->sids );\n    charset->format = 0;\n    charset->offset = 0;\n  }\n","idx":4210,"target":0}
{"code":"  cff_charset_free_cids( CFF_Charset  charset,\n                         FT_Memory    memory )\n  {\n    FT_FREE( charset->cids );\n    charset->max_cid = 0;\n  }\n","idx":4211,"target":0}
{"code":"  cff_fd_select_get( CFF_FDSelect  fdselect,\n                     FT_UInt       glyph_index )\n  {\n    FT_Byte  fd = 0;\n\n\n    switch ( fdselect->format )\n    {\n    case 0:\n      fd = fdselect->data[glyph_index];\n      break;\n\n    case 3:\n      \/* first, compare to cache *\/\n      if ( (FT_UInt)( glyph_index - fdselect->cache_first ) <\n                        fdselect->cache_count )\n      {\n        fd = fdselect->cache_fd;\n        break;\n      }\n\n      \/* then, lookup the ranges array *\/\n      {\n        FT_Byte*  p       = fdselect->data;\n        FT_Byte*  p_limit = p + fdselect->data_size;\n        FT_Byte   fd2;\n        FT_UInt   first, limit;\n\n\n        first = FT_NEXT_USHORT( p );\n        do\n        {\n          if ( glyph_index < first )\n            break;\n\n          fd2   = *p++;\n          limit = FT_NEXT_USHORT( p );\n\n          if ( glyph_index < limit )\n          {\n            fd = fd2;\n\n            \/* update cache *\/\n            fdselect->cache_first = first;\n            fdselect->cache_count = limit-first;\n            fdselect->cache_fd    = fd2;\n            break;\n          }\n          first = limit;\n\n        } while ( p < p_limit );\n      }\n      break;\n\n    default:\n      ;\n    }\n\n    return fd;\n  }\n","idx":4212,"target":0}
{"code":"  cff_get_standard_encoding( FT_UInt  charcode )\n  {\n    return (FT_UShort)( charcode < 256 ? cff_standard_encoding[charcode]\n                                       : 0 );\n  }\n","idx":4213,"target":0}
{"code":"  cff_index_access_element( CFF_Index  idx,\n                            FT_UInt    element,\n                            FT_Byte**  pbytes,\n                            FT_ULong*  pbyte_len )\n  {\n    FT_Error  error = CFF_Err_Ok;\n\n\n    if ( idx && idx->count > element )\n    {\n      \/* compute start and end offsets *\/\n      FT_Stream  stream = idx->stream;\n      FT_ULong   off1, off2 = 0;\n\n\n      \/* load offsets from file or the offset table *\/\n      if ( !idx->offsets )\n      {\n        FT_ULong  pos = element * idx->off_size;\n\n\n        if ( FT_STREAM_SEEK( idx->start + 3 + pos ) )\n          goto Exit;\n\n        off1 = cff_index_read_offset( idx, &error );\n        if ( error )\n          goto Exit;\n\n        if ( off1 != 0 )\n        {\n          do\n          {\n            element++;\n            off2 = cff_index_read_offset( idx, &error );\n          }\n          while ( off2 == 0 && element < idx->count );\n        }\n      }\n      else   \/* use offsets table *\/\n      {\n        off1 = idx->offsets[element];\n        if ( off1 )\n        {\n          do\n          {\n            element++;\n            off2 = idx->offsets[element];\n\n          } while ( off2 == 0 && element < idx->count );\n        }\n      }\n\n      \/* access element *\/\n      if ( off1 && off2 > off1 )\n      {\n        *pbyte_len = off2 - off1;\n\n        if ( idx->bytes )\n        {\n          \/* this index was completely loaded in memory, that's easy *\/\n          *pbytes = idx->bytes + off1 - 1;\n        }\n        else\n        {\n          \/* this index is still on disk\/file, access it through a frame *\/\n          if ( FT_STREAM_SEEK( idx->data_offset + off1 - 1 ) ||\n               FT_FRAME_EXTRACT( off2 - off1, *pbytes )      )\n            goto Exit;\n        }\n      }\n      else\n      {\n        \/* empty index element *\/\n        *pbytes    = 0;\n        *pbyte_len = 0;\n      }\n    }\n    else\n      error = CFF_Err_Invalid_Argument;\n\n  Exit:\n    return error;\n  }\n","idx":4214,"target":0}
{"code":"  cff_index_done( CFF_Index  idx )\n  {\n    if ( idx->stream )\n    {\n      FT_Stream  stream = idx->stream;\n      FT_Memory  memory = stream->memory;\n\n\n      if ( idx->bytes )\n        FT_FRAME_RELEASE( idx->bytes );\n\n      FT_FREE( idx->offsets );\n      FT_MEM_ZERO( idx, sizeof ( *idx ) );\n    }\n  }\n","idx":4215,"target":0}
{"code":"  cff_index_forget_element( CFF_Index  idx,\n                            FT_Byte**  pbytes )\n  {\n    if ( idx->bytes == 0 )\n    {\n      FT_Stream  stream = idx->stream;\n\n\n      FT_FRAME_RELEASE( *pbytes );\n    }\n  }\n","idx":4216,"target":0}
{"code":"  cff_index_get_name( CFF_Index  idx,\n                      FT_UInt    element )\n  {\n    FT_Memory   memory = idx->stream->memory;\n    FT_Byte*    bytes;\n    FT_ULong    byte_len;\n    FT_Error    error;\n    FT_String*  name = 0;\n\n\n    error = cff_index_access_element( idx, element, &bytes, &byte_len );\n    if ( error )\n      goto Exit;\n\n    if ( !FT_ALLOC( name, byte_len + 1 ) )\n    {\n      FT_MEM_COPY( name, bytes, byte_len );\n      name[byte_len] = 0;\n    }\n    cff_index_forget_element( idx, &bytes );\n\n  Exit:\n    return name;\n  }\n","idx":4217,"target":0}
{"code":"  cff_index_get_pointers( CFF_Index   idx,\n                          FT_Byte***  table )\n  {\n    FT_Error   error  = CFF_Err_Ok;\n    FT_Memory  memory = idx->stream->memory;\n    FT_ULong   n, offset, old_offset;\n    FT_Byte**  t;\n\n\n    *table = 0;\n\n    if ( idx->offsets == NULL )\n    {\n      error = cff_index_load_offsets( idx );\n      if ( error )\n        goto Exit;\n    }\n\n    if ( idx->count > 0 && !FT_NEW_ARRAY( t, idx->count + 1 ) )\n    {\n      old_offset = 1;\n      for ( n = 0; n <= idx->count; n++ )\n      {\n        \/* at this point, `idx->offsets' can't be NULL *\/\n        offset = idx->offsets[n];\n        if ( !offset )\n          offset = old_offset;\n\n        \/* two sanity checks for invalid offset tables *\/\n        else if ( offset < old_offset )\n          offset = old_offset;\n\n        else if ( offset - 1 >= idx->data_size && n < idx->count )\n          offset = old_offset;\n\n        t[n] = idx->bytes + offset - 1;\n\n        old_offset = offset;\n      }\n      *table = t;\n    }\n\n  Exit:\n    return error;\n  }\n","idx":4218,"target":0}
{"code":"  cff_index_get_sid_string( CFF_Index           idx,\n                            FT_UInt             sid,\n                            FT_Service_PsCMaps  psnames )\n  {\n    \/* value 0xFFFFU indicates a missing dictionary entry *\/\n    if ( sid == 0xFFFFU )\n      return 0;\n\n    \/* if it is not a standard string, return it *\/\n    if ( sid > 390 )\n      return cff_index_get_name( idx, sid - 391 );\n\n    \/* CID-keyed CFF fonts don't have glyph names *\/\n    if ( !psnames )\n      return 0;\n\n    \/* that's a standard string, fetch a copy from the PSName module *\/\n    {\n      FT_String*   name       = 0;\n      const char*  adobe_name = psnames->adobe_std_strings( sid );\n\n\n      if ( adobe_name )\n      {\n        FT_Memory  memory = idx->stream->memory;\n        FT_Error   error;\n\n\n        (void)FT_STRDUP( name, adobe_name );\n\n        FT_UNUSED( error );\n      }\n\n      return name;\n    }\n  }\n","idx":4219,"target":0}
{"code":"  cff_index_init( CFF_Index  idx,\n                  FT_Stream  stream,\n                  FT_Bool    load )\n  {\n    FT_Error   error;\n    FT_Memory  memory = stream->memory;\n    FT_UShort  count;\n\n\n    FT_MEM_ZERO( idx, sizeof ( *idx ) );\n\n    idx->stream = stream;\n    idx->start  = FT_STREAM_POS();\n    if ( !FT_READ_USHORT( count ) &&\n         count > 0                )\n    {\n      FT_Byte   offsize;\n      FT_ULong  size;\n\n\n      \/* there is at least one element; read the offset size,           *\/\n      \/* then access the offset table to compute the index's total size *\/\n      if ( FT_READ_BYTE( offsize ) )\n        goto Exit;\n\n      if ( offsize < 1 || offsize > 4 )\n      {\n        error = FT_Err_Invalid_Table;\n        goto Exit;\n      }\n\n      idx->count    = count;\n      idx->off_size = offsize;\n      size          = (FT_ULong)( count + 1 ) * offsize;\n\n      idx->data_offset = idx->start + 3 + size;\n\n      if ( FT_STREAM_SKIP( size - offsize ) )\n        goto Exit;\n\n      size = cff_index_read_offset( idx, &error );\n      if ( error )\n        goto Exit;\n\n      if ( size == 0 )\n      {\n        error = CFF_Err_Invalid_Table;\n        goto Exit;\n      }\n\n      idx->data_size = --size;\n\n      if ( load )\n      {\n        \/* load the data *\/\n        if ( FT_FRAME_EXTRACT( size, idx->bytes ) )\n          goto Exit;\n      }\n      else\n      {\n        \/* skip the data *\/\n        if ( FT_STREAM_SKIP( size ) )\n          goto Exit;\n      }\n    }\n\n  Exit:\n    if ( error )\n      FT_FREE( idx->offsets );\n\n    return error;\n  }\n","idx":4220,"target":0}
{"code":"  cff_index_load_offsets( CFF_Index  idx )\n  {\n    FT_Error   error  = CFF_Err_Ok;\n    FT_Stream  stream = idx->stream;\n    FT_Memory  memory = stream->memory;\n\n\n    if ( idx->count > 0 && idx->offsets == NULL )\n    {\n      FT_Byte    offsize = idx->off_size;\n      FT_ULong   data_size;\n      FT_Byte*   p;\n      FT_Byte*   p_end;\n      FT_ULong*  poff;\n\n\n      data_size = (FT_ULong)( idx->count + 1 ) * offsize;\n\n      if ( FT_NEW_ARRAY( idx->offsets, idx->count + 1 ) ||\n           FT_STREAM_SEEK( idx->start + 3 )             ||\n           FT_FRAME_ENTER( data_size )                  )\n        goto Exit;\n\n      poff   = idx->offsets;\n      p      = (FT_Byte*)stream->cursor;\n      p_end  = p + data_size;\n\n      switch ( offsize )\n      {\n      case 1:\n        for ( ; p < p_end; p++, poff++ )\n          poff[0] = p[0];\n        break;\n\n      case 2:\n        for ( ; p < p_end; p += 2, poff++ )\n          poff[0] = FT_PEEK_USHORT( p );\n        break;\n\n      case 3:\n        for ( ; p < p_end; p += 3, poff++ )\n          poff[0] = FT_PEEK_OFF3( p );\n        break;\n\n      default:\n        for ( ; p < p_end; p += 4, poff++ )\n          poff[0] = FT_PEEK_ULONG( p );\n      }\n\n      FT_FRAME_EXIT();\n    }\n\n  Exit:\n    if ( error )\n      FT_FREE( idx->offsets );\n\n    return error;\n  }\n","idx":4221,"target":0}
{"code":"  cff_index_read_offset( CFF_Index  idx,\n                         FT_Error  *errorp )\n  {\n    FT_Error   error;\n    FT_Stream  stream = idx->stream;\n    FT_Byte    tmp[4];\n    FT_ULong   result = 0;\n\n\n    if ( !FT_STREAM_READ( tmp, idx->off_size ) )\n    {\n      FT_Int  nn;\n\n\n      for ( nn = 0; nn < idx->off_size; nn++ )\n        result = ( result << 8 ) | tmp[nn];\n    }\n\n    *errorp = error;\n    return result;\n  }\n","idx":4222,"target":0}
{"code":"static int _assemble_line(FILE *f, char *buffer, int buf_len)\n{\n    char *p = buffer;\n    char *s, *os;\n    int used = 0;\n\n    \/* loop broken with a 'break' when a non-'\\\\n' ended line is read *\/\n\n    D((\"called.\"));\n    for (;;) {\n\tif (used >= buf_len) {\n\t    \/* Overflow *\/\n\t    D((\"_assemble_line: overflow\"));\n\t    return -1;\n\t}\n\tif (fgets(p, buf_len - used, f) == NULL) {\n\t    if (used) {\n\t\t\/* Incomplete read *\/\n\t\treturn -1;\n\t    } else {\n\t\t\/* EOF *\/\n\t\treturn 0;\n\t    }\n\t}\n\n\t\/* skip leading spaces --- line may be blank *\/\n\n\ts = p + strspn(p, \" \\n\\t\");\n\tif (*s && (*s != '#')) {\n\t    os = s;\n\n\t    \/*\n\t     * we are only interested in characters before the first '#'\n\t     * character\n\t     *\/\n\n\t    while (*s && *s != '#')\n\t\t ++s;\n\t    if (*s == '#') {\n\t\t *s = '\\0';\n\t\t used += strlen(os);\n\t\t break;                \/* the line has been read *\/\n\t    }\n\n\t    s = os;\n\n\t    \/*\n\t     * Check for backslash by scanning back from the end of\n\t     * the entered line, the '\\n' has been included since\n\t     * normally a line is terminated with this\n\t     * character. fgets() should only return one though!\n\t     *\/\n\n\t    s += strlen(s);\n\t    while (s > os && ((*--s == ' ') || (*s == '\\t')\n\t\t\t      || (*s == '\\n')));\n\n\t    \/* check if it ends with a backslash *\/\n\t    if (*s == '\\\\') {\n\t\t*s = '\\0';              \/* truncate the line here *\/\n\t\tused += strlen(os);\n\t\tp = s;                  \/* there is more ... *\/\n\t    } else {\n\t\t\/* End of the line! *\/\n\t\tused += strlen(os);\n\t\tbreak;                  \/* this is the complete line *\/\n\t    }\n\n\t} else {\n\t    \/* Nothing in this line *\/\n\t    \/* Don't move p         *\/\n\t}\n    }\n\n    return used;\n}\n","idx":6412,"target":0}
{"code":"static void   _clean_var(VAR *var)\n{\n    if (var->name) {\n      free(var->name);\n    }\n    if (var->defval && (&quote != var->defval)) {\n      free(var->defval);\n    }\n    if (var->override && (&quote != var->override)) {\n      free(var->override);\n    }\n    var->name = NULL;\n    var->value = NULL;    \/* never has memory specific to it *\/\n    var->defval = NULL;\n    var->override = NULL;\n    return;\n}\n","idx":6414,"target":0}
{"code":"static int _define_var(pam_handle_t *pamh, VAR *var)\n{\n  \/* We have a variable to define, this is a simple function *\/\n\n  char *envvar;\n  int retval = PAM_SUCCESS;\n\n  D((\"Called.\"));\n  if (asprintf(&envvar, \"%s=%s\", var->name, var->value) < 0) {\n    pam_syslog(pamh, LOG_ERR, \"out of memory\");\n    return PAM_BUF_ERR;\n  }\n\n  retval = pam_putenv(pamh, envvar);\n  _pam_drop(envvar);\n  D((\"Exit.\"));\n  return retval;\n}\n","idx":6415,"target":0}
{"code":"_pam_parse (const pam_handle_t *pamh, int flags, int argc,\n\t    const char **argv, const char **maildir, size_t *hashcount)\n{\n    int ctrl=0;\n\n    if (flags & PAM_SILENT) {\n\tctrl |= PAM_MAIL_SILENT;\n    }\n\n    *hashcount = 0;\n\n    \/* step through arguments *\/\n    for (; argc-- > 0; ++argv) {\n\n\t\/* generic options *\/\n\n\tif (!strcmp(*argv,\"debug\"))\n\t    ctrl |= PAM_DEBUG_ARG;\n\telse if (!strcmp(*argv,\"quiet\"))\n\t    ctrl |= PAM_QUIET_MAIL;\n\telse if (!strcmp(*argv,\"standard\"))\n\t    ctrl |= PAM_STANDARD_MAIL | PAM_EMPTY_TOO;\n\telse if (!strncmp(*argv,\"dir=\",4)) {\n\t    *maildir = 4 + *argv;\n\t    if (**maildir != '\\0') {\n\t\tD((\"new mail directory: %s\", *maildir));\n\t\tctrl |= PAM_NEW_MAIL_DIR;\n\t    } else {\n\t\tpam_syslog(pamh, LOG_ERR,\n\t\t\t   \"dir= specification missing argument - ignored\");\n\t    }\n\t} else if (!strncmp(*argv,\"hash=\",5)) {\n\t    char *ep = NULL;\n\t    *hashcount = strtoul(*argv+5,&ep,10);\n\t    if (!ep) {\n\t\t*hashcount = 0;\n\t    }\n\t} else if (!strcmp(*argv,\"close\")) {\n\t    ctrl |= PAM_LOGOUT_TOO;\n\t} else if (!strcmp(*argv,\"nopen\")) {\n\t    ctrl |= PAM_NO_LOGIN;\n\t} else if (!strcmp(*argv,\"noenv\")) {\n\t    ctrl |= PAM_NO_ENV;\n\t} else if (!strcmp(*argv,\"empty\")) {\n\t    ctrl |= PAM_EMPTY_TOO;\n\t} else {\n\t    pam_syslog(pamh, LOG_ERR, \"unknown option: %s\", *argv);\n\t}\n    }\n\n    if ((*hashcount != 0) && !(ctrl & PAM_NEW_MAIL_DIR)) {\n\t*maildir = DEFAULT_MAIL_DIRECTORY;\n\tctrl |= PAM_NEW_MAIL_DIR;\n    }\n\n    return ctrl;\n}\n","idx":6416,"target":0}
{"code":"static void mcf_fec_read_bd(mcf_fec_bd *bd, uint32_t addr)\n{\n    cpu_physical_memory_read(addr, bd, sizeof(*bd));\n    be16_to_cpus(&bd->flags);\n    be16_to_cpus(&bd->length);\n    be32_to_cpus(&bd->data);\n}\n","idx":8326,"target":0}
{"code":"static void mcf_fec_update(mcf_fec_state *s)\n{\n    uint32_t active;\n    uint32_t changed;\n    uint32_t mask;\n    int i;\n\n    active = s->eir & s->eimr;\n    changed = active ^s->irq_state;\n    for (i = 0; i < FEC_NUM_IRQ; i++) {\n        mask = mcf_fec_irq_map[i];\n        if (changed & mask) {\n            DPRINTF(\"IRQ %d = %d\\n\", i, (active & mask) != 0);\n            qemu_set_irq(s->irq[i], (active & mask) != 0);\n        }\n    }\n    s->irq_state = active;\n}\n","idx":8327,"target":0}
{"code":"static void mcf_fec_write_bd(mcf_fec_bd *bd, uint32_t addr)\n{\n    mcf_fec_bd tmp;\n    tmp.flags = cpu_to_be16(bd->flags);\n    tmp.length = cpu_to_be16(bd->length);\n    tmp.data = cpu_to_be32(bd->data);\n    cpu_physical_memory_write(addr, &tmp, sizeof(tmp));\n}\n","idx":8328,"target":0}
{"code":"delelement (struct fileinfo *f, struct fileinfo **start)\n{\n  struct fileinfo *prev = f->prev;\n  struct fileinfo *next = f->next;\n\n  xfree (f->name);\n  xfree (f->linkto);\n  xfree (f);\n\n  if (next)\n    next->prev = prev;\n  if (prev)\n    prev->next = next;\n  else\n    *start = next;\n  return next;\n}\n","idx":211,"target":0}
{"code":"freefileinfo (struct fileinfo *f)\n{\n  while (f)\n    {\n      struct fileinfo *next = f->next;\n      xfree (f->name);\n      if (f->linkto)\n        xfree (f->linkto);\n      xfree (f);\n      f = next;\n    }\n}\n","idx":212,"target":0}
{"code":"ftp_do_pasv (int csock, ip_address *addr, int *port)\n{\n  uerr_t err;\n\n  \/* We need to determine the address family and need to call\n     getpeername, so while we're at it, store the address to ADDR.\n     ftp_pasv and ftp_lpsv can simply override it.  *\/\n  if (!socket_ip_address (csock, addr, ENDPOINT_PEER))\n    abort ();\n\n  \/* If our control connection is over IPv6, then we first try EPSV and then\n   * LPSV if the former is not supported. If the control connection is over\n   * IPv4, we simply issue the good old PASV request. *\/\n  switch (addr->family)\n    {\n    case AF_INET:\n      if (!opt.server_response)\n        logputs (LOG_VERBOSE, \"==> PASV ... \");\n      err = ftp_pasv (csock, addr, port);\n      break;\n    case AF_INET6:\n      if (!opt.server_response)\n        logputs (LOG_VERBOSE, \"==> EPSV ... \");\n      err = ftp_epsv (csock, addr, port);\n\n      \/* If EPSV is not supported try LPSV *\/\n      if (err == FTPNOPASV)\n        {\n          if (!opt.server_response)\n            logputs (LOG_VERBOSE, \"==> LPSV ... \");\n          err = ftp_lpsv (csock, addr, port);\n        }\n      break;\n    default:\n      abort ();\n    }\n\n  return err;\n}\n","idx":213,"target":0}
{"code":"ftp_do_pasv (int csock, ip_address *addr, int *port)\n{\n  if (!opt.server_response)\n    logputs (LOG_VERBOSE, \"==> PASV ... \");\n  return ftp_pasv (csock, addr, port);\n}\n","idx":214,"target":0}
{"code":"ftp_do_port (int csock, int *local_sock)\n{\n  uerr_t err;\n  ip_address cip;\n\n  if (!socket_ip_address (csock, &cip, ENDPOINT_PEER))\n    abort ();\n\n  \/* If our control connection is over IPv6, then we first try EPRT and then\n   * LPRT if the former is not supported. If the control connection is over\n   * IPv4, we simply issue the good old PORT request. *\/\n  switch (cip.family)\n    {\n    case AF_INET:\n      if (!opt.server_response)\n        logputs (LOG_VERBOSE, \"==> PORT ... \");\n      err = ftp_port (csock, local_sock);\n      break;\n    case AF_INET6:\n      if (!opt.server_response)\n        logputs (LOG_VERBOSE, \"==> EPRT ... \");\n      err = ftp_eprt (csock, local_sock);\n\n      \/* If EPRT is not supported try LPRT *\/\n      if (err == FTPPORTERR)\n        {\n          if (!opt.server_response)\n            logputs (LOG_VERBOSE, \"==> LPRT ... \");\n          err = ftp_lprt (csock, local_sock);\n        }\n      break;\n    default:\n      abort ();\n    }\n  return err;\n}\n","idx":215,"target":0}
{"code":"ftp_do_port (int csock, int *local_sock)\n{\n  if (!opt.server_response)\n    logputs (LOG_VERBOSE, \"==> PORT ... \");\n  return ftp_port (csock, local_sock);\n}\n","idx":216,"target":0}
{"code":"ftp_expected_bytes (const char *s)\n{\n  wgint res;\n\n  while (1)\n    {\n      while (*s && *s != '(')\n        ++s;\n      if (!*s)\n        return 0;\n      ++s;                      \/* skip the '(' *\/\n      res = str_to_wgint (s, (char **) &s, 10);\n      if (!*s)\n        return 0;\n      while (*s && c_isspace (*s))\n        ++s;\n      if (!*s)\n        return 0;\n      if (c_tolower (*s) != 'b')\n        continue;\n      if (c_strncasecmp (s, \"byte\", 4))\n        continue;\n      else\n        break;\n    }\n  return res;\n}\n","idx":217,"target":0}
{"code":"ftp_get_listing (struct url *u, ccon *con, struct fileinfo **f)\n{\n  uerr_t err;\n  char *uf;                     \/* url file name *\/\n  char *lf;                     \/* list file name *\/\n  char *old_target = con->target;\n\n  con->st &= ~ON_YOUR_OWN;\n  con->cmd |= (DO_LIST | LEAVE_PENDING);\n  con->cmd &= ~DO_RETR;\n\n  \/* Find the listing file name.  We do it by taking the file name of\n     the URL and replacing the last component with the listing file\n     name.  *\/\n  uf = url_file_name (u, NULL);\n  lf = file_merge (uf, LIST_FILENAME);\n  xfree (uf);\n  DEBUGP ((_(\"Using %s as listing tmp file.\\n\"), quote (lf)));\n\n  con->target = xstrdup (lf);\n  xfree (lf);\n  err = ftp_loop_internal (u, NULL, con, NULL, false);\n  lf = xstrdup (con->target);\n  xfree (con->target);\n  con->target = old_target;\n\n  if (err == RETROK)\n    {\n      *f = ftp_parse_ls (lf, con->rs);\n      if (opt.remove_listing)\n        {\n          if (unlink (lf))\n            logprintf (LOG_NOTQUIET, \"unlink: %s\\n\", strerror (errno));\n          else\n            logprintf (LOG_VERBOSE, _(\"Removed %s.\\n\"), quote (lf));\n        }\n    }\n  else\n    *f = NULL;\n  xfree (lf);\n  con->cmd &= ~DO_LIST;\n  return err;\n}\n","idx":218,"target":0}
{"code":"ftp_retrieve_dirs (struct url *u, struct fileinfo *f, ccon *con)\n{\n  char *container = NULL;\n  int container_size = 0;\n\n  for (; f; f = f->next)\n    {\n      int size;\n      char *odir, *newdir;\n\n      if (opt.quota && total_downloaded_bytes > opt.quota)\n        break;\n      if (f->type != FT_DIRECTORY)\n        continue;\n\n      \/* Allocate u->dir off stack, but reallocate only if a larger\n         string is needed.  It's a pity there's no \"realloca\" for an\n         item on the bottom of the stack.  *\/\n      size = strlen (u->dir) + 1 + strlen (f->name) + 1;\n      if (size > container_size)\n        container = (char *)alloca (size);\n      newdir = container;\n\n      odir = u->dir;\n      if (*odir == '\\0'\n          || (*odir == '\/' && *(odir + 1) == '\\0'))\n        \/* If ODIR is empty or just \"\/\", simply append f->name to\n           ODIR.  (In the former case, to preserve u->dir being\n           relative; in the latter case, to avoid double slash.)  *\/\n        sprintf (newdir, \"%s%s\", odir, f->name);\n      else\n        \/* Else, use a separator. *\/\n        sprintf (newdir, \"%s\/%s\", odir, f->name);\n\n      DEBUGP ((\"Composing new CWD relative to the initial directory.\\n\"));\n      DEBUGP ((\"  odir = '%s'\\n  f->name = '%s'\\n  newdir = '%s'\\n\\n\",\n               odir, f->name, newdir));\n      if (!accdir (newdir))\n        {\n          logprintf (LOG_VERBOSE, _(\"\\\nNot descending to %s as it is excluded\/not-included.\\n\"),\n                     quote (newdir));\n          continue;\n        }\n\n      con->st &= ~DONE_CWD;\n\n      odir = xstrdup (u->dir);  \/* because url_set_dir will free\n                                   u->dir. *\/\n      url_set_dir (u, newdir);\n      ftp_retrieve_glob (u, con, GLOB_GETALL);\n      url_set_dir (u, odir);\n      xfree (odir);\n\n      \/* Set the time-stamp?  *\/\n    }\n\n  if (opt.quota && total_downloaded_bytes > opt.quota)\n    return QUOTEXC;\n  else\n    return RETROK;\n}\n","idx":221,"target":0}
{"code":"has_insecure_name_p (const char *s)\n{\n  if (*s == '\/')\n    return true;\n\n  if (strstr (s, \"..\/\") != 0)\n    return true;\n\n  return false;\n}\n","idx":224,"target":0}
{"code":"is_invalid_entry (struct fileinfo *f)\n{\n  struct fileinfo *cur = f;\n  char *f_name = f->name;\n\n  \/* If the node we're currently checking has a duplicate later, we eliminate\n   * the current node and leave the next one intact. *\/\n  while (cur->next)\n    {\n      cur = cur->next;\n      if (strcmp(f_name, cur->name) == 0)\n          return true;\n    }\n  return false;\n}\n","idx":225,"target":0}
{"code":"print_length (wgint size, wgint start, bool authoritative)\n{\n  logprintf (LOG_VERBOSE, _(\"Length: %s\"), number_to_static_string (size));\n  if (size >= 1024)\n    logprintf (LOG_VERBOSE, \" (%s)\", human_readable (size, 10, 1));\n  if (start > 0)\n    {\n      if (size - start >= 1024)\n        logprintf (LOG_VERBOSE, _(\", %s (%s) remaining\"),\n                   number_to_static_string (size - start),\n                   human_readable (size - start, 10, 1));\n      else\n        logprintf (LOG_VERBOSE, _(\", %s remaining\"),\n                   number_to_static_string (size - start));\n    }\n  logputs (LOG_VERBOSE, !authoritative ? _(\" (unauthoritative)\\n\") : \"\\n\");\n}\n","idx":226,"target":0}
{"code":"IsValidJsonNumber(const char *str, int len)\n{\n\tbool\t\tnumeric_error;\n\tJsonLexContext dummy_lex;\n\n\n\t\/*\n\t * json_lex_number expects a leading  '-' to have been eaten already.\n\t *\n\t * having to cast away the constness of str is ugly, but there's not much\n\t * easy alternative.\n\t *\/\n\tif (*str == '-')\n\t{\n\t\tdummy_lex.input = (char *) str + 1;\n\t\tdummy_lex.input_length = len - 1;\n\t}\n\telse\n\t{\n\t\tdummy_lex.input = (char *) str;\n\t\tdummy_lex.input_length = len;\n\t}\n\n\tjson_lex_number(&dummy_lex, dummy_lex.input, &numeric_error);\n\n\treturn !numeric_error;\n}\n","idx":2514,"target":0}
{"code":"add_json(Datum val, bool is_null, StringInfo result,\n\t\t Oid val_type, bool key_scalar)\n{\n\tJsonTypeCategory tcategory;\n\tOid\t\t\toutfuncoid;\n\n\tif (val_type == InvalidOid)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"could not determine input data type\")));\n\n\tif (is_null)\n\t{\n\t\ttcategory = JSONTYPE_NULL;\n\t\toutfuncoid = InvalidOid;\n\t}\n\telse\n\t\tjson_categorize_type(val_type,\n\t\t\t\t\t\t\t &tcategory, &outfuncoid);\n\n\tdatum_to_json(val, is_null, result, tcategory, outfuncoid, key_scalar);\n}\n","idx":2515,"target":0}
{"code":"array_dim_to_json(StringInfo result, int dim, int ndims, int *dims, Datum *vals,\n\t\t\t\t  bool *nulls, int *valcount, JsonTypeCategory tcategory,\n\t\t\t\t  Oid outfuncoid, bool use_line_feeds)\n{\n\tint\t\t\ti;\n\tconst char *sep;\n\n\tAssert(dim < ndims);\n\n\tsep = use_line_feeds ? \",\\n \" : \",\";\n\n\tappendStringInfoChar(result, '[');\n\n\tfor (i = 1; i <= dims[dim]; i++)\n\t{\n\t\tif (i > 1)\n\t\t\tappendStringInfoString(result, sep);\n\n\t\tif (dim + 1 == ndims)\n\t\t{\n\t\t\tdatum_to_json(vals[*valcount], nulls[*valcount], result, tcategory,\n\t\t\t\t\t\t  outfuncoid, false);\n\t\t\t(*valcount)++;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t\/*\n\t\t\t * Do we want line feeds on inner dimensions of arrays? For now\n\t\t\t * we'll say no.\n\t\t\t *\/\n\t\t\tarray_dim_to_json(result, dim + 1, ndims, dims, vals, nulls,\n\t\t\t\t\t\t\t  valcount, tcategory, outfuncoid, false);\n\t\t}\n\t}\n\n\tappendStringInfoChar(result, ']');\n}\n","idx":2516,"target":0}
{"code":"array_to_json_internal(Datum array, StringInfo result, bool use_line_feeds)\n{\n\tArrayType  *v = DatumGetArrayTypeP(array);\n\tOid\t\t\telement_type = ARR_ELEMTYPE(v);\n\tint\t\t   *dim;\n\tint\t\t\tndim;\n\tint\t\t\tnitems;\n\tint\t\t\tcount = 0;\n\tDatum\t   *elements;\n\tbool\t   *nulls;\n\tint16\t\ttyplen;\n\tbool\t\ttypbyval;\n\tchar\t\ttypalign;\n\tJsonTypeCategory tcategory;\n\tOid\t\t\toutfuncoid;\n\n\tndim = ARR_NDIM(v);\n\tdim = ARR_DIMS(v);\n\tnitems = ArrayGetNItems(ndim, dim);\n\n\tif (nitems <= 0)\n\t{\n\t\tappendStringInfoString(result, \"[]\");\n\t\treturn;\n\t}\n\n\tget_typlenbyvalalign(element_type,\n\t\t\t\t\t\t &typlen, &typbyval, &typalign);\n\n\tjson_categorize_type(element_type,\n\t\t\t\t\t\t &tcategory, &outfuncoid);\n\n\tdeconstruct_array(v, element_type, typlen, typbyval,\n\t\t\t\t\t  typalign, &elements, &nulls,\n\t\t\t\t\t  &nitems);\n\n\tarray_dim_to_json(result, 0, ndim, dim, elements, nulls, &count, tcategory,\n\t\t\t\t\t  outfuncoid, use_line_feeds);\n\n\tpfree(elements);\n\tpfree(nulls);\n}\n","idx":2518,"target":0}
{"code":"catenate_stringinfo_string(StringInfo buffer, const char *addon)\n{\n\t\/* custom version of cstring_to_text_with_len *\/\n\tint\t\t\tbuflen = buffer->len;\n\tint\t\t\taddlen = strlen(addon);\n\ttext\t   *result = (text *) palloc(buflen + addlen + VARHDRSZ);\n\n\tSET_VARSIZE(result, buflen + addlen + VARHDRSZ);\n\tmemcpy(VARDATA(result), buffer->data, buflen);\n\tmemcpy(VARDATA(result) + buflen, addon, addlen);\n\n\treturn result;\n}\n","idx":2520,"target":0}
{"code":"composite_to_json(Datum composite, StringInfo result, bool use_line_feeds)\n{\n\tHeapTupleHeader td;\n\tOid\t\t\ttupType;\n\tint32\t\ttupTypmod;\n\tTupleDesc\ttupdesc;\n\tHeapTupleData tmptup,\n\t\t\t   *tuple;\n\tint\t\t\ti;\n\tbool\t\tneedsep = false;\n\tconst char *sep;\n\n\tsep = use_line_feeds ? \",\\n \" : \",\";\n\n\ttd = DatumGetHeapTupleHeader(composite);\n\n\t\/* Extract rowtype info and find a tupdesc *\/\n\ttupType = HeapTupleHeaderGetTypeId(td);\n\ttupTypmod = HeapTupleHeaderGetTypMod(td);\n\ttupdesc = lookup_rowtype_tupdesc(tupType, tupTypmod);\n\n\t\/* Build a temporary HeapTuple control structure *\/\n\ttmptup.t_len = HeapTupleHeaderGetDatumLength(td);\n\ttmptup.t_data = td;\n\ttuple = &tmptup;\n\n\tappendStringInfoChar(result, '{');\n\n\tfor (i = 0; i < tupdesc->natts; i++)\n\t{\n\t\tDatum\t\tval;\n\t\tbool\t\tisnull;\n\t\tchar\t   *attname;\n\t\tJsonTypeCategory tcategory;\n\t\tOid\t\t\toutfuncoid;\n\n\t\tif (tupdesc->attrs[i]->attisdropped)\n\t\t\tcontinue;\n\n\t\tif (needsep)\n\t\t\tappendStringInfoString(result, sep);\n\t\tneedsep = true;\n\n\t\tattname = NameStr(tupdesc->attrs[i]->attname);\n\t\tescape_json(result, attname);\n\t\tappendStringInfoChar(result, ':');\n\n\t\tval = heap_getattr(tuple, i + 1, tupdesc, &isnull);\n\n\t\tif (isnull)\n\t\t{\n\t\t\ttcategory = JSONTYPE_NULL;\n\t\t\toutfuncoid = InvalidOid;\n\t\t}\n\t\telse\n\t\t\tjson_categorize_type(tupdesc->attrs[i]->atttypid,\n\t\t\t\t\t\t\t\t &tcategory, &outfuncoid);\n\n\t\tdatum_to_json(val, isnull, result, tcategory, outfuncoid, false);\n\t}\n\n\tappendStringInfoChar(result, '}');\n\tReleaseTupleDesc(tupdesc);\n}\n","idx":2521,"target":0}
{"code":"escape_json(StringInfo buf, const char *str)\n{\n\tconst char *p;\n\n\tappendStringInfoCharMacro(buf, '\\\"');\n\tfor (p = str; *p; p++)\n\t{\n\t\tswitch (*p)\n\t\t{\n\t\t\tcase '\\b':\n\t\t\t\tappendStringInfoString(buf, \"\\\\b\");\n\t\t\t\tbreak;\n\t\t\tcase '\\f':\n\t\t\t\tappendStringInfoString(buf, \"\\\\f\");\n\t\t\t\tbreak;\n\t\t\tcase '\\n':\n\t\t\t\tappendStringInfoString(buf, \"\\\\n\");\n\t\t\t\tbreak;\n\t\t\tcase '\\r':\n\t\t\t\tappendStringInfoString(buf, \"\\\\r\");\n\t\t\t\tbreak;\n\t\t\tcase '\\t':\n\t\t\t\tappendStringInfoString(buf, \"\\\\t\");\n\t\t\t\tbreak;\n\t\t\tcase '\"':\n\t\t\t\tappendStringInfoString(buf, \"\\\\\\\"\");\n\t\t\t\tbreak;\n\t\t\tcase '\\\\':\n\t\t\t\tappendStringInfoString(buf, \"\\\\\\\\\");\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tif ((unsigned char) *p < ' ')\n\t\t\t\t\tappendStringInfo(buf, \"\\\\u%04x\", (int) *p);\n\t\t\t\telse\n\t\t\t\t\tappendStringInfoCharMacro(buf, *p);\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tappendStringInfoCharMacro(buf, '\\\"');\n}\n","idx":2522,"target":0}
{"code":"extract_mb_char(char *s)\n{\n\tchar\t   *res;\n\tint\t\t\tlen;\n\n\tlen = pg_mblen(s);\n\tres = palloc(len + 1);\n\tmemcpy(res, s, len);\n\tres[len] = '\\0';\n\n\treturn res;\n}\n","idx":2523,"target":0}
{"code":"json_agg_transfn(PG_FUNCTION_ARGS)\n{\n\tMemoryContext aggcontext,\n\t\t\t\toldcontext;\n\tJsonAggState\t*state;\n\tDatum\t\tval;\n\n\tif (!AggCheckCallContext(fcinfo, &aggcontext))\n\t{\n\t\t\/* cannot be called directly because of internal-type argument *\/\n\t\telog(ERROR, \"json_agg_transfn called in non-aggregate context\");\n\t}\n\n\tif (PG_ARGISNULL(0))\n\t{\n\t\tOid         arg_type = get_fn_expr_argtype(fcinfo->flinfo, 1);\n\n\t\tif (arg_type == InvalidOid)\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t\t errmsg(\"could not determine input data type\")));\n\n\t\t\/*\n\t\t * Make this state object in a context where it will persist for the\n\t\t * duration of the aggregate call.  MemoryContextSwitchTo is only\n\t\t * needed the first time, as the StringInfo routines make sure they\n\t\t * use the right context to enlarge the object if necessary.\n\t\t *\/\n\t\toldcontext = MemoryContextSwitchTo(aggcontext);\n\t\tstate = (JsonAggState *) palloc(sizeof(JsonAggState));\n\t\tstate->str = makeStringInfo();\n\t\tMemoryContextSwitchTo(oldcontext);\n\n\t\tappendStringInfoChar(state->str, '[');\n\t\tjson_categorize_type(arg_type,&state->val_category,\n\t\t\t\t\t\t\t &state->val_output_func);\n\t}\n\telse\n\t{\n\t\tstate = (JsonAggState *) PG_GETARG_POINTER(0);\n\t\tappendStringInfoString(state->str, \", \");\n\t}\n\n\t\/* fast path for NULLs *\/\n\tif (PG_ARGISNULL(1))\n\t{\n\t\tdatum_to_json((Datum) 0, true, state->str, JSONTYPE_NULL,\n\t\t\t\t\t  InvalidOid, false);\n\t\tPG_RETURN_POINTER(state);\n\t}\n\n\tval = PG_GETARG_DATUM(1);\n\n\t\/* add some whitespace if structured type and not first item *\/\n\tif (!PG_ARGISNULL(0) &&\n\t\t(state->val_category == JSONTYPE_ARRAY ||\n\t\t state->val_category == JSONTYPE_COMPOSITE))\n\t{\n\t\tappendStringInfoString(state->str, \"\\n \");\n\t}\n\n\tdatum_to_json(val, false, state->str, state->val_category,\n\t\t\t\t  state->val_output_func, false);\n\n\t\/*\n\t * The transition type for array_agg() is declared to be \"internal\", which\n\t * is a pass-by-value type the same size as a pointer.  So we can safely\n\t * pass the JsonAggState pointer through nodeAgg.c's machinations.\n\t *\/\n\tPG_RETURN_POINTER(state);\n}\n","idx":2525,"target":0}
{"code":"json_build_array(PG_FUNCTION_ARGS)\n{\n\tint\t\t\tnargs = PG_NARGS();\n\tint\t\t\ti;\n\tDatum\t\targ;\n\tconst char *sep = \"\";\n\tStringInfo\tresult;\n\tOid\t\t\tval_type;\n\n\tresult = makeStringInfo();\n\n\tappendStringInfoChar(result, '[');\n\n\tfor (i = 0; i < nargs; i++)\n\t{\n\t\t\/*\n\t\t * Note: since json_build_array() is declared as taking type \"any\",\n\t\t * the parser will not do any type conversion on unknown-type literals\n\t\t * (that is, undecorated strings or NULLs).  Such values will arrive\n\t\t * here as type UNKNOWN, which fortunately does not matter to us,\n\t\t * since unknownout() works fine.\n\t\t *\/\n\t\tappendStringInfoString(result, sep);\n\t\tsep = \", \";\n\n\t\tval_type = get_fn_expr_argtype(fcinfo->flinfo, i);\n\n\t\tif (val_type == InvalidOid)\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t\t errmsg(\"could not determine data type for argument %d\",\n\t\t\t\t\t\t\ti + 1)));\n\n\t\tif (PG_ARGISNULL(i))\n\t\t\targ = (Datum) 0;\n\t\telse\n\t\t\targ = PG_GETARG_DATUM(i);\n\n\t\tadd_json(arg, PG_ARGISNULL(i), result, val_type, false);\n\t}\n\n\tappendStringInfoChar(result, ']');\n\n\tPG_RETURN_TEXT_P(cstring_to_text_with_len(result->data, result->len));\n}\n","idx":2526,"target":0}
{"code":"json_build_array_noargs(PG_FUNCTION_ARGS)\n{\n\tPG_RETURN_TEXT_P(cstring_to_text_with_len(\"[]\", 2));\n}\n","idx":2527,"target":0}
{"code":"json_build_object(PG_FUNCTION_ARGS)\n{\n\tint\t\t\tnargs = PG_NARGS();\n\tint\t\t\ti;\n\tDatum\t\targ;\n\tconst char *sep = \"\";\n\tStringInfo\tresult;\n\tOid\t\t\tval_type;\n\n\tif (nargs % 2 != 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"argument list must have even number of elements\"),\n\t\t\t\t errhint(\"The arguments of json_build_object() must consist of alternating keys and values.\")));\n\n\tresult = makeStringInfo();\n\n\tappendStringInfoChar(result, '{');\n\n\tfor (i = 0; i < nargs; i += 2)\n\t{\n\t\t\/*\n\t\t * Note: since json_build_object() is declared as taking type \"any\",\n\t\t * the parser will not do any type conversion on unknown-type literals\n\t\t * (that is, undecorated strings or NULLs).  Such values will arrive\n\t\t * here as type UNKNOWN, which fortunately does not matter to us,\n\t\t * since unknownout() works fine.\n\t\t *\/\n\t\tappendStringInfoString(result, sep);\n\t\tsep = \", \";\n\n\t\t\/* process key *\/\n\t\tval_type = get_fn_expr_argtype(fcinfo->flinfo, i);\n\n\t\tif (val_type == InvalidOid)\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t\t errmsg(\"could not determine data type for argument %d\",\n\t\t\t\t\t\t\ti + 1)));\n\n\t\tif (PG_ARGISNULL(i))\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t\t errmsg(\"argument %d cannot be null\", i + 1),\n\t\t\t\t\t errhint(\"Object keys should be text.\")));\n\n\t\targ = PG_GETARG_DATUM(i);\n\n\t\tadd_json(arg, false, result, val_type, true);\n\n\t\tappendStringInfoString(result, \" : \");\n\n\t\t\/* process value *\/\n\t\tval_type = get_fn_expr_argtype(fcinfo->flinfo, i + 1);\n\n\t\tif (val_type == InvalidOid)\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t\t errmsg(\"could not determine data type for argument %d\",\n\t\t\t\t\t\t\ti + 2)));\n\n\t\tif (PG_ARGISNULL(i + 1))\n\t\t\targ = (Datum) 0;\n\t\telse\n\t\t\targ = PG_GETARG_DATUM(i + 1);\n\n\t\tadd_json(arg, PG_ARGISNULL(i + 1), result, val_type, false);\n\t}\n\n\tappendStringInfoChar(result, '}');\n\n\tPG_RETURN_TEXT_P(cstring_to_text_with_len(result->data, result->len));\n}\n","idx":2528,"target":0}
{"code":"json_build_object_noargs(PG_FUNCTION_ARGS)\n{\n\tPG_RETURN_TEXT_P(cstring_to_text_with_len(\"{}\", 2));\n}\n","idx":2529,"target":0}
{"code":"json_categorize_type(Oid typoid,\n\t\t\t\t\t JsonTypeCategory *tcategory,\n\t\t\t\t\t Oid *outfuncoid)\n{\n\tbool\t\ttypisvarlena;\n\n\t\/* Look through any domain *\/\n\ttypoid = getBaseType(typoid);\n\n\t*outfuncoid = InvalidOid;\n\n\t\/*\n\t * We need to get the output function for everything except date and\n\t * timestamp types, array and composite types, booleans, and non-builtin\n\t * types where there's a cast to json.\n\t *\/\n\n\tswitch (typoid)\n\t{\n\t\tcase BOOLOID:\n\t\t\t*tcategory = JSONTYPE_BOOL;\n\t\t\tbreak;\n\n\t\tcase INT2OID:\n\t\tcase INT4OID:\n\t\tcase INT8OID:\n\t\tcase FLOAT4OID:\n\t\tcase FLOAT8OID:\n\t\tcase NUMERICOID:\n\t\t\tgetTypeOutputInfo(typoid, outfuncoid, &typisvarlena);\n\t\t\t*tcategory = JSONTYPE_NUMERIC;\n\t\t\tbreak;\n\n\t\tcase DATEOID:\n\t\t\t*tcategory = JSONTYPE_DATE;\n\t\t\tbreak;\n\n\t\tcase TIMESTAMPOID:\n\t\t\t*tcategory = JSONTYPE_TIMESTAMP;\n\t\t\tbreak;\n\n\t\tcase TIMESTAMPTZOID:\n\t\t\t*tcategory = JSONTYPE_TIMESTAMPTZ;\n\t\t\tbreak;\n\n\t\tcase JSONOID:\n\t\tcase JSONBOID:\n\t\t\tgetTypeOutputInfo(typoid, outfuncoid, &typisvarlena);\n\t\t\t*tcategory = JSONTYPE_JSON;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\t\/* Check for arrays and composites *\/\n\t\t\tif (OidIsValid(get_element_type(typoid)))\n\t\t\t\t*tcategory = JSONTYPE_ARRAY;\n\t\t\telse if (type_is_rowtype(typoid))\n\t\t\t\t*tcategory = JSONTYPE_COMPOSITE;\n\t\t\telse\n\t\t\t{\n\t\t\t\t\/* It's probably the general case ... *\/\n\t\t\t\t*tcategory = JSONTYPE_OTHER;\n\t\t\t\t\/* but let's look for a cast to json, if it's not built-in *\/\n\t\t\t\tif (typoid >= FirstNormalObjectId)\n\t\t\t\t{\n\t\t\t\t\tOid\t\t\tcastfunc;\n\t\t\t\t\tCoercionPathType ctype;\n\n\t\t\t\t\tctype = find_coercion_pathway(JSONOID, typoid,\n\t\t\t\t\t\t\t\t\t\t\t\t  COERCION_EXPLICIT,\n\t\t\t\t\t\t\t\t\t\t\t\t  &castfunc);\n\t\t\t\t\tif (ctype == COERCION_PATH_FUNC && OidIsValid(castfunc))\n\t\t\t\t\t{\n\t\t\t\t\t\t*tcategory = JSONTYPE_CAST;\n\t\t\t\t\t\t*outfuncoid = castfunc;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\t\/* non builtin type with no cast *\/\n\t\t\t\t\t\tgetTypeOutputInfo(typoid, outfuncoid, &typisvarlena);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t\/* any other builtin type *\/\n\t\t\t\t\tgetTypeOutputInfo(typoid, outfuncoid, &typisvarlena);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t}\n}\n","idx":2530,"target":0}
{"code":"json_in(PG_FUNCTION_ARGS)\n{\n\tchar\t   *json = PG_GETARG_CSTRING(0);\n\ttext\t   *result = cstring_to_text(json);\n\tJsonLexContext *lex;\n\n\t\/* validate it *\/\n\tlex = makeJsonLexContext(result, false);\n\tpg_parse_json(lex, &nullSemAction);\n\n\t\/* Internal representation is the same as text, for now *\/\n\tPG_RETURN_TEXT_P(result);\n}\n","idx":2531,"target":0}
{"code":"json_lex_number(JsonLexContext *lex, char *s, bool *num_err)\n{\n\tbool\t\terror = false;\n\tchar\t   *p;\n\tint\t\t\tlen;\n\n\tlen = s - lex->input;\n\t\/* Part (1): leading sign indicator. *\/\n\t\/* Caller already did this for us; so do nothing. *\/\n\n\t\/* Part (2): parse main digit string. *\/\n\tif (*s == '0')\n\t{\n\t\ts++;\n\t\tlen++;\n\t}\n\telse if (*s >= '1' && *s <= '9')\n\t{\n\t\tdo\n\t\t{\n\t\t\ts++;\n\t\t\tlen++;\n\t\t} while (len < lex->input_length && *s >= '0' && *s <= '9');\n\t}\n\telse\n\t\terror = true;\n\n\t\/* Part (3): parse optional decimal portion. *\/\n\tif (len < lex->input_length && *s == '.')\n\t{\n\t\ts++;\n\t\tlen++;\n\t\tif (len == lex->input_length || *s < '0' || *s > '9')\n\t\t\terror = true;\n\t\telse\n\t\t{\n\t\t\tdo\n\t\t\t{\n\t\t\t\ts++;\n\t\t\t\tlen++;\n\t\t\t} while (len < lex->input_length && *s >= '0' && *s <= '9');\n\t\t}\n\t}\n\n\t\/* Part (4): parse optional exponent. *\/\n\tif (len < lex->input_length && (*s == 'e' || *s == 'E'))\n\t{\n\t\ts++;\n\t\tlen++;\n\t\tif (len < lex->input_length && (*s == '+' || *s == '-'))\n\t\t{\n\t\t\ts++;\n\t\t\tlen++;\n\t\t}\n\t\tif (len == lex->input_length || *s < '0' || *s > '9')\n\t\t\terror = true;\n\t\telse\n\t\t{\n\t\t\tdo\n\t\t\t{\n\t\t\t\ts++;\n\t\t\t\tlen++;\n\t\t\t} while (len < lex->input_length && *s >= '0' && *s <= '9');\n\t\t}\n\t}\n\n\t\/*\n\t * Check for trailing garbage.  As in json_lex(), any alphanumeric stuff\n\t * here should be considered part of the token for error-reporting\n\t * purposes.\n\t *\/\n\tfor (p = s; len < lex->input_length && JSON_ALPHANUMERIC_CHAR(*p); p++, len++)\n\t\terror = true;\n\n\tif (num_err != NULL)\n\t{\n\t\t\/* let the caller handle the error *\/\n\t\t*num_err = error;\n\t}\n\telse\n\t{\n\t\tlex->prev_token_terminator = lex->token_terminator;\n\t\tlex->token_terminator = p;\n\t\tif (error)\n\t\t\treport_invalid_token(lex);\n\t}\n}\n","idx":2533,"target":0}
{"code":"json_object(PG_FUNCTION_ARGS)\n{\n\tArrayType  *in_array = PG_GETARG_ARRAYTYPE_P(0);\n\tint\t\t\tndims = ARR_NDIM(in_array);\n\tStringInfoData result;\n\tDatum\t   *in_datums;\n\tbool\t   *in_nulls;\n\tint\t\t\tin_count,\n\t\t\t\tcount,\n\t\t\t\ti;\n\ttext\t   *rval;\n\tchar\t   *v;\n\n\tswitch (ndims)\n\t{\n\t\tcase 0:\n\t\t\tPG_RETURN_DATUM(CStringGetTextDatum(\"{}\"));\n\t\t\tbreak;\n\n\t\tcase 1:\n\t\t\tif ((ARR_DIMS(in_array)[0]) % 2)\n\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t(errcode(ERRCODE_ARRAY_SUBSCRIPT_ERROR),\n\t\t\t\t\t\t errmsg(\"array must have even number of elements\")));\n\t\t\tbreak;\n\n\t\tcase 2:\n\t\t\tif ((ARR_DIMS(in_array)[1]) != 2)\n\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t(errcode(ERRCODE_ARRAY_SUBSCRIPT_ERROR),\n\t\t\t\t\t\t errmsg(\"array must have two columns\")));\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_ARRAY_SUBSCRIPT_ERROR),\n\t\t\t\t\t errmsg(\"wrong number of array subscripts\")));\n\t}\n\n\tdeconstruct_array(in_array,\n\t\t\t\t\t  TEXTOID, -1, false, 'i',\n\t\t\t\t\t  &in_datums, &in_nulls, &in_count);\n\n\tcount = in_count \/ 2;\n\n\tinitStringInfo(&result);\n\n\tappendStringInfoChar(&result, '{');\n\n\tfor (i = 0; i < count; ++i)\n\t{\n\t\tif (in_nulls[i * 2])\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_NULL_VALUE_NOT_ALLOWED),\n\t\t\t\t\t errmsg(\"null value not allowed for object key\")));\n\n\t\tv = TextDatumGetCString(in_datums[i * 2]);\n\t\tif (i > 0)\n\t\t\tappendStringInfoString(&result, \", \");\n\t\tescape_json(&result, v);\n\t\tappendStringInfoString(&result, \" : \");\n\t\tpfree(v);\n\t\tif (in_nulls[i * 2 + 1])\n\t\t\tappendStringInfoString(&result, \"null\");\n\t\telse\n\t\t{\n\t\t\tv = TextDatumGetCString(in_datums[i * 2 + 1]);\n\t\t\tescape_json(&result, v);\n\t\t\tpfree(v);\n\t\t}\n\t}\n\n\tappendStringInfoChar(&result, '}');\n\n\tpfree(in_datums);\n\tpfree(in_nulls);\n\n\trval = cstring_to_text_with_len(result.data, result.len);\n\tpfree(result.data);\n\n\tPG_RETURN_TEXT_P(rval);\n\n}\n","idx":2535,"target":0}
{"code":"json_object_agg_finalfn(PG_FUNCTION_ARGS)\n{\n\tJsonAggState\t*state;\n\n\t\/* cannot be called directly because of internal-type argument *\/\n\tAssert(AggCheckCallContext(fcinfo, NULL));\n\n\tstate = PG_ARGISNULL(0) ? NULL : (JsonAggState *) PG_GETARG_POINTER(0);\n\n\t\/* NULL result for no rows in, as is standard with aggregates *\/\n\tif (state == NULL)\n\t\tPG_RETURN_NULL();\n\n\t\/* Else return state with appropriate object terminator added *\/\n\tPG_RETURN_TEXT_P(catenate_stringinfo_string(state->str, \" }\"));\n","idx":2536,"target":0}
{"code":"json_object_two_arg(PG_FUNCTION_ARGS)\n{\n\tArrayType  *key_array = PG_GETARG_ARRAYTYPE_P(0);\n\tArrayType  *val_array = PG_GETARG_ARRAYTYPE_P(1);\n\tint\t\t\tnkdims = ARR_NDIM(key_array);\n\tint\t\t\tnvdims = ARR_NDIM(val_array);\n\tStringInfoData result;\n\tDatum\t   *key_datums,\n\t\t\t   *val_datums;\n\tbool\t   *key_nulls,\n\t\t\t   *val_nulls;\n\tint\t\t\tkey_count,\n\t\t\t\tval_count,\n\t\t\t\ti;\n\ttext\t   *rval;\n\tchar\t   *v;\n\n\tif (nkdims > 1 || nkdims != nvdims)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_ARRAY_SUBSCRIPT_ERROR),\n\t\t\t\t errmsg(\"wrong number of array subscripts\")));\n\n\tif (nkdims == 0)\n\t\tPG_RETURN_DATUM(CStringGetTextDatum(\"{}\"));\n\n\tdeconstruct_array(key_array,\n\t\t\t\t\t  TEXTOID, -1, false, 'i',\n\t\t\t\t\t  &key_datums, &key_nulls, &key_count);\n\n\tdeconstruct_array(val_array,\n\t\t\t\t\t  TEXTOID, -1, false, 'i',\n\t\t\t\t\t  &val_datums, &val_nulls, &val_count);\n\n\tif (key_count != val_count)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_ARRAY_SUBSCRIPT_ERROR),\n\t\t\t\t errmsg(\"mismatched array dimensions\")));\n\n\tinitStringInfo(&result);\n\n\tappendStringInfoChar(&result, '{');\n\n\tfor (i = 0; i < key_count; ++i)\n\t{\n\t\tif (key_nulls[i])\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_NULL_VALUE_NOT_ALLOWED),\n\t\t\t\t\t errmsg(\"null value not allowed for object key\")));\n\n\t\tv = TextDatumGetCString(key_datums[i]);\n\t\tif (i > 0)\n\t\t\tappendStringInfoString(&result, \", \");\n\t\tescape_json(&result, v);\n\t\tappendStringInfoString(&result, \" : \");\n\t\tpfree(v);\n\t\tif (val_nulls[i])\n\t\t\tappendStringInfoString(&result, \"null\");\n\t\telse\n\t\t{\n\t\t\tv = TextDatumGetCString(val_datums[i]);\n\t\t\tescape_json(&result, v);\n\t\t\tpfree(v);\n\t\t}\n\t}\n\n\tappendStringInfoChar(&result, '}');\n\n\tpfree(key_datums);\n\tpfree(key_nulls);\n\tpfree(val_datums);\n\tpfree(val_nulls);\n\n\trval = cstring_to_text_with_len(result.data, result.len);\n\tpfree(result.data);\n\n\tPG_RETURN_TEXT_P(rval);\n}\n","idx":2538,"target":0}
{"code":"json_out(PG_FUNCTION_ARGS)\n{\n\t\/* we needn't detoast because text_to_cstring will handle that *\/\n\tDatum\t\ttxt = PG_GETARG_DATUM(0);\n\n\tPG_RETURN_CSTRING(TextDatumGetCString(txt));\n}\n","idx":2539,"target":0}
{"code":"json_recv(PG_FUNCTION_ARGS)\n{\n\tStringInfo\tbuf = (StringInfo) PG_GETARG_POINTER(0);\n\tchar\t   *str;\n\tint\t\t\tnbytes;\n\tJsonLexContext *lex;\n\n\tstr = pq_getmsgtext(buf, buf->len - buf->cursor, &nbytes);\n\n\t\/* Validate it. *\/\n\tlex = makeJsonLexContextCstringLen(str, nbytes, false);\n\tpg_parse_json(lex, &nullSemAction);\n\n\tPG_RETURN_TEXT_P(cstring_to_text_with_len(str, nbytes));\n}\n","idx":2540,"target":0}
{"code":"json_send(PG_FUNCTION_ARGS)\n{\n\ttext\t   *t = PG_GETARG_TEXT_PP(0);\n\tStringInfoData buf;\n\n\tpq_begintypsend(&buf);\n\tpq_sendtext(&buf, VARDATA_ANY(t), VARSIZE_ANY_EXHDR(t));\n\tPG_RETURN_BYTEA_P(pq_endtypsend(&buf));\n}\n","idx":2541,"target":0}
{"code":"json_typeof(PG_FUNCTION_ARGS)\n{\n\ttext\t   *json;\n\n\tJsonLexContext *lex;\n\tJsonTokenType tok;\n\tchar\t   *type;\n\n\tjson = PG_GETARG_TEXT_P(0);\n\tlex = makeJsonLexContext(json, false);\n\n\t\/* Lex exactly one token from the input and check its type. *\/\n\tjson_lex(lex);\n\ttok = lex_peek(lex);\n\tswitch (tok)\n\t{\n\t\tcase JSON_TOKEN_OBJECT_START:\n\t\t\ttype = \"object\";\n\t\t\tbreak;\n\t\tcase JSON_TOKEN_ARRAY_START:\n\t\t\ttype = \"array\";\n\t\t\tbreak;\n\t\tcase JSON_TOKEN_STRING:\n\t\t\ttype = \"string\";\n\t\t\tbreak;\n\t\tcase JSON_TOKEN_NUMBER:\n\t\t\ttype = \"number\";\n\t\t\tbreak;\n\t\tcase JSON_TOKEN_TRUE:\n\t\tcase JSON_TOKEN_FALSE:\n\t\t\ttype = \"boolean\";\n\t\t\tbreak;\n\t\tcase JSON_TOKEN_NULL:\n\t\t\ttype = \"null\";\n\t\t\tbreak;\n\t\tdefault:\n\t\t\telog(ERROR, \"unexpected json token: %d\", tok);\n\t}\n\n\tPG_RETURN_TEXT_P(cstring_to_text(type));\n}\n","idx":2542,"target":0}
{"code":"lex_accept(JsonLexContext *lex, JsonTokenType token, char **lexeme)\n{\n\tif (lex->token_type == token)\n\t{\n\t\tif (lexeme != NULL)\n\t\t{\n\t\t\tif (lex->token_type == JSON_TOKEN_STRING)\n\t\t\t{\n\t\t\t\tif (lex->strval != NULL)\n\t\t\t\t\t*lexeme = pstrdup(lex->strval->data);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tint\t\t\tlen = (lex->token_terminator - lex->token_start);\n\t\t\t\tchar\t   *tokstr = palloc(len + 1);\n\n\t\t\t\tmemcpy(tokstr, lex->token_start, len);\n\t\t\t\ttokstr[len] = '\\0';\n\t\t\t\t*lexeme = tokstr;\n\t\t\t}\n\t\t}\n\t\tjson_lex(lex);\n\t\treturn true;\n\t}\n\treturn false;\n}\n","idx":2543,"target":0}
{"code":"lex_expect(JsonParseContext ctx, JsonLexContext *lex, JsonTokenType token)\n{\n\tif (!lex_accept(lex, token, NULL))\n\t\treport_parse_error(ctx, lex);\n}\n","idx":2544,"target":0}
{"code":"lex_peek(JsonLexContext *lex)\n{\n\treturn lex->token_type;\n}\n","idx":2545,"target":0}
{"code":"makeJsonLexContext(text *json, bool need_escapes)\n{\n\treturn makeJsonLexContextCstringLen(VARDATA(json),\n\t\t\t\t\t\t\t\t\t\tVARSIZE(json) - VARHDRSZ,\n\t\t\t\t\t\t\t\t\t\tneed_escapes);\n}\n","idx":2546,"target":0}
{"code":"makeJsonLexContextCstringLen(char *json, int len, bool need_escapes)\n{\n\tJsonLexContext *lex = palloc0(sizeof(JsonLexContext));\n\n\tlex->input = lex->token_terminator = lex->line_start = json;\n\tlex->line_number = 1;\n\tlex->input_length = len;\n\tif (need_escapes)\n\t\tlex->strval = makeStringInfo();\n\treturn lex;\n}\n","idx":2547,"target":0}
{"code":"parse_array_element(JsonLexContext *lex, JsonSemAction *sem)\n{\n\tjson_aelem_action astart = sem->array_element_start;\n\tjson_aelem_action aend = sem->array_element_end;\n\tJsonTokenType tok = lex_peek(lex);\n\n\tbool\t\tisnull;\n\n\tisnull = tok == JSON_TOKEN_NULL;\n\n\tif (astart != NULL)\n\t\t(*astart) (sem->semstate, isnull);\n\n\t\/* an array element is any object, array or scalar *\/\n\tswitch (tok)\n\t{\n\t\tcase JSON_TOKEN_OBJECT_START:\n\t\t\tparse_object(lex, sem);\n\t\t\tbreak;\n\t\tcase JSON_TOKEN_ARRAY_START:\n\t\t\tparse_array(lex, sem);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tparse_scalar(lex, sem);\n\t}\n\n\tif (aend != NULL)\n\t\t(*aend) (sem->semstate, isnull);\n}\n","idx":2548,"target":0}
{"code":"parse_object_field(JsonLexContext *lex, JsonSemAction *sem)\n{\n\t\/*\n\t * An object field is \"fieldname\" : value where value can be a scalar,\n\t * object or array.  Note: in user-facing docs and error messages, we\n\t * generally call a field name a \"key\".\n\t *\/\n\n\tchar\t   *fname = NULL;\t\/* keep compiler quiet *\/\n\tjson_ofield_action ostart = sem->object_field_start;\n\tjson_ofield_action oend = sem->object_field_end;\n\tbool\t\tisnull;\n\tchar\t  **fnameaddr = NULL;\n\tJsonTokenType tok;\n\n\tif (ostart != NULL || oend != NULL)\n\t\tfnameaddr = &fname;\n\n\tif (!lex_accept(lex, JSON_TOKEN_STRING, fnameaddr))\n\t\treport_parse_error(JSON_PARSE_STRING, lex);\n\n\tlex_expect(JSON_PARSE_OBJECT_LABEL, lex, JSON_TOKEN_COLON);\n\n\ttok = lex_peek(lex);\n\tisnull = tok == JSON_TOKEN_NULL;\n\n\tif (ostart != NULL)\n\t\t(*ostart) (sem->semstate, fname, isnull);\n\n\tswitch (tok)\n\t{\n\t\tcase JSON_TOKEN_OBJECT_START:\n\t\t\tparse_object(lex, sem);\n\t\t\tbreak;\n\t\tcase JSON_TOKEN_ARRAY_START:\n\t\t\tparse_array(lex, sem);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tparse_scalar(lex, sem);\n\t}\n\n\tif (oend != NULL)\n\t\t(*oend) (sem->semstate, fname, isnull);\n}\n","idx":2549,"target":0}
{"code":"parse_scalar(JsonLexContext *lex, JsonSemAction *sem)\n{\n\tchar\t   *val = NULL;\n\tjson_scalar_action sfunc = sem->scalar;\n\tchar\t  **valaddr;\n\tJsonTokenType tok = lex_peek(lex);\n\n\tvaladdr = sfunc == NULL ? NULL : &val;\n\n\t\/* a scalar must be a string, a number, true, false, or null *\/\n\tswitch (tok)\n\t{\n\t\tcase JSON_TOKEN_TRUE:\n\t\t\tlex_accept(lex, JSON_TOKEN_TRUE, valaddr);\n\t\t\tbreak;\n\t\tcase JSON_TOKEN_FALSE:\n\t\t\tlex_accept(lex, JSON_TOKEN_FALSE, valaddr);\n\t\t\tbreak;\n\t\tcase JSON_TOKEN_NULL:\n\t\t\tlex_accept(lex, JSON_TOKEN_NULL, valaddr);\n\t\t\tbreak;\n\t\tcase JSON_TOKEN_NUMBER:\n\t\t\tlex_accept(lex, JSON_TOKEN_NUMBER, valaddr);\n\t\t\tbreak;\n\t\tcase JSON_TOKEN_STRING:\n\t\t\tlex_accept(lex, JSON_TOKEN_STRING, valaddr);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treport_parse_error(JSON_PARSE_VALUE, lex);\n\t}\n\n\tif (sfunc != NULL)\n\t\t(*sfunc) (sem->semstate, val, tok);\n}\n","idx":2550,"target":0}
{"code":"pg_parse_json(JsonLexContext *lex, JsonSemAction *sem)\n{\n\tJsonTokenType tok;\n\n\t\/* get the initial token *\/\n\tjson_lex(lex);\n\n\ttok = lex_peek(lex);\n\n\t\/* parse by recursive descent *\/\n\tswitch (tok)\n\t{\n\t\tcase JSON_TOKEN_OBJECT_START:\n\t\t\tparse_object(lex, sem);\n\t\t\tbreak;\n\t\tcase JSON_TOKEN_ARRAY_START:\n\t\t\tparse_array(lex, sem);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tparse_scalar(lex, sem);\t\t\/* json can be a bare scalar *\/\n\t}\n\n\tlex_expect(JSON_PARSE_END, lex, JSON_TOKEN_END);\n\n}\n","idx":2551,"target":0}
{"code":"report_invalid_token(JsonLexContext *lex)\n{\n\tchar\t   *token;\n\tint\t\t\ttoklen;\n\n\t\/* Separate out the offending token. *\/\n\ttoklen = lex->token_terminator - lex->token_start;\n\ttoken = palloc(toklen + 1);\n\tmemcpy(token, lex->token_start, toklen);\n\ttoken[toklen] = '\\0';\n\n\tereport(ERROR,\n\t\t\t(errcode(ERRCODE_INVALID_TEXT_REPRESENTATION),\n\t\t\t errmsg(\"invalid input syntax for type json\"),\n\t\t\t errdetail(\"Token \\\"%s\\\" is invalid.\", token),\n\t\t\t report_json_context(lex)));\n}\n","idx":2552,"target":0}
{"code":"report_json_context(JsonLexContext *lex)\n{\n\tconst char *context_start;\n\tconst char *context_end;\n\tconst char *line_start;\n\tint\t\t\tline_number;\n\tchar\t   *ctxt;\n\tint\t\t\tctxtlen;\n\tconst char *prefix;\n\tconst char *suffix;\n\n\t\/* Choose boundaries for the part of the input we will display *\/\n\tcontext_start = lex->input;\n\tcontext_end = lex->token_terminator;\n\tline_start = context_start;\n\tline_number = 1;\n\tfor (;;)\n\t{\n\t\t\/* Always advance over newlines *\/\n\t\tif (context_start < context_end && *context_start == '\\n')\n\t\t{\n\t\t\tcontext_start++;\n\t\t\tline_start = context_start;\n\t\t\tline_number++;\n\t\t\tcontinue;\n\t\t}\n\t\t\/* Otherwise, done as soon as we are close enough to context_end *\/\n\t\tif (context_end - context_start < 50)\n\t\t\tbreak;\n\t\t\/* Advance to next multibyte character *\/\n\t\tif (IS_HIGHBIT_SET(*context_start))\n\t\t\tcontext_start += pg_mblen(context_start);\n\t\telse\n\t\t\tcontext_start++;\n\t}\n\n\t\/*\n\t * We add \"...\" to indicate that the excerpt doesn't start at the\n\t * beginning of the line ... but if we're within 3 characters of the\n\t * beginning of the line, we might as well just show the whole line.\n\t *\/\n\tif (context_start - line_start <= 3)\n\t\tcontext_start = line_start;\n\n\t\/* Get a null-terminated copy of the data to present *\/\n\tctxtlen = context_end - context_start;\n\tctxt = palloc(ctxtlen + 1);\n\tmemcpy(ctxt, context_start, ctxtlen);\n\tctxt[ctxtlen] = '\\0';\n\n\t\/*\n\t * Show the context, prefixing \"...\" if not starting at start of line, and\n\t * suffixing \"...\" if not ending at end of line.\n\t *\/\n\tprefix = (context_start > line_start) ? \"...\" : \"\";\n\tsuffix = (lex->token_type != JSON_TOKEN_END && context_end - lex->input < lex->input_length && *context_end != '\\n' && *context_end != '\\r') ? \"...\" : \"\";\n\n\treturn errcontext(\"JSON data, line %d: %s%s%s\",\n\t\t\t\t\t  line_number, prefix, ctxt, suffix);\n}\n","idx":2553,"target":0}
{"code":"row_to_json(PG_FUNCTION_ARGS)\n{\n\tDatum\t\tarray = PG_GETARG_DATUM(0);\n\tStringInfo\tresult;\n\n\tresult = makeStringInfo();\n\n\tcomposite_to_json(array, result, false);\n\n\tPG_RETURN_TEXT_P(cstring_to_text_with_len(result->data, result->len));\n}\n","idx":2555,"target":0}
{"code":"row_to_json_pretty(PG_FUNCTION_ARGS)\n{\n\tDatum\t\tarray = PG_GETARG_DATUM(0);\n\tbool\t\tuse_line_feeds = PG_GETARG_BOOL(1);\n\tStringInfo\tresult;\n\n\tresult = makeStringInfo();\n\n\tcomposite_to_json(array, result, use_line_feeds);\n\n\tPG_RETURN_TEXT_P(cstring_to_text_with_len(result->data, result->len));\n}\n","idx":2556,"target":0}
{"code":"to_json(PG_FUNCTION_ARGS)\n{\n\tDatum\t\tval = PG_GETARG_DATUM(0);\n\tOid\t\t\tval_type = get_fn_expr_argtype(fcinfo->flinfo, 0);\n\tStringInfo\tresult;\n\tJsonTypeCategory tcategory;\n\tOid\t\t\toutfuncoid;\n\n\tif (val_type == InvalidOid)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"could not determine input data type\")));\n\n\tjson_categorize_type(val_type,\n\t\t\t\t\t\t &tcategory, &outfuncoid);\n\n\tresult = makeStringInfo();\n\n\tdatum_to_json(val, false, result, tcategory, outfuncoid, false);\n\n\tPG_RETURN_TEXT_P(cstring_to_text_with_len(result->data, result->len));\n}\n","idx":2557,"target":0}
{"code":"JsonbToCString(StringInfo out, JsonbContainer *in, int estimated_len)\n{\n\treturn JsonbToCStringWorker(out, in, estimated_len, false);\n}\n","idx":2558,"target":0}
{"code":"JsonbToCStringIndent(StringInfo out, JsonbContainer *in, int estimated_len)\n{\n\treturn JsonbToCStringWorker(out, in, estimated_len, true);\n}\n","idx":2559,"target":0}
{"code":"add_indent(StringInfo out, bool indent, int level)\n{\n\tif (indent)\n\t{\n\t\tint\t\t\ti;\n\n\t\tappendStringInfoCharMacro(out, '\\n');\n\t\tfor (i = 0; i < level; i++)\n\t\t\tappendBinaryStringInfo(out, \"    \", 4);\n\t}\n}\n","idx":2561,"target":0}
{"code":"checkStringLen(size_t len)\n{\n\tif (len > JENTRY_OFFLENMASK)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_PROGRAM_LIMIT_EXCEEDED),\n\t\t\t\t errmsg(\"string too long to represent as jsonb string\"),\n\t\t\t\t errdetail(\"Due to an implementation restriction, jsonb strings cannot exceed %d bytes.\",\n\t\t\t\t\t\t   JENTRY_OFFLENMASK)));\n\n\treturn len;\n}\n","idx":2562,"target":0}
{"code":"addJsonbToParseState(JsonbParseState **jbps, Jsonb *jb)\n{\n\tJsonbIterator *it;\n\tJsonbValue *o = &(*jbps)->contVal;\n\tint\t\t\ttype;\n\tJsonbValue\tv;\n\n\tit = JsonbIteratorInit(&jb->root);\n\n\tAssert(o->type == jbvArray || o->type == jbvObject);\n\n\tif (JB_ROOT_IS_SCALAR(jb))\n\t{\n\t\t(void) JsonbIteratorNext(&it, &v, false);\t\t\/* skip array header *\/\n\t\t(void) JsonbIteratorNext(&it, &v, false);\t\t\/* fetch scalar value *\/\n\n\t\tswitch (o->type)\n\t\t{\n\t\t\tcase jbvArray:\n\t\t\t\t(void) pushJsonbValue(jbps, WJB_ELEM, &v);\n\t\t\t\tbreak;\n\t\t\tcase jbvObject:\n\t\t\t\t(void) pushJsonbValue(jbps, WJB_VALUE, &v);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\telog(ERROR, \"unexpected parent of nested structure\");\n\t\t}\n\t}\n\telse\n\t{\n\t\twhile ((type = JsonbIteratorNext(&it, &v, false)) != WJB_DONE)\n\t\t{\n\t\t\tif (type == WJB_KEY || type == WJB_VALUE || type == WJB_ELEM)\n\t\t\t\t(void) pushJsonbValue(jbps, type, &v);\n\t\t\telse\n\t\t\t\t(void) pushJsonbValue(jbps, type, NULL);\n\t\t}\n\t}\n\n}\n","idx":2564,"target":0}
{"code":"alen_array_element_start(void *state, bool isnull)\n{\n\tAlenState  *_state = (AlenState *) state;\n\n\t\/* just count up all the level 1 elements *\/\n\tif (_state->lex->lex_level == 1)\n\t\t_state->count++;\n}\n","idx":2565,"target":0}
{"code":"alen_object_start(void *state)\n{\n\tAlenState  *_state = (AlenState *) state;\n\n\t\/* json structure check *\/\n\tif (_state->lex->lex_level == 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"cannot get array length of a non-array\")));\n}\n","idx":2566,"target":0}
{"code":"alen_scalar(void *state, char *token, JsonTokenType tokentype)\n{\n\tAlenState  *_state = (AlenState *) state;\n\n\t\/* json structure check *\/\n\tif (_state->lex->lex_level == 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"cannot get array length of a scalar\")));\n}\n","idx":2567,"target":0}
{"code":"each_object_field_end(void *state, char *fname, bool isnull)\n{\n\tEachState  *_state = (EachState *) state;\n\tMemoryContext old_cxt;\n\tint\t\t\tlen;\n\ttext\t   *val;\n\tHeapTuple\ttuple;\n\tDatum\t\tvalues[2];\n\tbool\t\tnulls[2] = {false, false};\n\n\t\/* skip over nested objects *\/\n\tif (_state->lex->lex_level != 1)\n\t\treturn;\n\n\t\/* use the tmp context so we can clean up after each tuple is done *\/\n\told_cxt = MemoryContextSwitchTo(_state->tmp_cxt);\n\n\tvalues[0] = CStringGetTextDatum(fname);\n\n\tif (isnull && _state->normalize_results)\n\t{\n\t\tnulls[1] = true;\n\t\tvalues[1] = (Datum) 0;\n\t}\n\telse if (_state->next_scalar)\n\t{\n\t\tvalues[1] = CStringGetTextDatum(_state->normalized_scalar);\n\t\t_state->next_scalar = false;\n\t}\n\telse\n\t{\n\t\tlen = _state->lex->prev_token_terminator - _state->result_start;\n\t\tval = cstring_to_text_with_len(_state->result_start, len);\n\t\tvalues[1] = PointerGetDatum(val);\n\t}\n\n\ttuple = heap_form_tuple(_state->ret_tdesc, values, nulls);\n\n\ttuplestore_puttuple(_state->tuple_store, tuple);\n\n\t\/* clean up and switch back *\/\n\tMemoryContextSwitchTo(old_cxt);\n\tMemoryContextReset(_state->tmp_cxt);\n}\n","idx":2569,"target":0}
{"code":"each_object_field_start(void *state, char *fname, bool isnull)\n{\n\tEachState  *_state = (EachState *) state;\n\n\t\/* save a pointer to where the value starts *\/\n\tif (_state->lex->lex_level == 1)\n\t{\n\t\t\/*\n\t\t * next_scalar will be reset in the object_field_end handler, and\n\t\t * since we know the value is a scalar there is no danger of it being\n\t\t * on while recursing down the tree.\n\t\t *\/\n\t\tif (_state->normalize_results && _state->lex->token_type == JSON_TOKEN_STRING)\n\t\t\t_state->next_scalar = true;\n\t\telse\n\t\t\t_state->result_start = _state->lex->token_start;\n\t}\n}\n","idx":2570,"target":0}
{"code":"each_worker(FunctionCallInfo fcinfo, bool as_text)\n{\n\ttext\t   *json = PG_GETARG_TEXT_P(0);\n\tJsonLexContext *lex;\n\tJsonSemAction *sem;\n\tReturnSetInfo *rsi;\n\tMemoryContext old_cxt;\n\tTupleDesc\ttupdesc;\n\tEachState  *state;\n\n\tlex = makeJsonLexContext(json, true);\n\tstate = palloc0(sizeof(EachState));\n\tsem = palloc0(sizeof(JsonSemAction));\n\n\trsi = (ReturnSetInfo *) fcinfo->resultinfo;\n\n\tif (!rsi || !IsA(rsi, ReturnSetInfo) ||\n\t\t(rsi->allowedModes & SFRM_Materialize) == 0 ||\n\t\trsi->expectedDesc == NULL)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),\n\t\t\t\t errmsg(\"set-valued function called in context that \"\n\t\t\t\t\t\t\"cannot accept a set\")));\n\n\trsi->returnMode = SFRM_Materialize;\n\n\t(void) get_call_result_type(fcinfo, NULL, &tupdesc);\n\n\t\/* make these in a sufficiently long-lived memory context *\/\n\told_cxt = MemoryContextSwitchTo(rsi->econtext->ecxt_per_query_memory);\n\n\tstate->ret_tdesc = CreateTupleDescCopy(tupdesc);\n\tBlessTupleDesc(state->ret_tdesc);\n\tstate->tuple_store =\n\t\ttuplestore_begin_heap(rsi->allowedModes & SFRM_Materialize_Random,\n\t\t\t\t\t\t\t  false, work_mem);\n\n\tMemoryContextSwitchTo(old_cxt);\n\n\tsem->semstate = (void *) state;\n\tsem->array_start = each_array_start;\n\tsem->scalar = each_scalar;\n\tsem->object_field_start = each_object_field_start;\n\tsem->object_field_end = each_object_field_end;\n\n\tstate->normalize_results = as_text;\n\tstate->next_scalar = false;\n\tstate->lex = lex;\n\tstate->tmp_cxt = AllocSetContextCreate(CurrentMemoryContext,\n\t\t\t\t\t\t\t\t\t\t   \"json_each temporary cxt\",\n\t\t\t\t\t\t\t\t\t\t   ALLOCSET_DEFAULT_MINSIZE,\n\t\t\t\t\t\t\t\t\t\t   ALLOCSET_DEFAULT_INITSIZE,\n\t\t\t\t\t\t\t\t\t\t   ALLOCSET_DEFAULT_MAXSIZE);\n\n\tpg_parse_json(lex, sem);\n\n\tMemoryContextDelete(state->tmp_cxt);\n\n\trsi->setResult = state->tuple_store;\n\trsi->setDesc = state->ret_tdesc;\n\n\tPG_RETURN_NULL();\n}\n","idx":2572,"target":0}
{"code":"elements_object_start(void *state)\n{\n\tElementsState *_state = (ElementsState *) state;\n\n\t\/* json structure check *\/\n\tif (_state->lex->lex_level == 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"cannot call %s on a non-array\",\n\t\t\t\t\t\t_state->function_name)));\n}\n","idx":2576,"target":0}
{"code":"elements_scalar(void *state, char *token, JsonTokenType tokentype)\n{\n\tElementsState *_state = (ElementsState *) state;\n\n\t\/* json structure check *\/\n\tif (_state->lex->lex_level == 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"cannot call %s on a scalar\",\n\t\t\t\t\t\t_state->function_name)));\n\n\t\/* supply de-escaped value if required *\/\n\tif (_state->next_scalar)\n\t\t_state->normalized_scalar = token;\n}\n","idx":2577,"target":0}
{"code":"elements_worker(FunctionCallInfo fcinfo, const char *funcname, bool as_text)\n{\n\ttext\t   *json = PG_GETARG_TEXT_P(0);\n\n\t\/* elements only needs escaped strings when as_text *\/\n\tJsonLexContext *lex = makeJsonLexContext(json, as_text);\n\tJsonSemAction *sem;\n\tReturnSetInfo *rsi;\n\tMemoryContext old_cxt;\n\tTupleDesc\ttupdesc;\n\tElementsState *state;\n\n\tstate = palloc0(sizeof(ElementsState));\n\tsem = palloc0(sizeof(JsonSemAction));\n\n\trsi = (ReturnSetInfo *) fcinfo->resultinfo;\n\n\tif (!rsi || !IsA(rsi, ReturnSetInfo) ||\n\t\t(rsi->allowedModes & SFRM_Materialize) == 0 ||\n\t\trsi->expectedDesc == NULL)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),\n\t\t\t\t errmsg(\"set-valued function called in context that \"\n\t\t\t\t\t\t\"cannot accept a set\")));\n\n\trsi->returnMode = SFRM_Materialize;\n\n\t\/* it's a simple type, so don't use get_call_result_type() *\/\n\ttupdesc = rsi->expectedDesc;\n\n\t\/* make these in a sufficiently long-lived memory context *\/\n\told_cxt = MemoryContextSwitchTo(rsi->econtext->ecxt_per_query_memory);\n\n\tstate->ret_tdesc = CreateTupleDescCopy(tupdesc);\n\tBlessTupleDesc(state->ret_tdesc);\n\tstate->tuple_store =\n\t\ttuplestore_begin_heap(rsi->allowedModes & SFRM_Materialize_Random,\n\t\t\t\t\t\t\t  false, work_mem);\n\n\tMemoryContextSwitchTo(old_cxt);\n\n\tsem->semstate = (void *) state;\n\tsem->object_start = elements_object_start;\n\tsem->scalar = elements_scalar;\n\tsem->array_element_start = elements_array_element_start;\n\tsem->array_element_end = elements_array_element_end;\n\n\tstate->function_name = funcname;\n\tstate->normalize_results = as_text;\n\tstate->next_scalar = false;\n\tstate->lex = lex;\n\tstate->tmp_cxt = AllocSetContextCreate(CurrentMemoryContext,\n\t\t\t\t\t\t\t\t\t\t \"json_array_elements temporary cxt\",\n\t\t\t\t\t\t\t\t\t\t   ALLOCSET_DEFAULT_MINSIZE,\n\t\t\t\t\t\t\t\t\t\t   ALLOCSET_DEFAULT_INITSIZE,\n\t\t\t\t\t\t\t\t\t\t   ALLOCSET_DEFAULT_MAXSIZE);\n\n\tpg_parse_json(lex, sem);\n\n\tMemoryContextDelete(state->tmp_cxt);\n\n\trsi->setResult = state->tuple_store;\n\trsi->setDesc = state->ret_tdesc;\n\n\tPG_RETURN_NULL();\n}\n","idx":2578,"target":0}
{"code":"findJsonbValueFromContainerLen(JsonbContainer *container, uint32 flags,\n\t\t\t\t\t\t\t   char *key, uint32 keylen)\n{\n\tJsonbValue\tk;\n\n\tk.type = jbvString;\n\tk.val.string.val = key;\n\tk.val.string.len = keylen;\n\n\treturn findJsonbValueFromContainer(container, flags, &k);\n}\n","idx":2580,"target":0}
{"code":"get_array_element_end(void *state, bool isnull)\n{\n\tGetState   *_state = (GetState *) state;\n\tbool\t\tget_last = false;\n\tint\t\t\tlex_level = _state->lex->lex_level;\n\n\t\/* same tests as in get_array_element_start *\/\n\tif (lex_level <= _state->npath &&\n\t\t_state->pathok[lex_level - 1] &&\n\t\t_state->path_indexes != NULL &&\n\t\t_state->array_cur_index[lex_level - 1] == _state->path_indexes[lex_level - 1])\n\t{\n\t\tif (lex_level < _state->npath)\n\t\t{\n\t\t\t\/* done with this element so reset pathok *\/\n\t\t\t_state->pathok[lex_level] = false;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t\/* end of path, so we want this value *\/\n\t\t\tget_last = true;\n\t\t}\n\t}\n\n\t\/* same logic as for objects *\/\n\tif (get_last && _state->result_start != NULL)\n\t{\n\t\tif (isnull && _state->normalize_results)\n\t\t\t_state->tresult = (text *) NULL;\n\t\telse\n\t\t{\n\t\t\tchar\t   *start = _state->result_start;\n\t\t\tint\t\t\tlen = _state->lex->prev_token_terminator - start;\n\n\t\t\t_state->tresult = cstring_to_text_with_len(start, len);\n\t\t}\n\n\t\t_state->result_start = NULL;\n\t}\n}\n","idx":2581,"target":0}
{"code":"get_array_element_start(void *state, bool isnull)\n{\n\tGetState   *_state = (GetState *) state;\n\tbool\t\tget_next = false;\n\tint\t\t\tlex_level = _state->lex->lex_level;\n\n\t\/* Update array element counter *\/\n\tif (lex_level <= _state->npath)\n\t\t_state->array_cur_index[lex_level - 1]++;\n\n\tif (lex_level <= _state->npath &&\n\t\t_state->pathok[lex_level - 1] &&\n\t\t_state->path_indexes != NULL &&\n\t\t_state->array_cur_index[lex_level - 1] == _state->path_indexes[lex_level - 1])\n\t{\n\t\tif (lex_level < _state->npath)\n\t\t{\n\t\t\t\/* if not at end of path just mark path ok *\/\n\t\t\t_state->pathok[lex_level] = true;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t\/* end of path, so we want this value *\/\n\t\t\tget_next = true;\n\t\t}\n\t}\n\n\t\/* same logic as for objects *\/\n\tif (get_next)\n\t{\n\t\t_state->tresult = NULL;\n\t\t_state->result_start = NULL;\n\n\t\tif (_state->normalize_results &&\n\t\t\t_state->lex->token_type == JSON_TOKEN_STRING)\n\t\t{\n\t\t\t_state->next_scalar = true;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t_state->result_start = _state->lex->token_start;\n\t\t}\n\t}\n}\n","idx":2582,"target":0}
{"code":"get_array_end(void *state)\n{\n\tGetState   *_state = (GetState *) state;\n\tint\t\t\tlex_level = _state->lex->lex_level;\n\n\tif (lex_level == 0 && _state->npath == 0)\n\t{\n\t\t\/* Special case: return the entire array *\/\n\t\tchar\t   *start = _state->result_start;\n\t\tint\t\t\tlen = _state->lex->prev_token_terminator - start;\n\n\t\t_state->tresult = cstring_to_text_with_len(start, len);\n\t}\n}\n","idx":2583,"target":0}
{"code":"get_array_start(void *state)\n{\n\tGetState   *_state = (GetState *) state;\n\tint\t\t\tlex_level = _state->lex->lex_level;\n\n\tif (lex_level < _state->npath)\n\t{\n\t\t\/* Initialize counting of elements in this array *\/\n\t\t_state->array_cur_index[lex_level] = -1;\n\n\t\t\/* INT_MIN value is reserved to represent invalid subscript *\/\n\t\tif (_state->path_indexes[lex_level] < 0 &&\n\t\t\t_state->path_indexes[lex_level] != INT_MIN)\n\t\t{\n\t\t\t\/* Negative subscript -- convert to positive-wise subscript *\/\n\t\t\tint\t\tnelements = json_count_array_elements(_state->lex);\n\n\t\t\tif (-_state->path_indexes[lex_level] <= nelements)\n\t\t\t\t_state->path_indexes[lex_level] += nelements;\n\t\t}\n\t}\n\telse if (lex_level == 0 && _state->npath == 0)\n\t{\n\t\t\/*\n\t\t * Special case: we should match the entire array.  We only need this\n\t\t * at the outermost level because at nested levels the match will\n\t\t * have been started by the outer field or array element callback.\n\t\t *\/\n\t\t_state->result_start = _state->lex->token_start;\n\t}\n}\n","idx":2584,"target":0}
{"code":"get_object_start(void *state)\n{\n\tGetState   *_state = (GetState *) state;\n\tint\t\t\tlex_level = _state->lex->lex_level;\n\n\tif (lex_level == 0 && _state->npath == 0)\n\t{\n\t\t\/*\n\t\t * Special case: we should match the entire object.  We only need this\n\t\t * at outermost level because at nested levels the match will have\n\t\t * been started by the outer field or array element callback.\n\t\t *\/\n\t\t_state->result_start = _state->lex->token_start;\n\t}\n}\n","idx":2589,"target":0}
{"code":"get_path_all(FunctionCallInfo fcinfo, bool as_text)\n{\n\ttext\t   *json = PG_GETARG_TEXT_P(0);\n\tArrayType  *path = PG_GETARG_ARRAYTYPE_P(1);\n\ttext\t   *result;\n\tDatum\t   *pathtext;\n\tbool\t   *pathnulls;\n\tint\t\t\tnpath;\n\tchar\t  **tpath;\n\tint\t\t   *ipath;\n\tint\t\t\ti;\n\n\t\/*\n\t * If the array contains any null elements, return NULL, on the grounds\n\t * that you'd have gotten NULL if any RHS value were NULL in a nested\n\t * series of applications of the -> operator.  (Note: because we also\n\t * return NULL for error cases such as no-such-field, this is true\n\t * regardless of the contents of the rest of the array.)\n\t *\/\n\tif (array_contains_nulls(path))\n\t\tPG_RETURN_NULL();\n\n\tdeconstruct_array(path, TEXTOID, -1, false, 'i',\n\t\t\t\t\t  &pathtext, &pathnulls, &npath);\n\n\ttpath = palloc(npath * sizeof(char *));\n\tipath = palloc(npath * sizeof(int));\n\n\tfor (i = 0; i < npath; i++)\n\t{\n\t\tAssert(!pathnulls[i]);\n\t\ttpath[i] = TextDatumGetCString(pathtext[i]);\n\n\t\t\/*\n\t\t * we have no idea at this stage what structure the document is so\n\t\t * just convert anything in the path that we can to an integer and set\n\t\t * all the other integers to INT_MIN which will never match.\n\t\t *\/\n\t\tif (*tpath[i] != '\\0')\n\t\t{\n\t\t\tlong\t\tind;\n\t\t\tchar\t   *endptr;\n\n\t\t\terrno = 0;\n\t\t\tind = strtol(tpath[i], &endptr, 10);\n\t\t\tif (*endptr == '\\0' && errno == 0 && ind <= INT_MAX && ind >= INT_MIN)\n\t\t\t\tipath[i] = (int) ind;\n\t\t\telse\n\t\t\t\tipath[i] = INT_MIN;\n\t\t}\n\t\telse\n\t\t\tipath[i] = INT_MIN;\n\t}\n\n\tresult = get_worker(json, tpath, ipath, npath, as_text);\n\n\tif (result != NULL)\n\t\tPG_RETURN_TEXT_P(result);\n\telse\n\t\tPG_RETURN_NULL();\n}\n","idx":2590,"target":0}
{"code":"get_scalar(void *state, char *token, JsonTokenType tokentype)\n{\n\tGetState   *_state = (GetState *) state;\n\tint\t\t\tlex_level = _state->lex->lex_level;\n\n\t\/* Check for whole-object match *\/\n\tif (lex_level == 0 && _state->npath == 0)\n\t{\n\t\tif (_state->normalize_results && tokentype == JSON_TOKEN_STRING)\n\t\t{\n\t\t\t\/* we want the de-escaped string *\/\n\t\t\t_state->next_scalar = true;\n\t\t}\n\t\telse if (_state->normalize_results && tokentype == JSON_TOKEN_NULL)\n\t\t{\n\t\t\t_state->tresult = (text *) NULL;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t\/*\n\t\t\t * This is a bit hokey: we will suppress whitespace after the\n\t\t\t * scalar token, but not whitespace before it.  Probably not worth\n\t\t\t * doing our own space-skipping to avoid that.\n\t\t\t *\/\n\t\t\tchar\t   *start = _state->lex->input;\n\t\t\tint\t\t\tlen = _state->lex->prev_token_terminator - start;\n\n\t\t\t_state->tresult = cstring_to_text_with_len(start, len);\n\t\t}\n\t}\n\n\tif (_state->next_scalar)\n\t{\n\t\t\/* a de-escaped text value is wanted, so supply it *\/\n\t\t_state->tresult = cstring_to_text(token);\n\t\t\/* make sure the next call to get_scalar doesn't overwrite it *\/\n\t\t_state->next_scalar = false;\n\t}\n}\n","idx":2591,"target":0}
{"code":"get_worker(text *json,\n\t\t   char **tpath,\n\t\t   int *ipath,\n\t\t   int npath,\n\t\t   bool normalize_results)\n{\n\tJsonLexContext *lex = makeJsonLexContext(json, true);\n\tJsonSemAction *sem = palloc0(sizeof(JsonSemAction));\n\tGetState   *state = palloc0(sizeof(GetState));\n\n\tAssert(npath >= 0);\n\n\tstate->lex = lex;\n\t\/* is it \"_as_text\" variant? *\/\n\tstate->normalize_results = normalize_results;\n\tstate->npath = npath;\n\tstate->path_names = tpath;\n\tstate->path_indexes = ipath;\n\tstate->pathok = palloc0(sizeof(bool) * npath);\n\tstate->array_cur_index = palloc(sizeof(int) * npath);\n\n\tif (npath > 0)\n\t\tstate->pathok[0] = true;\n\n\tsem->semstate = (void *) state;\n\n\t\/*\n\t * Not all variants need all the semantic routines. Only set the ones that\n\t * are actually needed for maximum efficiency.\n\t *\/\n\tsem->scalar = get_scalar;\n\tif (npath == 0)\n\t{\n\t\tsem->object_start = get_object_start;\n\t\tsem->object_end = get_object_end;\n\t\tsem->array_start = get_array_start;\n\t\tsem->array_end = get_array_end;\n\t}\n\tif (tpath != NULL)\n\t{\n\t\tsem->object_field_start = get_object_field_start;\n\t\tsem->object_field_end = get_object_field_end;\n\t}\n\tif (ipath != NULL)\n\t{\n\t\tsem->array_start = get_array_start;\n\t\tsem->array_element_start = get_array_element_start;\n\t\tsem->array_element_end = get_array_element_end;\n\t}\n\n\tpg_parse_json(lex, sem);\n\n\treturn state->tresult;\n}\n","idx":2592,"target":0}
